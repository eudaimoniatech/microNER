{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gwiedemann/miniconda3/envs/kerasenv/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import fastText\n",
    "\n",
    "from validation import compute_f1\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "\n",
    "import models\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000\n",
      "2200\n",
      "5100\n"
     ]
    }
   ],
   "source": [
    "trainSentences = utils.get_sentences_germeval('../data/GermEVAL/NER-de-train.tsv')\n",
    "devSentences = utils.get_sentences_germeval('../data/GermEVAL/NER-de-dev.tsv')\n",
    "testSentences = utils.get_sentences_germeval('../data/GermEVAL/NER-de-test.tsv')\n",
    "\n",
    "# trainSentences = utils.get_sentences_conll('../data/CONLL/deu/deu_utf.train.bio')\n",
    "# devSentences = utils.get_sentences_conll('../data/CONLL/deu/deu_utf.testa.bio')\n",
    "# testSentences = utils.get_sentences_conll('../data/CONLL/deu/deu_utf.testb.bio')\n",
    "\n",
    "print(len(trainSentences))\n",
    "print(len(devSentences))\n",
    "print(len(testSentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Die', 'O'], ['These', 'O'], [',', 'O'], ['Schlatter', 'B-PER'], ['sei', 'O'], ['Antisemit', 'O'], ['gewesen', 'O'], [',', 'O'], ['wurde', 'O'], ['seither', 'O'], ['in', 'O'], ['der', 'O'], ['theologischen', 'O'], ['Fachliteratur', 'O'], ['nicht', 'O'], ['mehr', 'O'], ['vertreten', 'O'], ['.', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(testSentences[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelSet = set()\n",
    "characters= set()\n",
    "models.max_sequence_length = 0\n",
    "\n",
    "for dataset in [trainSentences, devSentences, testSentences]:\n",
    "    for sentence in dataset:\n",
    "        for word, label in sentence:\n",
    "            for char in word:\n",
    "                characters.add(char)\n",
    "            labelSet.add(label)\n",
    "        if len(sentence) > models.max_sequence_length:\n",
    "            models.max_sequence_length = len(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "print(len(labelSet))\n",
    "print(models.max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# :: Create a mapping for the labels ::\n",
    "models.label2Idx = {\"PADDING_TOKEN\":0}\n",
    "for label in labelSet:\n",
    "    models.label2Idx[label] = len(models.label2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 21, 'B-PERderiv': 1, 'I-ORG': 2, 'I-PERpart': 3, 'I-PERderiv': 4, 'B-LOCderiv': 17, 'I-OTHderiv': 18, 'I-LOCpart': 5, 'B-OTHderiv': 6, 'I-LOCderiv': 7, 'B-PERpart': 20, 'B-ORGpart': 19, 'I-ORGpart': 9, 'PADDING_TOKEN': 0, 'B-PER': 8, 'B-LOC': 10, 'B-LOCpart': 11, 'B-ORG': 12, 'I-ORGderiv': 22, 'I-PER': 13, 'I-OTH': 23, 'B-OTHpart': 14, 'I-LOC': 24, 'B-ORGderiv': 25, 'I-OTHpart': 15, 'B-OTH': 16}\n"
     ]
    }
   ],
   "source": [
    "print(models.label2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# :: Hard coded case lookup ::\n",
    "models.case2Idx = {'PADDING_TOKEN':0, 'numeric': 1, 'allLower':2, 'allUpper':3, 'initialUpper':4, 'other':5, 'mainly_numeric':6, 'contains_digit': 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PADDING_TOKEN': 0, 'initialUpper': 4, 'allLower': 2, 'numeric': 1, 'allUpper': 3, 'other': 5, 'contains_digit': 7, 'mainly_numeric': 6}\n"
     ]
    }
   ],
   "source": [
    "print(models.case2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(trainSentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Schartau', 'B-PER'], ['sagte', 'O'], ['dem', 'O'], ['\"', 'O'], ['Tagesspiegel', 'B-ORG'], ['\"', 'O'], ['vom', 'O'], ['Freitag', 'O'], [',', 'O'], ['Fischer', 'B-PER'], ['sei', 'O'], ['\"', 'O'], ['in', 'O'], ['einer', 'O'], ['Weise', 'O'], ['aufgetreten', 'O'], [',', 'O'], ['die', 'O'], ['alles', 'O'], ['andere', 'O'], ['als', 'O'], ['überzeugend', 'O'], ['war', 'O'], ['\"', 'O'], ['.', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(trainSentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'S': 5, 'è': 168, 'ă': 6, 'а': 114, '鷹': 8, 'Œ': 248, 'ب': 270, 'أ': 11, 'ラ': 12, 'C': 13, '李': 7, 'ū': 15, '£': 207, '\\xad': 16, '†': 17, 'j': 18, 'ą': 19, 'å': 20, 't': 21, 'ã': 330, '‹': 22, 'ي': 24, '°': 198, '@': 25, 'έ': 121, 'φ': 274, '?': 27, 'u': 28, 'ċ': 35, 'ǒ': 33, 'ņ': 291, 'υ': 32, 'ě': 60, '術': 34, '±': 30, '&': 36, '九': 38, 'ж': 39, '樓': 40, 'ệ': 41, '⋅': 232, 'Ä': 42, '–': 293, '»': 219, 'κ': 234, '妃': 43, 'a': 44, 'k': 46, 'Š': 48, 'İ': 49, '▪': 14, 'о': 50, 'È': 237, '3': 51, 'F': 52, 'Т': 54, '2': 83, 'ä': 55, 'µ': 56, 'м': 57, 'ń': 58, 'ε': 59, 'q': 61, 'r': 308, 'y': 63, 'ế': 65, 'x': 240, '(': 66, '\\x96': 67, 'ó': 68, 'V': 69, '¹': 269, 'ض': 70, '‘': 72, 'η': 264, 'ý': 73, 'ь': 244, 'ō': 74, '별': 126, 'à': 81, 'г': 79, 'A': 80, 'у': 82, '´': 84, '寝': 85, ',': 107, 'ā': 86, '€': 87, 'Ø': 89, 'ř': 243, 'к': 90, '−': 299, 'В': 91, 'И': 93, 'и': 285, '佐': 94, 'á': 95, 'л': 187, '·': 96, \"'\": 97, 'ḫ': 250, 'T': 100, '\\x94': 105, 'ο': 301, 'ž': 103, 'ñ': 252, '!': 328, 'L': 108, 'ю': 106, '0': 109, 'î': 110, 'б': 189, 'ا': 227, '“': 113, '¤': 115, 'ś': 116, '貴': 124, '章': 123, '9': 119, 'Ü': 120, 'À': 122, 'ы': 192, 'ά': 125, 's': 253, 'オ': 283, '«': 127, '冲': 326, 'ĩ': 288, '‐': 128, 'ç': 245, 'g': 129, 'Ц': 23, 'â': 132, 'P': 133, '造': 134, '’': 135, '傳': 137, 'ī': 143, 'ɨ': 139, 'f': 140, '[': 142, 'ı': 282, 'д': 145, 'æ': 147, 'J': 130, '\\x99': 149, '6': 309, ';': 150, '5': 77, 'ô': 151, '台': 26, 'G': 153, 'Î': 144, 'ψ': 155, 'e': 156, 'ł': 158, 'v': 159, '+': 160, '士': 161, '⊃': 162, 'ć': 29, '\\x95': 138, '©': 164, '\\u200e': 31, 'd': 165, '*': 166, '1': 167, 'Q': 170, 'з': 171, 'B': 172, 'č': 75, 'û': 173, 'š': 174, '동': 178, 'E': 141, 'ē': 295, 'в': 179, 'R': 180, 'ό': 181, '\\x9a': 259, 'є': 183, 'ő': 314, '7': 184, 'р': 185, 'é': 186, '算': 190, '¸': 175, 'ź': 146, 'Á': 191, 'ť': 194, 'ø': 331, 'π': 195, '公': 196, 'W': 197, '≤': 200, '-': 199, '}': 324, 'Ş': 312, 'ğ': 201, '²': 202, '→': 204, 'ḳ': 316, '8': 203, 'Â': 182, 'ـ': 37, 'i': 205, 'Þ': 88, '\\x92': 177, 'ż': 208, 'ð': 210, 'Λ': 211, 'ß': 212, 'С': 148, 'е': 213, 'Л': 216, 'O': 318, 'M': 217, 'Č': 220, 'U': 206, 'ι': 222, 'Ö': 287, '4': 64, '\\x80': 225, '別': 92, '鶴': 209, 'ö': 228, 'т': 229, '南': 272, 'ς': 230, 'σ': 231, 'õ': 152, 'ν': 233, 'l': 235, '太': 236, 'я': 310, 'c': 238, 'N': 239, 'П': 242, 'K': 241, '博': 154, '§': 247, '—': 246, 'Ż': 249, 'w': 251, 'τ': 131, '″': 254, 'Ž': 281, 'М': 306, '.': 255, '학': 71, 'ħ': 256, '…': 257, ':': 258, 'UNKNOWN': 333, '殿': 260, '</S>': 2, '대': 10, '%': 263, '=': 265, '\"': 267, 'n': 157, '루': 277, 'z': 271, 'ë': 214, 'й': 273, '`': 76, 'b': 276, 'X': 278, 'α': 279, 'h': 280, '</W>': 4, '”': 98, 'х': 45, 'Π': 325, 'ú': 298, '›': 78, 'п': 268, 'Y': 320, 'н': 286, 'p': 99, 'Ш': 47, 'É': 188, 'ň': 289, 'D': 101, '東': 290, 'Å': 102, 'm': 292, '$': 294, '<S>': 1, '/': 218, 'λ': 323, 'í': 118, '½': 296, '„': 297, 'ę': 104, 'o': 261, 'ї': 221, 'γ': 300, '~': 302, 'β': 303, '<W>': 3, 'У': 163, 'Е': 275, 'œ': 305, 'ρ': 193, '>': 262, 'ü': 307, 'Ł': 169, '<': 311, ']': 62, 'Æ': 313, '_': 315, '≘': 224, 'ê': 317, 'ن': 112, 'PADDING_TOKEN': 0, '守': 9, 'с': 176, 'Z': 319, 'H': 223, 'ş': 321, '‚': 322, 'ʻ': 111, '³': 226, 'ῦ': 117, 'ъ': 327, '柯': 215, ')': 329, 'I': 53, '×': 136, 'ŏ': 332, '懿': 284, 'Ġ': 304, '#': 266}\n"
     ]
    }
   ],
   "source": [
    "models.char2Idx={\"PADDING_TOKEN\":0, \"<S>\":1, \"</S>\":2, \"<W>\":3, \"</W>\":4}\n",
    "for char in characters:\n",
    "    models.char2Idx[char] = len(models.char2Idx)\n",
    "models.char2Idx['UNKNOWN'] = len(models.char2Idx)\n",
    "print(models.char2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Schartau', 'B-PER'], ['sagte', 'O'], ['dem', 'O'], ['\"', 'O'], ['Tagesspiegel', 'B-ORG'], ['\"', 'O'], ['vom', 'O'], ['Freitag', 'O'], [',', 'O'], ['Fischer', 'B-PER'], ['sei', 'O'], ['\"', 'O'], ['in', 'O'], ['einer', 'O'], ['Weise', 'O'], ['aufgetreten', 'O'], [',', 'O'], ['die', 'O'], ['alles', 'O'], ['andere', 'O'], ['als', 'O'], ['überzeugend', 'O'], ['war', 'O'], ['\"', 'O'], ['.', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(trainSentences[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.ft = fastText.load_model(\"../embeddings/wiki.de.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "print(models.nb_embedding_dims)\n",
    "print(len(trainSentences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "models.idx2Label = {v: k for k, v in models.label2Idx.items()}\n",
    "print(len(models.label2Idx))\n",
    "print(len(models.idx2Label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# importlib.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_model_filename = 'model_lstm_germeval.h5'\n",
    "# checkpoint = ModelCheckpoint(tmp_model_filename, verbose=1, save_best_only = True, monitor = 'val_acc')\n",
    "history = utils.F1History(tmp_model_filename, devSet = devSentences)\n",
    "model = models.get_model_lstm_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import importlib\n",
    "#importlib.reload(utils)\n",
    "# print(models.max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    utils.NerSequence(trainSentences[:1000], shuffle_data=True, batch_size=256), \n",
    "    validation_data = utils.NerSequence(devSentences[:1000], batch_size=256), \n",
    "    epochs = 3, callbacks = [history]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.acc)\n",
    "print(history.f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(tmp_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    utils.NerSequence(trainSentences, shuffle_data=True, batch_size=2048), \n",
    "    validation_data = utils.NerSequence(devSentences, batch_size=256), \n",
    "    epochs = 5, callbacks = [history]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(tmp_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels, pred_labels = utils.predict_sequences(model, testSentences[:1000])\n",
    "print(compute_f1(pred_labels, true_labels, models.idx2Label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 52)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 52, 32) 10688       char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, None, 100)    33200       char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 408)    0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, None, 400)    974400      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "crf (CRF)                       (None, None, 26)     11154       bidirectional_2[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,029,506\n",
      "Trainable params: 1,029,442\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: 0.0452 - acc: 0.9839\n",
      "New maximum F1 score: 0.7660898308380323 (before: 0) Saving to model_lstm_germeval.0.h5\n",
      "1500/1500 [==============================] - 653s 436ms/step - loss: 0.0452 - acc: 0.9839 - val_loss: 0.0019 - val_acc: 0.9895\n",
      "Epoch 2/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.0205 - acc: 0.9888\n",
      "New maximum F1 score: 0.7887906714312583 (before: 0.7660898308380323) Saving to model_lstm_germeval.0.h5\n",
      "1500/1500 [==============================] - 636s 424ms/step - loss: -0.0205 - acc: 0.9888 - val_loss: -0.0493 - val_acc: 0.9900\n",
      "Epoch 3/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.0752 - acc: 0.9902\n",
      "New maximum F1 score: 0.807037674507554 (before: 0.7887906714312583) Saving to model_lstm_germeval.0.h5\n",
      "1500/1500 [==============================] - 639s 426ms/step - loss: -0.0752 - acc: 0.9902 - val_loss: -0.1033 - val_acc: 0.9909\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 638s 425ms/step - loss: -0.1306 - acc: 0.9909 - val_loss: -0.1562 - val_acc: 0.9904\n",
      "Epoch 5/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.1860 - acc: 0.9917\n",
      "New maximum F1 score: 0.8226684180896979 (before: 0.807037674507554) Saving to model_lstm_germeval.0.h5\n",
      "1500/1500 [==============================] - 642s 428ms/step - loss: -0.1861 - acc: 0.9917 - val_loss: -0.2111 - val_acc: 0.9913\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 643s 428ms/step - loss: -0.2410 - acc: 0.9921 - val_loss: -0.2637 - val_acc: 0.9904\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 642s 428ms/step - loss: -0.2957 - acc: 0.9927 - val_loss: -0.3182 - val_acc: 0.9913\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 610s 407ms/step - loss: -0.3501 - acc: 0.9930 - val_loss: -0.3708 - val_acc: 0.9911\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 570s 380ms/step - loss: -0.4045 - acc: 0.9933 - val_loss: -0.4243 - val_acc: 0.9911\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 571s 381ms/step - loss: -0.4587 - acc: 0.9934 - val_loss: -0.4785 - val_acc: 0.9914\n",
      "Epoch 1/10\n",
      "47/47 [==============================] - 82s 2s/step - loss: -0.2166 - acc: 0.9930 - val_loss: -0.2131 - val_acc: 0.9914\n",
      "Epoch 2/10\n",
      "47/47 [==============================] - 68s 1s/step - loss: -0.2189 - acc: 0.9932 - val_loss: -0.2150 - val_acc: 0.9914\n",
      "Epoch 3/10\n",
      "46/47 [============================>.] - ETA: 0s - loss: -0.2207 - acc: 0.9933\n",
      "New maximum F1 score: 0.8239881173412551 (before: 0.8226684180896979) Saving to model_lstm_germeval.0.h5\n",
      "47/47 [==============================] - 67s 1s/step - loss: -0.2207 - acc: 0.9933 - val_loss: -0.2166 - val_acc: 0.9916\n",
      "Epoch 4/10\n",
      "46/47 [============================>.] - ETA: 0s - loss: -0.2227 - acc: 0.9935\n",
      "New maximum F1 score: 0.8261758691206544 (before: 0.8239881173412551) Saving to model_lstm_germeval.0.h5\n",
      "47/47 [==============================] - 69s 1s/step - loss: -0.2227 - acc: 0.9935 - val_loss: -0.2185 - val_acc: 0.9917\n",
      "Epoch 5/10\n",
      "47/47 [==============================] - 69s 1s/step - loss: -0.2247 - acc: 0.9936 - val_loss: -0.2200 - val_acc: 0.9915\n",
      "Epoch 6/10\n",
      "46/47 [============================>.] - ETA: 0s - loss: -0.2264 - acc: 0.9936\n",
      "New maximum F1 score: 0.827252419955324 (before: 0.8261758691206544) Saving to model_lstm_germeval.0.h5\n",
      "47/47 [==============================] - 69s 1s/step - loss: -0.2264 - acc: 0.9936 - val_loss: -0.2219 - val_acc: 0.9916\n",
      "Epoch 7/10\n",
      "47/47 [==============================] - 69s 1s/step - loss: -0.2282 - acc: 0.9935 - val_loss: -0.2234 - val_acc: 0.9916\n",
      "Epoch 8/10\n",
      "46/47 [============================>.] - ETA: 0s - loss: -0.2302 - acc: 0.9938\n",
      "New maximum F1 score: 0.8282790697674418 (before: 0.827252419955324) Saving to model_lstm_germeval.0.h5\n",
      "47/47 [==============================] - 67s 1s/step - loss: -0.2302 - acc: 0.9938 - val_loss: -0.2253 - val_acc: 0.9918\n",
      "Epoch 9/10\n",
      "46/47 [============================>.] - ETA: 0s - loss: -0.2320 - acc: 0.9938\n",
      "New maximum F1 score: 0.8290232558139534 (before: 0.8282790697674418) Saving to model_lstm_germeval.0.h5\n",
      "47/47 [==============================] - 67s 1s/step - loss: -0.2320 - acc: 0.9938 - val_loss: -0.2270 - val_acc: 0.9918\n",
      "Epoch 10/10\n",
      "47/47 [==============================] - 67s 1s/step - loss: -0.2337 - acc: 0.9938 - val_loss: -0.2288 - val_acc: 0.9916\n",
      "Run 1\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 52)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 52, 32) 10688       char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, None, 100)    33200       char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, 408)    0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, None, 400)    974400      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "crf (CRF)                       (None, None, 26)     11154       bidirectional_4[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,029,506\n",
      "Trainable params: 1,029,442\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: 0.0446 - acc: 0.9838\n",
      "New maximum F1 score: 0.7637277648878575 (before: 0) Saving to model_lstm_germeval.1.h5\n",
      "1500/1500 [==============================] - 579s 386ms/step - loss: 0.0446 - acc: 0.9838 - val_loss: 0.0012 - val_acc: 0.9891\n",
      "Epoch 2/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.0203 - acc: 0.9890\n",
      "New maximum F1 score: 0.7850779510022272 (before: 0.7637277648878575) Saving to model_lstm_germeval.1.h5\n",
      "1500/1500 [==============================] - 569s 379ms/step - loss: -0.0203 - acc: 0.9890 - val_loss: -0.0473 - val_acc: 0.9894\n",
      "Epoch 3/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.0740 - acc: 0.9901\n",
      "New maximum F1 score: 0.7954964931709116 (before: 0.7850779510022272) Saving to model_lstm_germeval.1.h5\n",
      "1500/1500 [==============================] - 575s 383ms/step - loss: -0.0740 - acc: 0.9901 - val_loss: -0.1003 - val_acc: 0.9896\n",
      "Epoch 4/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.1293 - acc: 0.9910\n",
      "New maximum F1 score: 0.8110530246452577 (before: 0.7954964931709116) Saving to model_lstm_germeval.1.h5\n",
      "1500/1500 [==============================] - 574s 382ms/step - loss: -0.1293 - acc: 0.9910 - val_loss: -0.1553 - val_acc: 0.9912\n",
      "Epoch 5/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.1846 - acc: 0.9918\n",
      "New maximum F1 score: 0.8194810078977057 (before: 0.8110530246452577) Saving to model_lstm_germeval.1.h5\n",
      "1500/1500 [==============================] - 571s 381ms/step - loss: -0.1846 - acc: 0.9918 - val_loss: -0.2095 - val_acc: 0.9913\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 574s 383ms/step - loss: -0.2397 - acc: 0.9922 - val_loss: -0.2621 - val_acc: 0.9909\n",
      "Epoch 7/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.2943 - acc: 0.9927\n",
      "New maximum F1 score: 0.8207126948775055 (before: 0.8194810078977057) Saving to model_lstm_germeval.1.h5\n",
      "1500/1500 [==============================] - 573s 382ms/step - loss: -0.2943 - acc: 0.9926 - val_loss: -0.3174 - val_acc: 0.9913\n",
      "Epoch 8/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.3487 - acc: 0.9929\n",
      "New maximum F1 score: 0.8214814814814815 (before: 0.8207126948775055) Saving to model_lstm_germeval.1.h5\n",
      "1500/1500 [==============================] - 569s 379ms/step - loss: -0.3487 - acc: 0.9929 - val_loss: -0.3708 - val_acc: 0.9913\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 569s 379ms/step - loss: -0.4031 - acc: 0.9932 - val_loss: -0.4237 - val_acc: 0.9913\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 569s 380ms/step - loss: -0.4572 - acc: 0.9935 - val_loss: -0.4767 - val_acc: 0.9913\n",
      "Epoch 1/10\n",
      "46/47 [============================>.] - ETA: 1s - loss: -0.3786 - acc: 0.9940\n",
      "New maximum F1 score: 0.8240058910162003 (before: 0.8214814814814815) Saving to model_lstm_germeval.1.h5\n",
      "47/47 [==============================] - 81s 2s/step - loss: -0.3786 - acc: 0.9940 - val_loss: -0.3722 - val_acc: 0.9914\n",
      "Epoch 2/10\n",
      "46/47 [============================>.] - ETA: 0s - loss: -0.3805 - acc: 0.9943\n",
      "New maximum F1 score: 0.8256712026480323 (before: 0.8240058910162003) Saving to model_lstm_germeval.1.h5\n",
      "47/47 [==============================] - 69s 1s/step - loss: -0.3806 - acc: 0.9943 - val_loss: -0.3739 - val_acc: 0.9914\n",
      "Epoch 3/10\n",
      "47/47 [==============================] - 69s 1s/step - loss: -0.3826 - acc: 0.9945 - val_loss: -0.3757 - val_acc: 0.9914\n",
      "Epoch 4/10\n",
      "47/47 [==============================] - 69s 1s/step - loss: -0.3846 - acc: 0.9945 - val_loss: -0.3773 - val_acc: 0.9914\n",
      "Epoch 5/10\n",
      "46/47 [============================>.] - ETA: 0s - loss: -0.3862 - acc: 0.9945\n",
      "New maximum F1 score: 0.8276243093922651 (before: 0.8256712026480323) Saving to model_lstm_germeval.1.h5\n",
      "47/47 [==============================] - 69s 1s/step - loss: -0.3862 - acc: 0.9945 - val_loss: -0.3791 - val_acc: 0.9915\n",
      "Epoch 6/10\n",
      "47/47 [==============================] - 70s 1s/step - loss: -0.3881 - acc: 0.9946 - val_loss: -0.3807 - val_acc: 0.9915\n",
      "Epoch 7/10\n",
      "47/47 [==============================] - 69s 1s/step - loss: -0.3900 - acc: 0.9948 - val_loss: -0.3822 - val_acc: 0.9914\n",
      "Epoch 8/10\n",
      "47/47 [==============================] - 68s 1s/step - loss: -0.3918 - acc: 0.9948 - val_loss: -0.3841 - val_acc: 0.9916\n",
      "Epoch 9/10\n",
      "47/47 [==============================] - 67s 1s/step - loss: -0.3937 - acc: 0.9949 - val_loss: -0.3856 - val_acc: 0.9915\n",
      "Epoch 10/10\n",
      "47/47 [==============================] - 66s 1s/step - loss: -0.3952 - acc: 0.9947 - val_loss: -0.3873 - val_acc: 0.9915\n",
      "Run 2\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 52)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 52, 32) 10688       char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, None, 100)    33200       char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, None, 408)    0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, None, 400)    974400      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "crf (CRF)                       (None, None, 26)     11154       bidirectional_6[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,029,506\n",
      "Trainable params: 1,029,442\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: 0.0457 - acc: 0.9839\n",
      "New maximum F1 score: 0.7615191825718142 (before: 0) Saving to model_lstm_germeval.2.h5\n",
      "1500/1500 [==============================] - 580s 387ms/step - loss: 0.0457 - acc: 0.9839 - val_loss: 0.0036 - val_acc: 0.9890\n",
      "Epoch 2/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.0193 - acc: 0.9887\n",
      "New maximum F1 score: 0.7785310734463277 (before: 0.7615191825718142) Saving to model_lstm_germeval.2.h5\n",
      "1500/1500 [==============================] - 571s 381ms/step - loss: -0.0193 - acc: 0.9887 - val_loss: -0.0468 - val_acc: 0.9896\n",
      "Epoch 3/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.0735 - acc: 0.9900\n",
      "New maximum F1 score: 0.808390022675737 (before: 0.7785310734463277) Saving to model_lstm_germeval.2.h5\n",
      "1500/1500 [==============================] - 568s 379ms/step - loss: -0.0736 - acc: 0.9900 - val_loss: -0.1013 - val_acc: 0.9909\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 568s 379ms/step - loss: -0.1291 - acc: 0.9908 - val_loss: -0.1553 - val_acc: 0.9910\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.1844 - acc: 0.9914\n",
      "New maximum F1 score: 0.8160962767957879 (before: 0.808390022675737) Saving to model_lstm_germeval.2.h5\n",
      "1500/1500 [==============================] - 572s 381ms/step - loss: -0.1844 - acc: 0.9914 - val_loss: -0.2101 - val_acc: 0.9911\n",
      "Epoch 6/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.2395 - acc: 0.9920\n",
      "New maximum F1 score: 0.8195684523809526 (before: 0.8160962767957879) Saving to model_lstm_germeval.2.h5\n",
      "1500/1500 [==============================] - 571s 381ms/step - loss: -0.2395 - acc: 0.9920 - val_loss: -0.2636 - val_acc: 0.9915\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 575s 383ms/step - loss: -0.2943 - acc: 0.9926 - val_loss: -0.3160 - val_acc: 0.9908\n",
      "Epoch 8/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.3488 - acc: 0.9929\n",
      "New maximum F1 score: 0.820959081651546 (before: 0.8195684523809526) Saving to model_lstm_germeval.2.h5\n",
      "1500/1500 [==============================] - 587s 391ms/step - loss: -0.3488 - acc: 0.9929 - val_loss: -0.3700 - val_acc: 0.9912\n",
      "Epoch 9/10\n",
      " 265/1500 [====>.........................] - ETA: 7:52 - loss: -0.3821 - acc: 0.9934"
     ]
    }
   ],
   "source": [
    "f = open('results_lstm_germeval.txt', 'a')\n",
    "for run_i in range(10):\n",
    "    print(\"Run \" + str(run_i))\n",
    "    \n",
    "    tmp_model_filename = 'model_lstm_germeval.' + str(run_i) + '.h5'\n",
    "\n",
    "    history = utils.F1History(tmp_model_filename, devSet=devSentences)\n",
    "\n",
    "    model = models.get_model_lstm_v2()\n",
    "    model.fit_generator(\n",
    "        utils.NerSequence(trainSentences, shuffle_data=True, batch_size=16), \n",
    "        validation_data = utils.NerSequence(devSentences, batch_size=512), \n",
    "        epochs = 10, callbacks = [history]\n",
    "    )\n",
    "    \n",
    "    model.load_weights(tmp_model_filename)\n",
    "    \n",
    "    model.fit_generator(\n",
    "        utils.NerSequence(trainSentences, shuffle_data=True, batch_size=512), \n",
    "        validation_data = utils.NerSequence(devSentences, batch_size=512), \n",
    "        epochs = 10, callbacks = [history]\n",
    "    )\n",
    "    \n",
    "    model.load_weights(tmp_model_filename)\n",
    "    \n",
    "    true_labels, pred_labels = utils.predict_sequences(model, testSentences)\n",
    "    \n",
    "    pre, rec, f1 = compute_f1(pred_labels, true_labels, models.idx2Label)\n",
    "    f.write(str(run_i) + \"\\t\" + str(pre) + \"\\t\" + str(rec) +  \"\\t\" + str(f1))\n",
    "    f.write(\"\\n\")\n",
    "    f.flush()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, json\n",
    "# copy file for best run\n",
    "shutil.copyfile('tmp_3cnn_bi-lstm.h5', '../models/final_model_germeval_outer.h5')\n",
    "with open(\"../models/final_model_germeval.indexes\", \"w\") as f:\n",
    "    json.dump([models.idx2Label, models.label2Idx, models.char2Idx, models.case2Idx], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_contrib.layers import CRF\n",
    "def create_custom_objects():\n",
    "    instanceHolder = {\"instance\": None}\n",
    "    class ClassWrapper(CRF):\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            instanceHolder[\"instance\"] = self\n",
    "            super(ClassWrapper, self).__init__(*args, **kwargs)\n",
    "    def loss(*args):\n",
    "        method = getattr(instanceHolder[\"instance\"], \"loss_function\")\n",
    "        return method(*args)\n",
    "    def accuracy(*args):\n",
    "        method = getattr(instanceHolder[\"instance\"], \"accuracy\")\n",
    "        return method(*args)\n",
    "    return {\"ClassWrapper\": ClassWrapper ,\"CRF\": ClassWrapper, \"loss\": loss, \"accuracy\":accuracy}\n",
    "\n",
    "finalmodel = load_model('../models/final_model_germeval_outer.h5', custom_objects=create_custom_objects())\n",
    "true_labels, pred_labels = utils.predict_sequences(finalmodel, testSentences)\n",
    "print(compute_f1(pred_labels, true_labels, models.idx2Label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('germeval_output.tsv', 'w', encoding='UTF-8')\n",
    "for i_sent, sent in enumerate(testSentences):\n",
    "    for i_tok, tok in enumerate(sent):\n",
    "        if tok[0] == 'PADDING_TOKEN':\n",
    "            break\n",
    "        correctlabel = models.idx2Label[true_labels[i_sent][i_tok]]\n",
    "        guessedlabel = models.idx2Label[pred_labels[i_sent][i_tok]]\n",
    "        line = \"\\t\".join([str(i_tok+1), tok[0], correctlabel, correctlabel, guessedlabel, guessedlabel])\n",
    "        f.write(line + '\\n')\n",
    "    f.write('\\n')\n",
    "f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
