{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gwiedemann/miniconda3/envs/kerasenv/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import fastText\n",
    "\n",
    "from validation import compute_f1\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "\n",
    "import models\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000\n",
      "2200\n",
      "5100\n"
     ]
    }
   ],
   "source": [
    "trainSentences = utils.get_sentences_germeval('../data/GermEVAL/NER-de-train.tsv')\n",
    "devSentences = utils.get_sentences_germeval('../data/GermEVAL/NER-de-dev.tsv')\n",
    "testSentences = utils.get_sentences_germeval('../data/GermEVAL/NER-de-test.tsv')\n",
    "\n",
    "# trainSentences = get_sentences('../data/CONLL/deu/deu_utf.train')\n",
    "# devSentences = get_sentences('../data/CONLL/deu/deu_utf.testa')\n",
    "# testSentences = get_sentences('../data/CONLL/deu/deu_utf.testb')\n",
    "\n",
    "print(len(trainSentences))\n",
    "print(len(devSentences))\n",
    "print(len(testSentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1951', 'O'], ['bis', 'O'], ['1953', 'O'], ['wurde', 'O'], ['der', 'O'], ['nördliche', 'O'], ['Teil', 'O'], ['als', 'O'], ['Jugendburg', 'O'], ['des', 'O'], ['Kolpingwerkes', 'B-OTH'], ['gebaut', 'O'], ['.', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(testSentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelSet = set()\n",
    "characters= set()\n",
    "models.max_sequence_length = 0\n",
    "\n",
    "for dataset in [trainSentences, devSentences, testSentences]:\n",
    "    for sentence in dataset:\n",
    "        for word, label in sentence:\n",
    "            for char in word:\n",
    "                characters.add(char)\n",
    "            labelSet.add(label)\n",
    "        if len(sentence) > models.max_sequence_length:\n",
    "            models.max_sequence_length = len(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "print(len(labelSet))\n",
    "print(models.max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# :: Create a mapping for the labels ::\n",
    "models.label2Idx = {\"PADDING_TOKEN\":0}\n",
    "for label in labelSet:\n",
    "    models.label2Idx[label] = len(models.label2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-OTH': 2, 'I-PER': 5, 'I-ORG': 24, 'I-OTH': 6, 'B-PERderiv': 22, 'B-OTHpart': 17, 'I-ORGpart': 7, 'B-PER': 8, 'I-LOC': 16, 'B-OTHderiv': 14, 'B-LOC': 19, 'I-OTHderiv': 25, 'I-OTHpart': 20, 'B-LOCderiv': 9, 'B-ORGpart': 21, 'B-PERpart': 10, 'I-ORGderiv': 11, 'O': 1, 'I-PERderiv': 12, 'B-ORG': 15, 'B-ORGderiv': 23, 'I-LOCpart': 4, 'I-PERpart': 13, 'B-LOCpart': 18, 'PADDING_TOKEN': 0, 'I-LOCderiv': 3}\n"
     ]
    }
   ],
   "source": [
    "print(models.label2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# :: Hard coded case lookup ::\n",
    "models.case2Idx = {'PADDING_TOKEN':0, 'numeric': 1, 'allLower':2, 'allUpper':3, 'initialUpper':4, 'other':5, 'mainly_numeric':6, 'contains_digit': 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'allLower': 2, 'initialUpper': 4, 'allUpper': 3, 'mainly_numeric': 6, 'numeric': 1, 'PADDING_TOKEN': 0, 'contains_digit': 7, 'other': 5}\n"
     ]
    }
   ],
   "source": [
    "print(models.case2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(trainSentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Schartau', 'B-PER'], ['sagte', 'O'], ['dem', 'O'], ['\"', 'O'], ['Tagesspiegel', 'B-ORG'], ['\"', 'O'], ['vom', 'O'], ['Freitag', 'O'], [',', 'O'], ['Fischer', 'B-PER'], ['sei', 'O'], ['\"', 'O'], ['in', 'O'], ['einer', 'O'], ['Weise', 'O'], ['aufgetreten', 'O'], [',', 'O'], ['die', 'O'], ['alles', 'O'], ['andere', 'O'], ['als', 'O'], ['überzeugend', 'O'], ['war', 'O'], ['\"', 'O'], ['.', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(trainSentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'`': 5, 'D': 6, 'ħ': 7, '殿': 8, '”': 9, 'E': 10, '&': 11, '算': 12, '±': 184, '©': 14, 'f': 15, ')': 17, 'N': 18, 'ß': 20, 'q': 21, 'ż': 27, 'τ': 25, 'M': 24, 'ı': 284, 'G': 30, '士': 31, '@': 32, 'ê': 34, 'ῦ': 39, 'ь': 37, '별': 188, 'õ': 40, '\\u200e': 41, '동': 310, 'ú': 42, '?': 43, '\"': 45, 'û': 47, 'ε': 49, 'М': 50, 'ς': 190, '.': 51, '佐': 296, 'ν': 53, 'Þ': 67, 'j': 54, 'π': 19, 'ă': 292, 'ế': 57, 'č': 56, 'ο': 58, '術': 59, '造': 60, 'є': 68, '…': 62, 'ά': 293, '<W>': 3, 'к': 311, 'â': 63, '»': 64, 'ó': 66, '0': 69, 'أ': 13, '«': 209, 'ā': 71, 'V': 72, '/': 73, 'ğ': 75, 'и': 332, '4': 76, 'ɨ': 78, '⊃': 87, 'а': 79, '‘': 80, 'л': 83, 'п': 84, ']': 129, 'm': 85, 'd': 88, 'Ł': 89, 'ا': 90, 'в': 91, '≤': 245, '!': 316, 'T': 16, 'í': 93, 'б': 22, ';': 94, 'F': 95, 'ι': 96, '_': 70, 'B': 97, 'n': 98, '—': 99, 'ю': 100, '→': 101, 'Ž': 131, 'J': 103, '<': 105, 'H': 106, 'β': 107, '¸': 108, 'ś': 26, 'ź': 110, '$': 111, 'İ': 112, 'ḳ': 331, 'æ': 28, '(': 113, '–': 114, 'C': 115, 'ب': 116, 'UNKNOWN': 333, 'Ш': 254, 'ḫ': 124, '8': 119, 'ن': 123, '#': 44, 'U': 74, '³': 127, 'Ż': 125, 'ń': 126, '\\x9a': 130, '‚': 128, 'é': 305, '[': 132, 'Š': 259, 'х': 133, '\\xad': 134, 'p': 135, '鷹': 139, 'ü': 137, '¹': 138, 'ệ': 140, 'ĩ': 321, '‹': 142, '妃': 144, 'î': 145, 'É': 146, 'Ġ': 147, 'У': 148, 'έ': 149, 'x': 150, '3': 77, 'ý': 157, 'Т': 160, '章': 158, 'ж': 38, '九': 159, 'ī': 141, 'à': 164, 'z': 163, 'ť': 165, 'Ä': 166, 'ċ': 167, 'u': 168, 'Е': 170, '⋅': 171, 'ό': 172, '鶴': 173, 'X': 81, 'φ': 175, '2': 82, 'й': 143, 'Œ': 86, 'υ': 179, 'ä': 180, 'н': 181, 'ą': 314, '柯': 252, 'Λ': 182, '²': 183, 'è': 33, 'A': 185, 'т': 221, '’': 186, 'O': 187, 'Z': 189, 'a': 192, '§': 216, 'Y': 193, 'с': 194, 'ъ': 264, 'ŏ': 29, 'з': 36, 'á': 197, '%': 198, '太': 202, 'Á': 200, '−': 23, '\\x80': 205, 'ǒ': 207, '›': 298, 'ě': 153, 'Q': 210, 'ψ': 211, '南': 212, 'г': 152, 'о': 213, 'Â': 92, '5': 215, 'ô': 151, 'ы': 218, 'R': 262, 'À': 219, 'ū': 155, '·': 224, '\\x92': 223, 'Ц': 225, '¤': 226, ':': 220, 'ї': 154, 'я': 229, 'S': 288, '~': 230, 'И': 327, 'o': 232, '´': 156, 'L': 233, 'K': 234, 'ø': 120, 'η': 217, '″': 222, '>': 196, '}': 236, 'Ø': 237, '\\x99': 238, 'д': 239, '守': 240, '대': 313, '‐': 241, 'ę': 242, '\\x94': 243, '別': 244, 'С': 195, '東': 52, 'Î': 214, '=': 201, '台': 246, \"'\": 162, 'å': 247, 'W': 248, '-': 46, '9': 249, 'ض': 250, '+': 251, '\\x96': 253, '≘': 227, 'ö': 255, 'c': 121, 'р': 256, '루': 257, '×': 317, '“': 258, '貴': 268, 'v': 48, ',': 261, '½': 263, 'κ': 269, 'Å': 265, 'ρ': 266, '„': 319, 'λ': 320, '°': 102, 'ō': 270, 'Č': 231, 'y': 169, 'I': 272, 'В': 273, '1': 275, 'ł': 271, 'µ': 277, 'g': 300, 'σ': 279, 'Ö': 280, 'ラ': 312, 'α': 323, '</S>': 2, 't': 104, 'ř': 282, '£': 283, 'ð': 274, 'Ş': 203, 'オ': 285, '冲': 286, 'h': 287, 'Π': 294, 'š': 291, 'b': 290, '傳': 325, '李': 276, 'γ': 295, 'l': 174, 'Æ': 297, '6': 118, '寝': 267, '†': 330, '<S>': 1, 'ņ': 299, '\\x95': 55, 'P': 301, 'i': 302, 's': 303, 'ã': 306, '€': 308, 'ʻ': 309, 'ć': 176, '懿': 208, 'П': 109, 'ñ': 199, '▪': 177, 'ē': 191, 'ő': 235, 'k': 304, '公': 178, 'Ü': 315, '7': 260, '樓': 278, '博': 206, 'ي': 161, 'r': 289, '*': 35, 'у': 318, 'Л': 61, 'È': 204, 'ë': 65, 'м': 322, 'ـ': 281, 'ň': 324, 'ş': 136, 'w': 326, '</W>': 4, 'e': 328, 'е': 329, 'ç': 122, '학': 228, 'ž': 307, 'PADDING_TOKEN': 0, 'œ': 117}\n"
     ]
    }
   ],
   "source": [
    "models.char2Idx={\"PADDING_TOKEN\":0, \"<S>\":1, \"</S>\":2, \"<W>\":3, \"</W>\":4}\n",
    "for char in characters:\n",
    "    models.char2Idx[char] = len(models.char2Idx)\n",
    "models.char2Idx['UNKNOWN'] = len(models.char2Idx)\n",
    "print(models.char2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Schartau', 'B-PER'], ['sagte', 'O'], ['dem', 'O'], ['\"', 'O'], ['Tagesspiegel', 'B-ORG'], ['\"', 'O'], ['vom', 'O'], ['Freitag', 'O'], [',', 'O'], ['Fischer', 'B-PER'], ['sei', 'O'], ['\"', 'O'], ['in', 'O'], ['einer', 'O'], ['Weise', 'O'], ['aufgetreten', 'O'], [',', 'O'], ['die', 'O'], ['alles', 'O'], ['andere', 'O'], ['als', 'O'], ['überzeugend', 'O'], ['war', 'O'], ['\"', 'O'], ['.', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(trainSentences[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.ft = fastText.load_model(\"../embeddings/wiki.de.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "print(models.nb_embedding_dims)\n",
    "print(len(trainSentences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "models.idx2Label = {v: k for k, v in models.label2Idx.items()}\n",
    "print(len(models.label2Idx))\n",
    "print(len(models.idx2Label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models' from '/home/gwiedemann/microNER/scripts/models.py'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 52)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 52, 32) 10688       char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_10 (TimeDistri (None, None, 52, 32) 3104        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_13 (TimeDistri (None, None, 52, 32) 4128        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_16 (TimeDistri (None, None, 52, 32) 5152        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_11 (TimeDistri (None, None, 17, 32) 0           time_distributed_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_14 (TimeDistri (None, None, 17, 32) 0           time_distributed_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_17 (TimeDistri (None, None, 17, 32) 0           time_distributed_16[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_12 (TimeDistri (None, None, 544)    0           time_distributed_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_15 (TimeDistri (None, None, 544)    0           time_distributed_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_18 (TimeDistri (None, None, 544)    0           time_distributed_17[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, 1940)   0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_12[0][0]        \n",
      "                                                                 time_distributed_15[0][0]        \n",
      "                                                                 time_distributed_18[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, None, 400)    3425600     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_19 (TimeDistri (None, None, 26)     10426       bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "crf (CRF)                       (None, None, 26)     1430        time_distributed_19[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 3,460,592\n",
      "Trainable params: 3,460,528\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tmp_model_filename = 'tmp_3cnn_bi-lstm_mp.h5'\n",
    "# checkpoint = ModelCheckpoint(tmp_model_filename, verbose=1, save_best_only = True, monitor = 'val_acc')\n",
    "history = utils.F1History(tmp_model_filename, devSet = devSentences)\n",
    "model = models.get_model_3cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# importlib.reload(utils)\n",
    "#cprint(models.max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0783 - acc: 0.9791\n",
      "New maximum F1 score: 0.7373529960798955 (before: 0) Saving to tmp_3cnn_bi-lstm_mp.h5\n",
      "750/750 [==============================] - 277s 369ms/step - loss: 0.0782 - acc: 0.9791 - val_loss: 0.0262 - val_acc: 0.9881\n",
      "Epoch 2/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0157 - acc: 0.9881\n",
      "New maximum F1 score: 0.7723561799886082 (before: 0.7373529960798955) Saving to tmp_3cnn_bi-lstm_mp.h5\n",
      "750/750 [==============================] - 244s 325ms/step - loss: 0.0157 - acc: 0.9881 - val_loss: 0.0022 - val_acc: 0.9890\n",
      "Epoch 3/10\n",
      "156/750 [=====>........................] - ETA: 2:59 - loss: -5.8808e-04 - acc: 0.9892"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    utils.NerSequence(trainSentences, shuffle_data=True, batch_size=32), \n",
    "    validation_data = utils.NerSequence(devSentences, batch_size=256), \n",
    "    epochs = 10, callbacks = [history]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.acc)\n",
    "print(history.f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(tmp_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    utils.NerSequence(trainSentences, shuffle_data=True, batch_size=2048), \n",
    "    validation_data = utils.NerSequence(devSentences, batch_size=256), \n",
    "    epochs = 5, callbacks = [history]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels, pred_labels = utils.predict_sequences(model, testSentences)\n",
    "print(compute_f1(pred_labels, true_labels, models.idx2Label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('results_3cnn.txt', 'a')\n",
    "for run_i in range(1,10):\n",
    "    print(\"Run \" + str(run_i))\n",
    "    \n",
    "    tmp_model_filename = 'tmp_generator_NER_3cnn_best.' + str(run_i) + '.h5'\n",
    "\n",
    "    history = utils.F1History(tmp_model_filename, devSet=devSentences)\n",
    "\n",
    "    model = models.get_model_3cnn()\n",
    "    model.fit_generator(\n",
    "        utils.NerSequence(trainSentences, shuffle_data=True, batch_size=32), \n",
    "        validation_data = utils.NerSequence(devSentences, batch_size=256), \n",
    "        epochs = 10, callbacks = [history]\n",
    "    )\n",
    "    \n",
    "    model.load_weights(tmp_model_filename)\n",
    "    \n",
    "    model.fit_generator(\n",
    "        utils.NerSequence(trainSentences, shuffle_data=True, batch_size=2048), \n",
    "        validation_data = utils.NerSequence(devSentences, batch_size=256), \n",
    "        epochs = 10, callbacks = [history]\n",
    "    )\n",
    "    \n",
    "    model.load_weights(tmp_model_filename)\n",
    "    \n",
    "    true_labels, pred_labels = utils.predict_sequences(model, testSentences)\n",
    "    \n",
    "    pre, rec, f1 = compute_f1(pred_labels, true_labels, models.idx2Label)\n",
    "    f.write(str(run_i) + \"\\t\" + str(pre) + \"\\t\" + str(rec) +  \"\\t\" + str(f1))\n",
    "    f.write(\"\\n\")\n",
    "    f.flush()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, json\n",
    "# copy file for best run\n",
    "shutil.copyfile('tmp_3cnn_bi-lstm.h5', '../models/final_model_germeval_outer.h5')\n",
    "with open(\"../models/final_model_germeval.indexes\", \"w\") as f:\n",
    "    json.dump([models.idx2Label, models.label2Idx, models.char2Idx, models.case2Idx], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_contrib.layers import CRF\n",
    "def create_custom_objects():\n",
    "    instanceHolder = {\"instance\": None}\n",
    "    class ClassWrapper(CRF):\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            instanceHolder[\"instance\"] = self\n",
    "            super(ClassWrapper, self).__init__(*args, **kwargs)\n",
    "    def loss(*args):\n",
    "        method = getattr(instanceHolder[\"instance\"], \"loss_function\")\n",
    "        return method(*args)\n",
    "    def accuracy(*args):\n",
    "        method = getattr(instanceHolder[\"instance\"], \"accuracy\")\n",
    "        return method(*args)\n",
    "    return {\"ClassWrapper\": ClassWrapper ,\"CRF\": ClassWrapper, \"loss\": loss, \"accuracy\":accuracy}\n",
    "\n",
    "finalmodel = load_model('../models/final_model_germeval_outer.h5', custom_objects=create_custom_objects())\n",
    "true_labels, pred_labels = utils.predict_sequences(finalmodel, testSentences)\n",
    "print(compute_f1(pred_labels, true_labels, models.idx2Label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('germeval_output.tsv', 'w', encoding='UTF-8')\n",
    "for i_sent, sent in enumerate(testSentences):\n",
    "    for i_tok, tok in enumerate(sent):\n",
    "        if tok[0] == 'PADDING_TOKEN':\n",
    "            break\n",
    "        correctlabel = models.idx2Label[true_labels[i_sent][i_tok]]\n",
    "        guessedlabel = models.idx2Label[pred_labels[i_sent][i_tok]]\n",
    "        line = \"\\t\".join([str(i_tok+1), tok[0], correctlabel, correctlabel, guessedlabel, guessedlabel])\n",
    "        f.write(line + '\\n')\n",
    "    f.write('\\n')\n",
    "f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
