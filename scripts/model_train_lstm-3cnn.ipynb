{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gwiedemann/miniconda3/envs/kerasenv/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import fastText\n",
    "\n",
    "from validation import compute_f1\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "\n",
    "import models\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000\n",
      "2200\n",
      "5100\n"
     ]
    }
   ],
   "source": [
    "trainSentences = utils.get_sentences_germeval('../data/GermEVAL/NER-de-train.tsv')\n",
    "devSentences = utils.get_sentences_germeval('../data/GermEVAL/NER-de-dev.tsv')\n",
    "testSentences = utils.get_sentences_germeval('../data/GermEVAL/NER-de-test.tsv')\n",
    "\n",
    "# trainSentences = get_sentences('../data/CONLL/deu/deu_utf.train')\n",
    "# devSentences = get_sentences('../data/CONLL/deu/deu_utf.testa')\n",
    "# testSentences = get_sentences('../data/CONLL/deu/deu_utf.testb')\n",
    "\n",
    "print(len(trainSentences))\n",
    "print(len(devSentences))\n",
    "print(len(testSentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1951', 'O'], ['bis', 'O'], ['1953', 'O'], ['wurde', 'O'], ['der', 'O'], ['nördliche', 'O'], ['Teil', 'O'], ['als', 'O'], ['Jugendburg', 'O'], ['des', 'O'], ['Kolpingwerkes', 'B-OTH'], ['gebaut', 'O'], ['.', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(testSentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelSet = set()\n",
    "characters= set()\n",
    "models.max_sequence_length = 0\n",
    "\n",
    "for dataset in [trainSentences, devSentences, testSentences]:\n",
    "    for sentence in dataset:\n",
    "        for word, label in sentence:\n",
    "            for char in word:\n",
    "                characters.add(char)\n",
    "            labelSet.add(label)\n",
    "        if len(sentence) > models.max_sequence_length:\n",
    "            models.max_sequence_length = len(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "print(len(labelSet))\n",
    "print(models.max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# :: Create a mapping for the labels ::\n",
    "models.label2Idx = {\"PADDING_TOKEN\":0}\n",
    "for label in labelSet:\n",
    "    models.label2Idx[label] = len(models.label2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-ORGderiv': 1, 'B-LOCpart': 12, 'I-ORGderiv': 14, 'I-LOCderiv': 2, 'I-ORGpart': 15, 'B-LOC': 3, 'B-PER': 4, 'I-OTHpart': 16, 'B-PERderiv': 17, 'B-PERpart': 18, 'B-ORGpart': 19, 'I-PER': 5, 'I-PERpart': 10, 'I-LOCpart': 20, 'B-LOCderiv': 21, 'I-ORG': 6, 'I-OTH': 22, 'B-OTHpart': 7, 'O': 23, 'B-OTH': 8, 'PADDING_TOKEN': 0, 'B-ORG': 24, 'I-LOC': 25, 'B-OTHderiv': 13, 'I-OTHderiv': 9, 'I-PERderiv': 11}\n"
     ]
    }
   ],
   "source": [
    "print(models.label2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# :: Hard coded case lookup ::\n",
    "models.case2Idx = {'PADDING_TOKEN':0, 'numeric': 1, 'allLower':2, 'allUpper':3, 'initialUpper':4, 'other':5, 'mainly_numeric':6, 'contains_digit': 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mainly_numeric': 6, 'PADDING_TOKEN': 0, 'numeric': 1, 'contains_digit': 7, 'allUpper': 3, 'initialUpper': 4, 'allLower': 2, 'other': 5}\n"
     ]
    }
   ],
   "source": [
    "print(models.case2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(trainSentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Schartau', 'B-PER'], ['sagte', 'O'], ['dem', 'O'], ['\"', 'O'], ['Tagesspiegel', 'B-ORG'], ['\"', 'O'], ['vom', 'O'], ['Freitag', 'O'], [',', 'O'], ['Fischer', 'B-PER'], ['sei', 'O'], ['\"', 'O'], ['in', 'O'], ['einer', 'O'], ['Weise', 'O'], ['aufgetreten', 'O'], [',', 'O'], ['die', 'O'], ['alles', 'O'], ['andere', 'O'], ['als', 'O'], ['überzeugend', 'O'], ['war', 'O'], ['\"', 'O'], ['.', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(trainSentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2': 1, 'И': 2, 'ħ': 3, ':': 4, 'v': 5, '대': 9, 'R': 8, 'ň': 10, '-': 11, 'č': 244, 'Ш': 302, 'Ø': 12, 'ō': 13, '§': 15, 'Е': 16, 'G': 17, 'u': 247, 'Å': 18, '”': 19, '·': 281, 'J': 20, 'ж': 22, 'ź': 23, '⋅': 24, 'ý': 188, 'p': 25, '\\x9a': 28, '«': 218, 'Ц': 29, '‘': 30, '9': 115, 'å': 260, 'Λ': 249, 'ê': 31, '南': 33, '!': 320, '4': 6, 'æ': 36, '懿': 37, '李': 7, '}': 38, 'ρ': 40, 'K': 41, ',': 42, '柯': 43, 'σ': 45, 'в': 46, 'H': 294, 'œ': 49, 'Þ': 48, 'р': 50, 'ῦ': 52, 'í': 53, '‐': 54, 'õ': 55, '−': 56, 'Ż': 58, 'ñ': 59, '九': 60, ']': 61, 'ă': 62, '¤': 63, 'φ': 64, 'ю': 65, '\\x96': 66, '別': 67, '@': 68, 'É': 177, '$': 69, 'Ö': 283, '©': 70, 'и': 328, 'l': 71, 'г': 72, 'з': 73, 'V': 74, 'ḫ': 14, 'ç': 78, 'â': 77, 'ї': 79, 'W': 80, '鷹': 81, 'ő': 83, 'Á': 84, 'w': 86, 'd': 87, 'Ş': 89, 'ã': 233, 'ä': 90, '*': 91, 'Y': 92, 'È': 181, 'Т': 126, '+': 27, '鶴': 189, '£': 96, '守': 100, 'F': 97, 'Ä': 98, 'e': 99, '<': 101, 'с': 103, 'è': 104, 'ы': 105, 'û': 106, '`': 107, 'ą': 288, 'Î': 135, 'Č': 111, '6': 110, '_': 112, '³': 113, '造': 114, 'л': 116, 'n': 117, 'ā': 118, 'PADDING_TOKEN': 0, 'λ': 119, 's': 120, '術': 121, 'ν': 122, 'Š': 21, 'γ': 123, 'オ': 124, 'U': 125, 'ú': 289, 'ن': 128, 'UNKNOWN': 329, '—': 129, '\\u200e': 130, 'N': 131, 'е': 132, '冲': 75, 'п': 134, '\\x95': 137, '妃': 140, 'h': 139, '‚': 143, 'є': 144, 'ě': 324, '≤': 145, '7': 146, '루': 150, '士': 148, 'ʻ': 149, '.': 26, 'ċ': 151, 'У': 152, 'ö': 153, 'O': 154, 'ē': 155, '貴': 280, 'С': 157, '~': 158, 'ņ': 159, '†': 160, 'υ': 161, '°': 162, 'İ': 164, 'ř': 165, 'ḳ': 166, 'ü': 196, '[': 167, '…': 286, 'q': 127, '殿': 168, '公': 169, '×': 170, '별': 172, 'E': 133, '>': 173, '€': 82, 'o': 198, 'Ġ': 174, 'ô': 175, 'M': 176, 'ø': 178, 'ć': 238, 'ð': 171, 'ę': 301, '傳': 180, 'ا': 85, 'о': 182, 'а': 183, 'Q': 184, 'Æ': 185, 'é': 186, '5': 187, '¹': 190, 'β': 136, '▪': 250, 'j': 264, 'ĩ': 191, 'м': 192, 'ł': 193, '0': 194, 'π': 195, '⊃': 88, 'z': 197, 'T': 32, 'ъ': 201, 'Л': 202, 'm': 319, 'ž': 138, 'х': 204, '/': 205, 'ż': 207, 'C': 208, 'ラ': 209, 'B': 203, '3': 210, 'ض': 57, '±': 211, '佐': 212, '#': 273, 'أ': 213, \"'\": 141, '=': 215, '太': 216, '„': 34, 'š': 219, 'ς': 220, 'ş': 221, '›': 223, 'ب': 305, '²': 225, ')': 35, 'ı': 245, '\\x94': 227, 'М': 93, '寝': 228, 'Â': 229, 'I': 230, 'ế': 231, 'П': 232, '\\xad': 258, '\"': 234, 'Π': 235, 'Ł': 236, 'έ': 255, 'ó': 237, 'б': 147, 'X': 239, '–': 240, '½': 263, 'т': 241, '\\x80': 242, '’': 243, 'ـ': 179, 'x': 246, 'ε': 248, '8': 39, 'ό': 251, '東': 299, '»': 252, 'À': 314, '\\x99': 265, '\\x92': 253, 'D': 254, 'ť': 256, 'ń': 257, 'g': 95, 'A': 259, 'µ': 76, '‹': 317, 'ь': 261, 't': 262, 'y': 295, '台': 44, '학': 266, 'á': 267, 'ŏ': 102, 'à': 268, '章': 304, 'α': 322, 'ū': 269, 'В': 270, 'я': 271, ';': 199, '(': 274, 'ệ': 275, '樓': 214, '→': 276, 'Ü': 277, 'ά': 313, 'b': 278, 'ǒ': 279, 'L': 156, '%': 282, '″': 47, '1': 284, 'c': 285, 'f': 217, 'ß': 296, '동': 226, 'й': 290, 'н': 291, 'Ž': 292, 'r': 293, 'τ': 297, 'î': 298, '博': 272, 'k': 300, 'ي': 108, 'ī': 303, 'ο': 222, 'ψ': 306, 'i': 326, '?': 307, 'Œ': 308, 'ɨ': 309, 'κ': 224, 'S': 310, 'у': 311, 'Z': 312, 'a': 109, '算': 315, '≘': 316, 'η': 94, '“': 318, 'ğ': 206, '¸': 287, 'д': 321, 'P': 323, 'ś': 51, 'ι': 325, 'ë': 163, 'к': 142, '´': 327, '&': 200}\n"
     ]
    }
   ],
   "source": [
    "models.char2Idx={\"PADDING_TOKEN\":0}\n",
    "for char in characters:\n",
    "    models.char2Idx[char] = len(models.char2Idx)\n",
    "models.char2Idx['UNKNOWN'] = len(models.char2Idx)\n",
    "print(models.char2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Schartau', 'B-PER'], ['sagte', 'O'], ['dem', 'O'], ['\"', 'O'], ['Tagesspiegel', 'B-ORG'], ['\"', 'O'], ['vom', 'O'], ['Freitag', 'O'], [',', 'O'], ['Fischer', 'B-PER'], ['sei', 'O'], ['\"', 'O'], ['in', 'O'], ['einer', 'O'], ['Weise', 'O'], ['aufgetreten', 'O'], [',', 'O'], ['die', 'O'], ['alles', 'O'], ['andere', 'O'], ['als', 'O'], ['überzeugend', 'O'], ['war', 'O'], ['\"', 'O'], ['.', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(trainSentences[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.ft = fastText.load_model(\"../embeddings/wiki.de.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "print(models.nb_embedding_dims)\n",
    "print(len(trainSentences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "models.idx2Label = {v: k for k, v in models.label2Idx.items()}\n",
    "print(len(models.label2Idx))\n",
    "print(len(models.idx2Label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models' from '/home/gwiedemann/microNER/scripts/models.py'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 52)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 52, 32) 10560       char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_22 (TimeDistri (None, None, 52, 32) 3104        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_24 (TimeDistri (None, None, 52, 32) 4128        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_26 (TimeDistri (None, None, 52, 32) 5152        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_23 (TimeDistri (None, None, 1, 32)  0           time_distributed_22[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_25 (TimeDistri (None, None, 1, 32)  0           time_distributed_24[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_27 (TimeDistri (None, None, 1, 32)  0           time_distributed_26[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, None, 1, 96)  0           time_distributed_23[0][0]        \n",
      "                                                                 time_distributed_25[0][0]        \n",
      "                                                                 time_distributed_27[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_28 (TimeDistri (None, None, 100)    58800       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, None, 408)    0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_28[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, None, 400)    974400      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_29 (TimeDistri (None, None, 26)     10426       bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "crf (CRF)                       (None, None, 26)     1430        time_distributed_29[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 1,068,064\n",
      "Trainable params: 1,068,000\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tmp_model_filename = 'tmp_lstm3cnn_bi-lstm.h5'\n",
    "# checkpoint = ModelCheckpoint(tmp_model_filename, verbose=1, save_best_only = True, monitor = 'val_acc')\n",
    "history = utils.F1History(tmp_model_filename, devSet = devSentences)\n",
    "model = models.get_model_3cnnlstm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/home/gwiedemann/microNER/scripts/utils.py'>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(utils)\n",
    "# print(models.max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.9572 - acc: 0.5923 - val_loss: 0.4937 - val_acc: 0.9075\n",
      "Epoch 2/5\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.4878 - acc: 0.8939 - val_loss: 0.2820 - val_acc: 0.9623\n",
      "Epoch 3/5\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.2636 - acc: 0.9603 - val_loss: 0.2433 - val_acc: 0.9598\n",
      "Epoch 4/5\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.2360 - acc: 0.9559 - val_loss: 0.2228 - val_acc: 0.9636\n",
      "Epoch 5/5\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.2050 - acc: 0.9644 - val_loss: 0.2079 - val_acc: 0.9645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbaae78f6d8>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    utils.NerSequence(trainSentences[1:100], shuffle_data=True, batch_size=32), \n",
    "    validation_data = utils.NerSequence(devSentences[1:100], batch_size=256), \n",
    "    epochs = 5, callbacks = [history]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.acc)\n",
    "print(history.f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(tmp_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    utils.NerSequence(trainSentences[1:100], shuffle_data=True, batch_size=2048), \n",
    "    validation_data = utils.NerSequence(devSentences[1:100], batch_size=256), \n",
    "    epochs = 5, callbacks = [history]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels, pred_labels = utils.predict_sequences(model, testSentences)\n",
    "print(compute_f1(pred_labels, true_labels, models.idx2Label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 52)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 52, 32) 10560       char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_30 (TimeDistri (None, None, 52, 32) 3104        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_32 (TimeDistri (None, None, 52, 32) 4128        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_34 (TimeDistri (None, None, 52, 32) 5152        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_31 (TimeDistri (None, None, 1, 32)  0           time_distributed_30[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_33 (TimeDistri (None, None, 1, 32)  0           time_distributed_32[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_35 (TimeDistri (None, None, 1, 32)  0           time_distributed_34[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, None, 1, 96)  0           time_distributed_31[0][0]        \n",
      "                                                                 time_distributed_33[0][0]        \n",
      "                                                                 time_distributed_35[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_36 (TimeDistri (None, None, 100)    58800       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, None, 408)    0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_36[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, None, 400)    974400      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_37 (TimeDistri (None, None, 26)     10426       bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "crf (CRF)                       (None, None, 26)     1430        time_distributed_37[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 1,068,064\n",
      "Trainable params: 1,068,000\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: 0.0437 - acc: 0.9834\n",
      "New maximum F1 score: 0.75414206817749 (before: 0) Saving to tmp_lstm3cnn_bi-lstm.0.h5\n",
      "1500/1500 [==============================] - 432s 288ms/step - loss: 0.0436 - acc: 0.9834 - val_loss: -4.5148e-04 - val_acc: 0.9889\n",
      "Epoch 2/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.0223 - acc: 0.9888\n",
      "New maximum F1 score: 0.7869222096956032 (before: 0.75414206817749) Saving to tmp_lstm3cnn_bi-lstm.0.h5\n",
      "1500/1500 [==============================] - 424s 283ms/step - loss: -0.0223 - acc: 0.9888 - val_loss: -0.0503 - val_acc: 0.9903\n",
      "Epoch 3/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.0763 - acc: 0.9902\n",
      "New maximum F1 score: 0.7984976525821597 (before: 0.7869222096956032) Saving to tmp_lstm3cnn_bi-lstm.0.h5\n",
      "1500/1500 [==============================] - 428s 285ms/step - loss: -0.0764 - acc: 0.9902 - val_loss: -0.1038 - val_acc: 0.9905\n",
      "Epoch 4/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.1316 - acc: 0.9910\n",
      "New maximum F1 score: 0.8129536571747626 (before: 0.7984976525821597) Saving to tmp_lstm3cnn_bi-lstm.0.h5\n",
      "1500/1500 [==============================] - 413s 276ms/step - loss: -0.1317 - acc: 0.9910 - val_loss: -0.1583 - val_acc: 0.9911\n",
      "Epoch 5/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.1871 - acc: 0.9917\n",
      "New maximum F1 score: 0.8175675675675675 (before: 0.8129536571747626) Saving to tmp_lstm3cnn_bi-lstm.0.h5\n",
      "1500/1500 [==============================] - 411s 274ms/step - loss: -0.1871 - acc: 0.9917 - val_loss: -0.2129 - val_acc: 0.9913\n",
      "Epoch 6/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.2423 - acc: 0.9924\n",
      "New maximum F1 score: 0.819913256647181 (before: 0.8175675675675675) Saving to tmp_lstm3cnn_bi-lstm.0.h5\n",
      "1500/1500 [==============================] - 410s 274ms/step - loss: -0.2424 - acc: 0.9924 - val_loss: -0.2665 - val_acc: 0.9910\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 408s 272ms/step - loss: -0.2969 - acc: 0.9927 - val_loss: -0.3183 - val_acc: 0.9905\n",
      "Epoch 8/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.3516 - acc: 0.9931\n",
      "New maximum F1 score: 0.8253023255813954 (before: 0.819913256647181) Saving to tmp_lstm3cnn_bi-lstm.0.h5\n",
      "1500/1500 [==============================] - 405s 270ms/step - loss: -0.3517 - acc: 0.9931 - val_loss: -0.3724 - val_acc: 0.9916\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 401s 267ms/step - loss: -0.4060 - acc: 0.9935 - val_loss: -0.4262 - val_acc: 0.9916\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 405s 270ms/step - loss: -0.4598 - acc: 0.9936 - val_loss: -0.4797 - val_acc: 0.9914\n",
      "Epoch 1/10\n",
      "46/47 [============================>.] - ETA: 1s - loss: -0.3817 - acc: 0.9944\n",
      "New maximum F1 score: 0.8245937961595272 (before: 0) Saving to tmp_lstm3cnn_bi-lstm.0.h5\n",
      "47/47 [==============================] - 75s 2s/step - loss: -0.3817 - acc: 0.9944 - val_loss: -0.3745 - val_acc: 0.9916\n",
      "Epoch 2/10\n",
      "46/47 [============================>.] - ETA: 0s - loss: -0.3842 - acc: 0.9947\n",
      "New maximum F1 score: 0.8266419981498613 (before: 0.8245937961595272) Saving to tmp_lstm3cnn_bi-lstm.0.h5\n",
      "47/47 [==============================] - 64s 1s/step - loss: -0.3842 - acc: 0.9947 - val_loss: -0.3764 - val_acc: 0.9916\n",
      "Epoch 3/10\n",
      "46/47 [============================>.] - ETA: 0s - loss: -0.3863 - acc: 0.9949\n",
      "New maximum F1 score: 0.8292230669386241 (before: 0.8266419981498613) Saving to tmp_lstm3cnn_bi-lstm.0.h5\n",
      "47/47 [==============================] - 63s 1s/step - loss: -0.3863 - acc: 0.9949 - val_loss: -0.3782 - val_acc: 0.9917\n",
      "Epoch 4/10\n",
      "47/47 [==============================] - 65s 1s/step - loss: -0.3881 - acc: 0.9949 - val_loss: -0.3798 - val_acc: 0.9917\n",
      "Epoch 5/10\n",
      "47/47 [==============================] - 65s 1s/step - loss: -0.3901 - acc: 0.9950 - val_loss: -0.3814 - val_acc: 0.9917\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 64s 1s/step - loss: -0.3920 - acc: 0.9951 - val_loss: -0.3830 - val_acc: 0.9916\n",
      "Epoch 7/10\n",
      "46/47 [============================>.] - ETA: 0s - loss: -0.3938 - acc: 0.9952\n",
      "New maximum F1 score: 0.8297397769516729 (before: 0.8292230669386241) Saving to tmp_lstm3cnn_bi-lstm.0.h5\n",
      "47/47 [==============================] - 64s 1s/step - loss: -0.3938 - acc: 0.9952 - val_loss: -0.3847 - val_acc: 0.9918\n",
      "Epoch 8/10\n",
      "47/47 [==============================] - 65s 1s/step - loss: -0.3957 - acc: 0.9953 - val_loss: -0.3863 - val_acc: 0.9917\n",
      "Epoch 9/10\n",
      "47/47 [==============================] - 65s 1s/step - loss: -0.3974 - acc: 0.9953 - val_loss: -0.3878 - val_acc: 0.9916\n",
      "Epoch 10/10\n",
      "47/47 [==============================] - 64s 1s/step - loss: -0.3992 - acc: 0.9954 - val_loss: -0.3895 - val_acc: 0.9916\n",
      "Run 1\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 52)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 52, 32) 10560       char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_38 (TimeDistri (None, None, 52, 32) 3104        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_40 (TimeDistri (None, None, 52, 32) 4128        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_42 (TimeDistri (None, None, 52, 32) 5152        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_39 (TimeDistri (None, None, 1, 32)  0           time_distributed_38[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_41 (TimeDistri (None, None, 1, 32)  0           time_distributed_40[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_43 (TimeDistri (None, None, 1, 32)  0           time_distributed_42[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, None, 1, 96)  0           time_distributed_39[0][0]        \n",
      "                                                                 time_distributed_41[0][0]        \n",
      "                                                                 time_distributed_43[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_44 (TimeDistri (None, None, 100)    58800       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, None, 408)    0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_44[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, None, 400)    974400      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_45 (TimeDistri (None, None, 26)     10426       bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "crf (CRF)                       (None, None, 26)     1430        time_distributed_45[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 1,068,064\n",
      "Trainable params: 1,068,000\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.9835\n",
      "New maximum F1 score: 0.759344012204424 (before: 0) Saving to tmp_lstm3cnn_bi-lstm.1.h5\n",
      "1500/1500 [==============================] - 417s 278ms/step - loss: 0.0522 - acc: 0.9835 - val_loss: 0.0079 - val_acc: 0.9890\n",
      "Epoch 2/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.0152 - acc: 0.9889\n",
      "New maximum F1 score: 0.7804421131509928 (before: 0.759344012204424) Saving to tmp_lstm3cnn_bi-lstm.1.h5\n",
      "1500/1500 [==============================] - 403s 269ms/step - loss: -0.0152 - acc: 0.9889 - val_loss: -0.0434 - val_acc: 0.9902\n",
      "Epoch 3/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.0694 - acc: 0.9902\n",
      "New maximum F1 score: 0.8052095130237824 (before: 0.7804421131509928) Saving to tmp_lstm3cnn_bi-lstm.1.h5\n",
      "1500/1500 [==============================] - 403s 269ms/step - loss: -0.0694 - acc: 0.9902 - val_loss: -0.0969 - val_acc: 0.9906\n",
      "Epoch 4/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.1248 - acc: 0.9911\n",
      "New maximum F1 score: 0.8129536571747626 (before: 0.8052095130237824) Saving to tmp_lstm3cnn_bi-lstm.1.h5\n",
      "1500/1500 [==============================] - 406s 271ms/step - loss: -0.1248 - acc: 0.9911 - val_loss: -0.1514 - val_acc: 0.9911\n",
      "Epoch 5/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.1802 - acc: 0.9918\n",
      "New maximum F1 score: 0.8159129292550197 (before: 0.8129536571747626) Saving to tmp_lstm3cnn_bi-lstm.1.h5\n",
      "1500/1500 [==============================] - 402s 268ms/step - loss: -0.1802 - acc: 0.9918 - val_loss: -0.2049 - val_acc: 0.9914\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 404s 270ms/step - loss: -0.2353 - acc: 0.9923 - val_loss: -0.2584 - val_acc: 0.9911\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 409s 273ms/step - loss: -0.2901 - acc: 0.9929 - val_loss: -0.3121 - val_acc: 0.9910\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 402s 268ms/step - loss: -0.3446 - acc: 0.9932 - val_loss: -0.3648 - val_acc: 0.9910\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 403s 269ms/step - loss: -0.3989 - acc: 0.9935 - val_loss: -0.4193 - val_acc: 0.9914\n",
      "Epoch 10/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.4532 - acc: 0.9938\n",
      "New maximum F1 score: 0.8221242190371186 (before: 0.8159129292550197) Saving to tmp_lstm3cnn_bi-lstm.1.h5\n",
      "1500/1500 [==============================] - 406s 271ms/step - loss: -0.4532 - acc: 0.9938 - val_loss: -0.4728 - val_acc: 0.9916\n",
      "Epoch 1/10\n",
      "46/47 [============================>.] - ETA: 1s - loss: -0.4830 - acc: 0.9949\n",
      "New maximum F1 score: 0.8211577584612539 (before: 0) Saving to tmp_lstm3cnn_bi-lstm.1.h5\n",
      "47/47 [==============================] - 76s 2s/step - loss: -0.4830 - acc: 0.9949 - val_loss: -0.4749 - val_acc: 0.9915\n",
      "Epoch 2/10\n",
      "46/47 [============================>.] - ETA: 0s - loss: -0.4855 - acc: 0.9952\n",
      "New maximum F1 score: 0.8222304011777696 (before: 0.8211577584612539) Saving to tmp_lstm3cnn_bi-lstm.1.h5\n",
      "47/47 [==============================] - 65s 1s/step - loss: -0.4855 - acc: 0.9952 - val_loss: -0.4762 - val_acc: 0.9915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "46/47 [============================>.] - ETA: 0s - loss: -0.4875 - acc: 0.9952\n",
      "New maximum F1 score: 0.8237901736239379 (before: 0.8222304011777696) Saving to tmp_lstm3cnn_bi-lstm.1.h5\n",
      "47/47 [==============================] - 65s 1s/step - loss: -0.4875 - acc: 0.9953 - val_loss: -0.4780 - val_acc: 0.9916\n",
      "Epoch 4/10\n",
      "47/47 [==============================] - 66s 1s/step - loss: -0.4893 - acc: 0.9954 - val_loss: -0.4797 - val_acc: 0.9916\n",
      "Epoch 5/10\n",
      "47/47 [==============================] - 65s 1s/step - loss: -0.4913 - acc: 0.9955 - val_loss: -0.4810 - val_acc: 0.9915\n",
      "Epoch 6/10\n",
      "47/47 [==============================] - 65s 1s/step - loss: -0.4932 - acc: 0.9956 - val_loss: -0.4826 - val_acc: 0.9916\n",
      "Epoch 7/10\n",
      "47/47 [==============================] - 67s 1s/step - loss: -0.4950 - acc: 0.9957 - val_loss: -0.4843 - val_acc: 0.9915\n",
      "Epoch 8/10\n",
      "47/47 [==============================] - 65s 1s/step - loss: -0.4968 - acc: 0.9958 - val_loss: -0.4858 - val_acc: 0.9915\n",
      "Epoch 9/10\n",
      "46/47 [============================>.] - ETA: 0s - loss: -0.4987 - acc: 0.9958\n",
      "New maximum F1 score: 0.8245971476199295 (before: 0.8237901736239379) Saving to tmp_lstm3cnn_bi-lstm.1.h5\n",
      "47/47 [==============================] - 67s 1s/step - loss: -0.4987 - acc: 0.9958 - val_loss: -0.4876 - val_acc: 0.9918\n",
      "Epoch 10/10\n",
      "46/47 [============================>.] - ETA: 0s - loss: -0.5004 - acc: 0.9958\n",
      "New maximum F1 score: 0.8254847645429362 (before: 0.8245971476199295) Saving to tmp_lstm3cnn_bi-lstm.1.h5\n",
      "47/47 [==============================] - 66s 1s/step - loss: -0.5005 - acc: 0.9958 - val_loss: -0.4890 - val_acc: 0.9918\n",
      "Run 2\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 52)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 52, 32) 10560       char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_46 (TimeDistri (None, None, 52, 32) 3104        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_48 (TimeDistri (None, None, 52, 32) 4128        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_50 (TimeDistri (None, None, 52, 32) 5152        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_47 (TimeDistri (None, None, 1, 32)  0           time_distributed_46[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_49 (TimeDistri (None, None, 1, 32)  0           time_distributed_48[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_51 (TimeDistri (None, None, 1, 32)  0           time_distributed_50[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, None, 1, 96)  0           time_distributed_47[0][0]        \n",
      "                                                                 time_distributed_49[0][0]        \n",
      "                                                                 time_distributed_51[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_52 (TimeDistri (None, None, 100)    58800       concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, None, 408)    0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_52[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, None, 400)    974400      concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_53 (TimeDistri (None, None, 26)     10426       bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "crf (CRF)                       (None, None, 26)     1430        time_distributed_53[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 1,068,064\n",
      "Trainable params: 1,068,000\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: 0.0509 - acc: 0.9837\n",
      "New maximum F1 score: 0.7638808837656099 (before: 0) Saving to tmp_lstm3cnn_bi-lstm.2.h5\n",
      "1500/1500 [==============================] - 411s 274ms/step - loss: 0.0509 - acc: 0.9837 - val_loss: 0.0088 - val_acc: 0.9890\n",
      "Epoch 2/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.0126 - acc: 0.9889\n",
      "New maximum F1 score: 0.781665107577175 (before: 0.7638808837656099) Saving to tmp_lstm3cnn_bi-lstm.2.h5\n",
      "1500/1500 [==============================] - 408s 272ms/step - loss: -0.0126 - acc: 0.9890 - val_loss: -0.0397 - val_acc: 0.9901\n",
      "Epoch 3/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.0653 - acc: 0.9904\n",
      "New maximum F1 score: 0.7989623865110247 (before: 0.781665107577175) Saving to tmp_lstm3cnn_bi-lstm.2.h5\n",
      "1500/1500 [==============================] - 405s 270ms/step - loss: -0.0653 - acc: 0.9904 - val_loss: -0.0920 - val_acc: 0.9903\n",
      "Epoch 4/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.1203 - acc: 0.9910\n",
      "New maximum F1 score: 0.8089970501474927 (before: 0.7989623865110247) Saving to tmp_lstm3cnn_bi-lstm.2.h5\n",
      "1500/1500 [==============================] - 402s 268ms/step - loss: -0.1204 - acc: 0.9910 - val_loss: -0.1460 - val_acc: 0.9909\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 401s 268ms/step - loss: -0.1754 - acc: 0.9916 - val_loss: -0.1987 - val_acc: 0.9898\n",
      "Epoch 6/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.2306 - acc: 0.9924\n",
      "New maximum F1 score: 0.8174136664217487 (before: 0.8089970501474927) Saving to tmp_lstm3cnn_bi-lstm.2.h5\n",
      "1500/1500 [==============================] - 405s 270ms/step - loss: -0.2307 - acc: 0.9924 - val_loss: -0.2532 - val_acc: 0.9913\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 403s 269ms/step - loss: -0.2853 - acc: 0.9929 - val_loss: -0.3063 - val_acc: 0.9911\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 401s 267ms/step - loss: -0.3399 - acc: 0.9932 - val_loss: -0.3602 - val_acc: 0.9905\n",
      "Epoch 9/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.3941 - acc: 0.9934\n",
      "New maximum F1 score: 0.8194885196938586 (before: 0.8174136664217487) Saving to tmp_lstm3cnn_bi-lstm.2.h5\n",
      "1500/1500 [==============================] - 402s 268ms/step - loss: -0.3941 - acc: 0.9934 - val_loss: -0.4142 - val_acc: 0.9909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 406s 271ms/step - loss: -0.4483 - acc: 0.9936 - val_loss: -0.4673 - val_acc: 0.9914\n",
      "Epoch 1/10\n",
      "46/47 [============================>.] - ETA: 1s - loss: -0.4242 - acc: 0.9945\n",
      "New maximum F1 score: 0.8212899648863426 (before: 0) Saving to tmp_lstm3cnn_bi-lstm.2.h5\n",
      "47/47 [==============================] - 75s 2s/step - loss: -0.4242 - acc: 0.9946 - val_loss: -0.4158 - val_acc: 0.9912\n",
      "Epoch 2/10\n",
      "46/47 [============================>.] - ETA: 0s - loss: -0.4265 - acc: 0.9948\n",
      "New maximum F1 score: 0.8223368964246222 (before: 0.8212899648863426) Saving to tmp_lstm3cnn_bi-lstm.2.h5\n",
      "47/47 [==============================] - 64s 1s/step - loss: -0.4265 - acc: 0.9948 - val_loss: -0.4175 - val_acc: 0.9912\n",
      "Epoch 3/10\n",
      "46/47 [============================>.] - ETA: 0s - loss: -0.4284 - acc: 0.9949\n",
      "New maximum F1 score: 0.8229859571322985 (before: 0.8223368964246222) Saving to tmp_lstm3cnn_bi-lstm.2.h5\n",
      "47/47 [==============================] - 65s 1s/step - loss: -0.4285 - acc: 0.9950 - val_loss: -0.4192 - val_acc: 0.9913\n",
      "Epoch 4/10\n",
      "46/47 [============================>.] - ETA: 0s - loss: -0.4305 - acc: 0.9951\n",
      "New maximum F1 score: 0.8234211010863561 (before: 0.8229859571322985) Saving to tmp_lstm3cnn_bi-lstm.2.h5\n",
      "47/47 [==============================] - 64s 1s/step - loss: -0.4306 - acc: 0.9951 - val_loss: -0.4207 - val_acc: 0.9913\n",
      "Epoch 5/10\n",
      "46/47 [============================>.] - ETA: 0s - loss: -0.4324 - acc: 0.9952\n",
      "New maximum F1 score: 0.825420284500277 (before: 0.8234211010863561) Saving to tmp_lstm3cnn_bi-lstm.2.h5\n",
      "47/47 [==============================] - 66s 1s/step - loss: -0.4324 - acc: 0.9952 - val_loss: -0.4224 - val_acc: 0.9914\n",
      "Epoch 6/10\n",
      "47/47 [==============================] - 64s 1s/step - loss: -0.4343 - acc: 0.9953 - val_loss: -0.4241 - val_acc: 0.9913\n",
      "Epoch 7/10\n",
      "47/47 [==============================] - 61s 1s/step - loss: -0.4362 - acc: 0.9955 - val_loss: -0.4255 - val_acc: 0.9913\n",
      "Epoch 8/10\n",
      "47/47 [==============================] - 65s 1s/step - loss: -0.4379 - acc: 0.9954 - val_loss: -0.4272 - val_acc: 0.9914\n",
      "Epoch 9/10\n",
      "47/47 [==============================] - 65s 1s/step - loss: -0.4399 - acc: 0.9955 - val_loss: -0.4288 - val_acc: 0.9913\n",
      "Epoch 10/10\n",
      "47/47 [==============================] - 65s 1s/step - loss: -0.4418 - acc: 0.9957 - val_loss: -0.4302 - val_acc: 0.9913\n",
      "Run 3\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 52)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 52, 32) 10560       char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_54 (TimeDistri (None, None, 52, 32) 3104        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_56 (TimeDistri (None, None, 52, 32) 4128        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_58 (TimeDistri (None, None, 52, 32) 5152        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_55 (TimeDistri (None, None, 1, 32)  0           time_distributed_54[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_57 (TimeDistri (None, None, 1, 32)  0           time_distributed_56[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_59 (TimeDistri (None, None, 1, 32)  0           time_distributed_58[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, None, 1, 96)  0           time_distributed_55[0][0]        \n",
      "                                                                 time_distributed_57[0][0]        \n",
      "                                                                 time_distributed_59[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_60 (TimeDistri (None, None, 100)    58800       concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, None, 408)    0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_60[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, None, 400)    974400      concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_61 (TimeDistri (None, None, 26)     10426       bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "crf (CRF)                       (None, None, 26)     1430        time_distributed_61[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 1,068,064\n",
      "Trainable params: 1,068,000\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9837\n",
      "New maximum F1 score: 0.7605633802816902 (before: 0) Saving to tmp_lstm3cnn_bi-lstm.3.h5\n",
      "1500/1500 [==============================] - 406s 270ms/step - loss: 0.0502 - acc: 0.9838 - val_loss: 0.0094 - val_acc: 0.9886\n",
      "Epoch 2/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.0138 - acc: 0.9890\n",
      "New maximum F1 score: 0.7886904761904763 (before: 0.7605633802816902) Saving to tmp_lstm3cnn_bi-lstm.3.h5\n",
      "1500/1500 [==============================] - 402s 268ms/step - loss: -0.0138 - acc: 0.9890 - val_loss: -0.0408 - val_acc: 0.9903\n",
      "Epoch 3/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.0671 - acc: 0.9903\n",
      "New maximum F1 score: 0.8088455772113944 (before: 0.7886904761904763) Saving to tmp_lstm3cnn_bi-lstm.3.h5\n",
      "1500/1500 [==============================] - 404s 269ms/step - loss: -0.0671 - acc: 0.9903 - val_loss: -0.0944 - val_acc: 0.9910\n",
      "Epoch 4/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.1218 - acc: 0.9912\n",
      "New maximum F1 score: 0.8134203168685927 (before: 0.8088455772113944) Saving to tmp_lstm3cnn_bi-lstm.3.h5\n",
      "1500/1500 [==============================] - 400s 267ms/step - loss: -0.1219 - acc: 0.9912 - val_loss: -0.1483 - val_acc: 0.9912\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 399s 266ms/step - loss: -0.1772 - acc: 0.9918 - val_loss: -0.2010 - val_acc: 0.9910\n",
      "Epoch 6/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.2322 - acc: 0.9924\n",
      "New maximum F1 score: 0.8182156133828996 (before: 0.8134203168685927) Saving to tmp_lstm3cnn_bi-lstm.3.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 403s 268ms/step - loss: -0.2322 - acc: 0.9924 - val_loss: -0.2552 - val_acc: 0.9912\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 405s 270ms/step - loss: -0.2869 - acc: 0.9928 - val_loss: -0.3079 - val_acc: 0.9909\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 404s 270ms/step - loss: -0.3414 - acc: 0.9932 - val_loss: -0.3628 - val_acc: 0.9912\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 400s 267ms/step - loss: -0.3958 - acc: 0.9935 - val_loss: -0.4146 - val_acc: 0.9908\n",
      "Epoch 10/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.4501 - acc: 0.9937\n",
      "New maximum F1 score: 0.8205693296602388 (before: 0.8182156133828996) Saving to tmp_lstm3cnn_bi-lstm.3.h5\n",
      "1500/1500 [==============================] - 399s 266ms/step - loss: -0.4502 - acc: 0.9937 - val_loss: -0.4687 - val_acc: 0.9912\n",
      "Epoch 1/10\n",
      "46/47 [============================>.] - ETA: 1s - loss: -0.4797 - acc: 0.9948\n",
      "New maximum F1 score: 0.8241372947038199 (before: 0) Saving to tmp_lstm3cnn_bi-lstm.3.h5\n",
      "47/47 [==============================] - 75s 2s/step - loss: -0.4798 - acc: 0.9948 - val_loss: -0.4707 - val_acc: 0.9913\n",
      "Epoch 2/10\n",
      "46/47 [============================>.] - ETA: 0s - loss: -0.4822 - acc: 0.9952\n",
      "New maximum F1 score: 0.827611664820967 (before: 0.8241372947038199) Saving to tmp_lstm3cnn_bi-lstm.3.h5\n",
      "47/47 [==============================] - 65s 1s/step - loss: -0.4822 - acc: 0.9952 - val_loss: -0.4723 - val_acc: 0.9915\n",
      "Epoch 3/10\n",
      "47/47 [==============================] - 64s 1s/step - loss: -0.4842 - acc: 0.9953 - val_loss: -0.4739 - val_acc: 0.9914\n",
      "Epoch 4/10\n",
      "46/47 [============================>.] - ETA: 0s - loss: -0.4862 - acc: 0.9954\n",
      "New maximum F1 score: 0.8276752767527674 (before: 0.827611664820967) Saving to tmp_lstm3cnn_bi-lstm.3.h5\n",
      "47/47 [==============================] - 66s 1s/step - loss: -0.4862 - acc: 0.9954 - val_loss: -0.4755 - val_acc: 0.9915\n",
      "Epoch 5/10\n",
      "47/47 [==============================] - 63s 1s/step - loss: -0.4881 - acc: 0.9956 - val_loss: -0.4771 - val_acc: 0.9914\n",
      "Epoch 6/10\n",
      "46/47 [============================>.] - ETA: 0s - loss: -0.4900 - acc: 0.9957\n",
      "New maximum F1 score: 0.8294030950626383 (before: 0.8276752767527674) Saving to tmp_lstm3cnn_bi-lstm.3.h5\n",
      "47/47 [==============================] - 65s 1s/step - loss: -0.4899 - acc: 0.9957 - val_loss: -0.4787 - val_acc: 0.9916\n",
      "Epoch 7/10\n",
      "47/47 [==============================] - 64s 1s/step - loss: -0.4918 - acc: 0.9957 - val_loss: -0.4804 - val_acc: 0.9915\n",
      "Epoch 8/10\n",
      "46/47 [============================>.] - ETA: 0s - loss: -0.4936 - acc: 0.9958\n",
      "New maximum F1 score: 0.8295559240832873 (before: 0.8294030950626383) Saving to tmp_lstm3cnn_bi-lstm.3.h5\n",
      "47/47 [==============================] - 66s 1s/step - loss: -0.4936 - acc: 0.9958 - val_loss: -0.4819 - val_acc: 0.9915\n",
      "Epoch 9/10\n",
      "47/47 [==============================] - 65s 1s/step - loss: -0.4955 - acc: 0.9959 - val_loss: -0.4834 - val_acc: 0.9915\n",
      "Epoch 10/10\n",
      "46/47 [============================>.] - ETA: 0s - loss: -0.4972 - acc: 0.9958\n",
      "New maximum F1 score: 0.8307579102281089 (before: 0.8295559240832873) Saving to tmp_lstm3cnn_bi-lstm.3.h5\n",
      "47/47 [==============================] - 65s 1s/step - loss: -0.4972 - acc: 0.9958 - val_loss: -0.4852 - val_acc: 0.9916\n",
      "Run 4\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 52)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 52, 32) 10560       char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_62 (TimeDistri (None, None, 52, 32) 3104        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_64 (TimeDistri (None, None, 52, 32) 4128        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_66 (TimeDistri (None, None, 52, 32) 5152        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_63 (TimeDistri (None, None, 1, 32)  0           time_distributed_62[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_65 (TimeDistri (None, None, 1, 32)  0           time_distributed_64[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_67 (TimeDistri (None, None, 1, 32)  0           time_distributed_66[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, None, 1, 96)  0           time_distributed_63[0][0]        \n",
      "                                                                 time_distributed_65[0][0]        \n",
      "                                                                 time_distributed_67[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_68 (TimeDistri (None, None, 100)    58800       concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, None, 408)    0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_68[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, None, 400)    974400      concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_69 (TimeDistri (None, None, 26)     10426       bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "crf (CRF)                       (None, None, 26)     1430        time_distributed_69[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 1,068,064\n",
      "Trainable params: 1,068,000\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      " 212/1500 [===>..........................] - ETA: 6:15 - loss: 0.1412 - acc: 0.9679"
     ]
    }
   ],
   "source": [
    "f = open('results_lstm3cnn.txt', 'a')\n",
    "for run_i in range(10):\n",
    "    print(\"Run \" + str(run_i))\n",
    "    \n",
    "    tmp_model_filename = 'tmp_lstm3cnn_bi-lstm.' + str(run_i) + '.h5'\n",
    "\n",
    "    history = utils.F1History(tmp_model_filename, devSet=devSentences)\n",
    "    \n",
    "    model = models.get_model_3cnnlstm()\n",
    "    model.fit_generator(\n",
    "        utils.NerSequence(trainSentences, shuffle_data=True, batch_size=16), \n",
    "        validation_data = utils.NerSequence(devSentences, batch_size=256), \n",
    "        epochs = 10, callbacks = [history]\n",
    "    )\n",
    "    \n",
    "    model.load_weights(tmp_model_filename)\n",
    "    \n",
    "    model.fit_generator(\n",
    "        utils.NerSequence(trainSentences, shuffle_data=True, batch_size=512), \n",
    "        validation_data = utils.NerSequence(devSentences, batch_size=256), \n",
    "        epochs = 10, callbacks = [history]\n",
    "    )\n",
    "    \n",
    "    true_labels, pred_labels = utils.predict_sequences(model, testSentences)\n",
    "    \n",
    "    pre, rec, f1 = compute_f1(pred_labels, true_labels, models.idx2Label)\n",
    "    f.write(str(run_i) + \"\\t\" + str(pre) + \"\\t\" + str(rec) +  \"\\t\" + str(f1))\n",
    "    f.write(\"\\n\")\n",
    "    f.flush()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, json\n",
    "# copy file for best run\n",
    "shutil.copyfile('tmp_lstm_bi-lstm.h5', '../models/final_model-lstm_germeval_outer.h5')\n",
    "with open(\"../models/final_model-lstm_germeval.indexes\", \"w\") as f:\n",
    "    json.dump([models.idx2Label, models.label2Idx, models.char2Idx, models.case2Idx], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_contrib.layers import CRF\n",
    "def create_custom_objects():\n",
    "    instanceHolder = {\"instance\": None}\n",
    "    class ClassWrapper(CRF):\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            instanceHolder[\"instance\"] = self\n",
    "            super(ClassWrapper, self).__init__(*args, **kwargs)\n",
    "    def loss(*args):\n",
    "        method = getattr(instanceHolder[\"instance\"], \"loss_function\")\n",
    "        return method(*args)\n",
    "    def accuracy(*args):\n",
    "        method = getattr(instanceHolder[\"instance\"], \"accuracy\")\n",
    "        return method(*args)\n",
    "    return {\"ClassWrapper\": ClassWrapper ,\"CRF\": ClassWrapper, \"loss\": loss, \"accuracy\":accuracy}\n",
    "\n",
    "finalmodel = load_model('../models/final_model-lstm_germeval_outer.h5', custom_objects=create_custom_objects())\n",
    "true_labels, pred_labels = utils.predict_sequences(finalmodel, testSentences)\n",
    "print(compute_f1(pred_labels, true_labels, models.idx2Label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('germeval_output.tsv', 'w', encoding='UTF-8')\n",
    "for i_sent, sent in enumerate(testSentences):\n",
    "    for i_tok, tok in enumerate(sent):\n",
    "        if tok[0] == 'PADDING_TOKEN':\n",
    "            break\n",
    "        correctlabel = models.idx2Label[true_labels[i_sent][i_tok]]\n",
    "        guessedlabel = models.idx2Label[pred_labels[i_sent][i_tok]]\n",
    "        line = \"\\t\".join([str(i_tok+1), tok[0], correctlabel, correctlabel, guessedlabel, guessedlabel])\n",
    "        f.write(line + '\\n')\n",
    "    f.write('\\n')\n",
    "f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = models.get_model_lstm()\n",
    "\n",
    "model.load_weights(tmp_model_filename)\n",
    "\n",
    "model.fit_generator(\n",
    "    utils.NerSequence(trainSentences, shuffle_data=True, batch_size=512), \n",
    "    validation_data = utils.NerSequence(devSentences, batch_size=256), \n",
    "    epochs = 10, callbacks = [history]\n",
    ")\n",
    "\n",
    "true_labels, pred_labels = utils.predict_sequences(model, testSentences)\n",
    "\n",
    "pre, rec, f1 = compute_f1(pred_labels, true_labels, models.idx2Label)\n",
    "f.write(str(run_i) + \"\\t\" + str(pre) + \"\\t\" + str(rec) +  \"\\t\" + str(f1))\n",
    "f.write(\"\\n\")\n",
    "f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
