{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gwiedemann/miniconda3/envs/kerasenv/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import fastText\n",
    "\n",
    "from validation import compute_f1\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "\n",
    "import models\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12152\n",
      "2867\n",
      "3005\n"
     ]
    }
   ],
   "source": [
    "# trainSentences = utils.get_sentences_germeval('../data/GermEVAL/NER-de-train.tsv')\n",
    "# devSentences = utils.get_sentences_germeval('../data/GermEVAL/NER-de-dev.tsv')\n",
    "# testSentences = utils.get_sentences_germeval('../data/GermEVAL/NER-de-test.tsv')\n",
    "\n",
    "trainSentences = utils.get_sentences_conll('../data/CONLL/deu/deu_utf.train.bio')\n",
    "devSentences = utils.get_sentences_conll('../data/CONLL/deu/deu_utf.testa.bio')\n",
    "testSentences = utils.get_sentences_conll('../data/CONLL/deu/deu_utf.testb.bio')\n",
    "\n",
    "print(len(trainSentences))\n",
    "print(len(devSentences))\n",
    "print(len(testSentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Die', 'O'], ['sechs', 'O'], ['Abgeordneten', 'O'], ['der', 'O'], ['Grünen', 'B-ORG'], [',', 'O'], ['die', 'O'], ['seit', 'O'], ['Bildung', 'O'], ['einer', 'O'], ['Großen', 'O'], ['Koalition', 'O'], ['von', 'O'], ['Christ-', 'O'], ['und', 'O'], ['Sozialdemokraten', 'O'], ['die', 'O'], ['Opposition', 'O'], ['darstellen', 'O'], [',', 'O'], ['hatten', 'O'], ['sich', 'O'], ['beim', 'O'], ['Vorsteher', 'O'], ['Rainer', 'B-PER'], ['Bergert', 'I-PER'], ['für', 'O'], ['ihr', 'O'], ['Fehlen', 'O'], ['entschuldigen', 'O'], ['lassen', 'O'], ['.', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(testSentences[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "labelSet = set()\n",
    "characters= set()\n",
    "models.max_sequence_length = 0\n",
    "n_gt_100 = 0\n",
    "for dataset in [trainSentences, devSentences, testSentences]:\n",
    "    for sentence in dataset:\n",
    "        for word, label in sentence:\n",
    "            for char in word:\n",
    "                characters.add(char)\n",
    "            labelSet.add(label)\n",
    "        if len(sentence) > models.max_sequence_length:\n",
    "            models.max_sequence_length = len(sentence)\n",
    "        if len(sentence) > 100:\n",
    "            n_gt_100 += 1\n",
    "print(n_gt_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(labelSet))\n",
    "print(models.max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# :: Create a mapping for the labels ::\n",
    "models.label2Idx = {\"PADDING_TOKEN\":0}\n",
    "for label in labelSet:\n",
    "    models.label2Idx[label] = len(models.label2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-MISC': 3, 'O': 1, 'B-LOC': 2, 'I-ORG': 7, 'I-MISC': 4, 'I-PER': 6, 'PADDING_TOKEN': 0, 'B-ORG': 9, 'I-LOC': 8, 'B-PER': 5}\n"
     ]
    }
   ],
   "source": [
    "print(models.label2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# :: Hard coded case lookup ::\n",
    "models.case2Idx = {'PADDING_TOKEN':0, 'numeric': 1, 'allLower':2, 'allUpper':3, 'initialUpper':4, 'other':5, 'mainly_numeric':6, 'contains_digit': 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mainly_numeric': 6, 'numeric': 1, 'PADDING_TOKEN': 0, 'allLower': 2, 'contains_digit': 7, 'other': 5, 'allUpper': 3, 'initialUpper': 4}\n"
     ]
    }
   ],
   "source": [
    "print(models.case2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(trainSentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Ereignis', 'O'], ['und', 'O'], ['Erzählung', 'O'], ['oder', 'O'], [':', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(trainSentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ö': 54, 'ä': 55, 'J': 29, 'PADDING_TOKEN': 0, 'I': 5, 'o': 61, 'è': 101, 'Z': 6, 'P': 7, '!': 8, 'Ä': 57, '&': 9, 'Y': 58, 'UNKNOWN': 103, 'd': 60, 'S': 10, 'á': 63, '</S>': 2, 'l': 64, '=': 32, 'ê': 11, 'ß': 12, '-': 66, 'b': 14, 'h': 67, 'V': 68, 'x': 34, '5': 15, 'j': 70, 'Ü': 71, 'r': 97, 'M': 72, 't': 17, '</W>': 4, 'C': 65, 'H': 18, 'f': 73, '<S>': 1, '.': 19, 'ç': 20, 'w': 23, 'W': 21, '/': 99, 'g': 22, '9': 75, 'z': 79, '2': 25, '8': 76, 'N': 26, 'ñ': 28, '+': 77, 'B': 56, '0': 78, 'p': 30, 'í': 31, '<W>': 3, 'i': 33, '\"': 35, 'R': 24, '§': 83, 'L': 81, '7': 82, ')': 36, ':': 37, 'A': 38, 'q': 84, 'E': 85, 'v': 87, 'a': 88, '4': 98, 'n': 89, 'D': 69, '6': 74, 'm': 39, 'é': 80, \"'\": 62, 'F': 40, 'ì': 41, 'T': 90, 'U': 91, 'ô': 59, '*': 42, 'y': 27, 's': 43, 'ó': 16, 'X': 44, 'O': 86, 'G': 92, 'e': 93, 'ü': 94, '%': 95, ';': 45, 'Q': 96, '1': 46, 'u': 13, '?': 47, '(': 48, 'K': 49, 'k': 50, ',': 100, 'ò': 51, '3': 102, 'Ö': 52, 'c': 53}\n"
     ]
    }
   ],
   "source": [
    "models.char2Idx={\"PADDING_TOKEN\":0, \"<S>\":1, \"</S>\":2, \"<W>\":3, \"</W>\":4}\n",
    "for char in characters:\n",
    "    models.char2Idx[char] = len(models.char2Idx)\n",
    "models.char2Idx['UNKNOWN'] = len(models.char2Idx)\n",
    "print(models.char2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Ereignis', 'O'], ['und', 'O'], ['Erzählung', 'O'], ['oder', 'O'], [':', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(trainSentences[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.ft = fastText.load_model(\"../embeddings/wiki.de.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(models.nb_embedding_dims)\n",
    "print(len(trainSentences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "models.idx2Label = {v: k for k, v in models.label2Idx.items()}\n",
    "print(len(models.label2Idx))\n",
    "print(len(models.idx2Label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# importlib.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_model_filename = 'model_lstm_conll.h5'\n",
    "# checkpoint = ModelCheckpoint(tmp_model_filename, verbose=1, save_best_only = True, monitor = 'val_acc')\n",
    "history = utils.F1History(tmp_model_filename, devSet = devSentences)\n",
    "model = models.get_model_lstm_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import importlib\n",
    "#importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    utils.NerSequence(trainSentences[:1000], shuffle_data=True, batch_size=256), \n",
    "    validation_data = utils.NerSequence(devSentences[:1000], batch_size=256), \n",
    "    epochs = 3, callbacks = [history]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.acc)\n",
    "print(history.f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(tmp_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    utils.NerSequence(trainSentences, shuffle_data=True, batch_size=2048), \n",
    "    validation_data = utils.NerSequence(devSentences, batch_size=256), \n",
    "    epochs = 5, callbacks = [history]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(tmp_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels, pred_labels = utils.predict_sequences(model, testSentences[:1000])\n",
    "print(compute_f1(pred_labels, true_labels, models.idx2Label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 52)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 52, 32) 3328        char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, None, 100)    33200       char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 408)    0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, None, 400)    974400      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "crf (CRF)                       (None, None, 10)     4130        bidirectional_2[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,015,122\n",
      "Trainable params: 1,015,058\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9898\n",
      "New maximum F1 score: 0.7807585568917669 (before: 0) Saving to model_lstm_conll.0.h5\n",
      "380/380 [==============================] - 255s 671ms/step - loss: 0.0391 - acc: 0.9898 - val_loss: 0.0197 - val_acc: 0.9943\n",
      "Epoch 2/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9959\n",
      "New maximum F1 score: 0.8086544962812713 (before: 0.7807585568917669) Saving to model_lstm_conll.0.h5\n",
      "380/380 [==============================] - 250s 658ms/step - loss: 0.0123 - acc: 0.9959 - val_loss: 0.0137 - val_acc: 0.9950\n",
      "Epoch 3/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9965\n",
      "New maximum F1 score: 0.8145969790135009 (before: 0.8086544962812713) Saving to model_lstm_conll.0.h5\n",
      "380/380 [==============================] - 249s 656ms/step - loss: 0.0070 - acc: 0.9965 - val_loss: 0.0096 - val_acc: 0.9952\n",
      "Epoch 4/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9970\n",
      "New maximum F1 score: 0.8288720202423758 (before: 0.8145969790135009) Saving to model_lstm_conll.0.h5\n",
      "380/380 [==============================] - 250s 657ms/step - loss: 0.0020 - acc: 0.9970 - val_loss: 0.0047 - val_acc: 0.9954\n",
      "Epoch 5/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: -0.0030 - acc: 0.9974\n",
      "New maximum F1 score: 0.8378164556962027 (before: 0.8288720202423758) Saving to model_lstm_conll.0.h5\n",
      "380/380 [==============================] - 249s 656ms/step - loss: -0.0030 - acc: 0.9974 - val_loss: -6.3676e-05 - val_acc: 0.9957\n",
      "Epoch 6/10\n",
      "380/380 [==============================] - 247s 650ms/step - loss: -0.0085 - acc: 0.9977 - val_loss: -0.0044 - val_acc: 0.9957\n",
      "Epoch 7/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: -0.0142 - acc: 0.9979\n",
      "New maximum F1 score: 0.8512766517504606 (before: 0.8378164556962027) Saving to model_lstm_conll.0.h5\n",
      "380/380 [==============================] - 248s 652ms/step - loss: -0.0142 - acc: 0.9979 - val_loss: -0.0107 - val_acc: 0.9960\n",
      "Epoch 8/10\n",
      "380/380 [==============================] - 248s 653ms/step - loss: -0.0204 - acc: 0.9982 - val_loss: -0.0157 - val_acc: 0.9958\n",
      "Epoch 9/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: -0.0268 - acc: 0.9983\n",
      "New maximum F1 score: 0.8539444224944026 (before: 0.8512766517504606) Saving to model_lstm_conll.0.h5\n",
      "380/380 [==============================] - 248s 653ms/step - loss: -0.0268 - acc: 0.9983 - val_loss: -0.0228 - val_acc: 0.9961\n",
      "Epoch 10/10\n",
      "380/380 [==============================] - 249s 654ms/step - loss: -0.0339 - acc: 0.9986 - val_loss: -0.0282 - val_acc: 0.9958\n",
      "Epoch 1/10\n",
      "47/48 [============================>.] - ETA: 1s - loss: -0.0314 - acc: 0.9987\n",
      "New maximum F1 score: 0.8542381832585161 (before: 0.8539444224944026) Saving to model_lstm_conll.0.h5\n",
      "48/48 [==============================] - 105s 2s/step - loss: -0.0314 - acc: 0.9987 - val_loss: -0.0237 - val_acc: 0.9961\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 85s 2s/step - loss: -0.0325 - acc: 0.9988 - val_loss: -0.0244 - val_acc: 0.9961\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 86s 2s/step - loss: -0.0334 - acc: 0.9989 - val_loss: -0.0253 - val_acc: 0.9961\n",
      "Epoch 4/10\n",
      "47/48 [============================>.] - ETA: 0s - loss: -0.0344 - acc: 0.9989\n",
      "New maximum F1 score: 0.8573305307409353 (before: 0.8542381832585161) Saving to model_lstm_conll.0.h5\n",
      "48/48 [==============================] - 86s 2s/step - loss: -0.0344 - acc: 0.9989 - val_loss: -0.0261 - val_acc: 0.9962\n",
      "Epoch 5/10\n",
      "47/48 [============================>.] - ETA: 0s - loss: -0.0354 - acc: 0.9990\n",
      "New maximum F1 score: 0.8587184873949579 (before: 0.8573305307409353) Saving to model_lstm_conll.0.h5\n",
      "48/48 [==============================] - 85s 2s/step - loss: -0.0354 - acc: 0.9990 - val_loss: -0.0270 - val_acc: 0.9962\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 87s 2s/step - loss: -0.0364 - acc: 0.9990 - val_loss: -0.0277 - val_acc: 0.9962\n",
      "Epoch 7/10\n",
      "47/48 [============================>.] - ETA: 0s - loss: -0.0374 - acc: 0.9991\n",
      "New maximum F1 score: 0.8601416950931514 (before: 0.8587184873949579) Saving to model_lstm_conll.0.h5\n",
      "48/48 [==============================] - 88s 2s/step - loss: -0.0374 - acc: 0.9991 - val_loss: -0.0287 - val_acc: 0.9962\n",
      "Epoch 8/10\n",
      "47/48 [============================>.] - ETA: 0s - loss: -0.0383 - acc: 0.9991\n",
      "New maximum F1 score: 0.8610018358248098 (before: 0.8601416950931514) Saving to model_lstm_conll.0.h5\n",
      "48/48 [==============================] - 88s 2s/step - loss: -0.0383 - acc: 0.9991 - val_loss: -0.0293 - val_acc: 0.9963\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 88s 2s/step - loss: -0.0392 - acc: 0.9992 - val_loss: -0.0301 - val_acc: 0.9962\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 86s 2s/step - loss: -0.0402 - acc: 0.9992 - val_loss: -0.0309 - val_acc: 0.9962\n",
      "Run 1\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 52)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 52, 32) 3328        char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, None, 100)    33200       char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, 408)    0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, None, 400)    974400      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "crf (CRF)                       (None, None, 10)     4130        bidirectional_4[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,015,122\n",
      "Trainable params: 1,015,058\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: 0.0372 - acc: 0.9903\n",
      "New maximum F1 score: 0.7762483130904183 (before: 0) Saving to model_lstm_conll.1.h5\n",
      "380/380 [==============================] - 256s 674ms/step - loss: 0.0371 - acc: 0.9903 - val_loss: 0.0212 - val_acc: 0.9943\n",
      "Epoch 2/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9959\n",
      "New maximum F1 score: 0.8085969180859691 (before: 0.7762483130904183) Saving to model_lstm_conll.1.h5\n",
      "380/380 [==============================] - 249s 655ms/step - loss: 0.0136 - acc: 0.9959 - val_loss: 0.0154 - val_acc: 0.9950\n",
      "Epoch 3/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: 0.0082 - acc: 0.9966\n",
      "New maximum F1 score: 0.8180581996192547 (before: 0.8085969180859691) Saving to model_lstm_conll.1.h5\n",
      "380/380 [==============================] - 249s 655ms/step - loss: 0.0082 - acc: 0.9966 - val_loss: 0.0109 - val_acc: 0.9953\n",
      "Epoch 4/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9971\n",
      "New maximum F1 score: 0.8286438191758901 (before: 0.8180581996192547) Saving to model_lstm_conll.1.h5\n",
      "380/380 [==============================] - 248s 653ms/step - loss: 0.0032 - acc: 0.9971 - val_loss: 0.0062 - val_acc: 0.9955\n",
      "Epoch 5/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: -0.0018 - acc: 0.9975\n",
      "New maximum F1 score: 0.8420627440420089 (before: 0.8286438191758901) Saving to model_lstm_conll.1.h5\n",
      "380/380 [==============================] - 248s 652ms/step - loss: -0.0018 - acc: 0.9975 - val_loss: 0.0017 - val_acc: 0.9958\n",
      "Epoch 6/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: -0.0072 - acc: 0.9977\n",
      "New maximum F1 score: 0.845233292994487 (before: 0.8420627440420089) Saving to model_lstm_conll.1.h5\n",
      "380/380 [==============================] - 250s 657ms/step - loss: -0.0072 - acc: 0.9977 - val_loss: -0.0037 - val_acc: 0.9959\n",
      "Epoch 7/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: -0.0130 - acc: 0.9979\n",
      "New maximum F1 score: 0.8464091331474843 (before: 0.845233292994487) Saving to model_lstm_conll.1.h5\n",
      "380/380 [==============================] - 251s 660ms/step - loss: -0.0130 - acc: 0.9979 - val_loss: -0.0091 - val_acc: 0.9959\n",
      "Epoch 8/10\n",
      "380/380 [==============================] - 250s 658ms/step - loss: -0.0194 - acc: 0.9982 - val_loss: -0.0149 - val_acc: 0.9959\n",
      "Epoch 9/10\n",
      "380/380 [==============================] - 251s 660ms/step - loss: -0.0260 - acc: 0.9984 - val_loss: -0.0211 - val_acc: 0.9960\n",
      "Epoch 10/10\n",
      "380/380 [==============================] - 249s 655ms/step - loss: -0.0328 - acc: 0.9985 - val_loss: -0.0270 - val_acc: 0.9959\n",
      "Epoch 1/10\n",
      "47/48 [============================>.] - ETA: 1s - loss: -0.0174 - acc: 0.9985\n",
      "New maximum F1 score: 0.8491487396067046 (before: 0.8464091331474843) Saving to model_lstm_conll.1.h5\n",
      "48/48 [==============================] - 107s 2s/step - loss: -0.0174 - acc: 0.9985 - val_loss: -0.0104 - val_acc: 0.9960\n",
      "Epoch 2/10\n",
      "47/48 [============================>.] - ETA: 0s - loss: -0.0186 - acc: 0.9986\n",
      "New maximum F1 score: 0.851730035521642 (before: 0.8491487396067046) Saving to model_lstm_conll.1.h5\n",
      "48/48 [==============================] - 87s 2s/step - loss: -0.0186 - acc: 0.9986 - val_loss: -0.0112 - val_acc: 0.9961\n",
      "Epoch 3/10\n",
      "47/48 [============================>.] - ETA: 0s - loss: -0.0196 - acc: 0.9986\n",
      "New maximum F1 score: 0.8521623419827012 (before: 0.851730035521642) Saving to model_lstm_conll.1.h5\n",
      "48/48 [==============================] - 85s 2s/step - loss: -0.0196 - acc: 0.9986 - val_loss: -0.0118 - val_acc: 0.9961\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 88s 2s/step - loss: -0.0205 - acc: 0.9987 - val_loss: -0.0126 - val_acc: 0.9961\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 87s 2s/step - loss: -0.0216 - acc: 0.9987 - val_loss: -0.0135 - val_acc: 0.9960\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 89s 2s/step - loss: -0.0226 - acc: 0.9988 - val_loss: -0.0141 - val_acc: 0.9961\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 89s 2s/step - loss: -0.0236 - acc: 0.9988 - val_loss: -0.0152 - val_acc: 0.9961\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 89s 2s/step - loss: -0.0246 - acc: 0.9988 - val_loss: -0.0160 - val_acc: 0.9960\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 87s 2s/step - loss: -0.0256 - acc: 0.9990 - val_loss: -0.0166 - val_acc: 0.9960\n",
      "Epoch 10/10\n",
      "47/48 [============================>.] - ETA: 0s - loss: -0.0265 - acc: 0.9989\n",
      "New maximum F1 score: 0.8525854047587397 (before: 0.8521623419827012) Saving to model_lstm_conll.1.h5\n",
      "48/48 [==============================] - 89s 2s/step - loss: -0.0265 - acc: 0.9989 - val_loss: -0.0175 - val_acc: 0.9961\n",
      "Run 2\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 52)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 52, 32) 3328        char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, None, 100)    33200       char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, None, 408)    0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, None, 400)    974400      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "crf (CRF)                       (None, None, 10)     4130        bidirectional_6[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,015,122\n",
      "Trainable params: 1,015,058\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: 0.0356 - acc: 0.9902\n",
      "New maximum F1 score: 0.783114186851211 (before: 0) Saving to model_lstm_conll.2.h5\n",
      "380/380 [==============================] - 258s 679ms/step - loss: 0.0355 - acc: 0.9903 - val_loss: 0.0201 - val_acc: 0.9942\n",
      "Epoch 2/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9958\n",
      "New maximum F1 score: 0.818082491122644 (before: 0.783114186851211) Saving to model_lstm_conll.2.h5\n",
      "380/380 [==============================] - 250s 657ms/step - loss: 0.0125 - acc: 0.9958 - val_loss: 0.0140 - val_acc: 0.9951\n",
      "Epoch 3/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9966\n",
      "New maximum F1 score: 0.8248407643312102 (before: 0.818082491122644) Saving to model_lstm_conll.2.h5\n",
      "380/380 [==============================] - 251s 661ms/step - loss: 0.0071 - acc: 0.9966 - val_loss: 0.0097 - val_acc: 0.9953\n",
      "Epoch 4/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9971\n",
      "New maximum F1 score: 0.8264551687054712 (before: 0.8248407643312102) Saving to model_lstm_conll.2.h5\n",
      "380/380 [==============================] - 251s 661ms/step - loss: 0.0023 - acc: 0.9971 - val_loss: 0.0057 - val_acc: 0.9954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: -0.0027 - acc: 0.9975\n",
      "New maximum F1 score: 0.8399206873760741 (before: 0.8264551687054712) Saving to model_lstm_conll.2.h5\n",
      "380/380 [==============================] - 251s 659ms/step - loss: -0.0028 - acc: 0.9975 - val_loss: 9.6199e-04 - val_acc: 0.9957\n",
      "Epoch 6/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: -0.0080 - acc: 0.9977\n",
      "New maximum F1 score: 0.8434978171715836 (before: 0.8399206873760741) Saving to model_lstm_conll.2.h5\n",
      "380/380 [==============================] - 251s 662ms/step - loss: -0.0080 - acc: 0.9977 - val_loss: -0.0047 - val_acc: 0.9958\n",
      "Epoch 7/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: -0.0139 - acc: 0.9980\n",
      "New maximum F1 score: 0.8457815565729234 (before: 0.8434978171715836) Saving to model_lstm_conll.2.h5\n",
      "380/380 [==============================] - 252s 663ms/step - loss: -0.0139 - acc: 0.9980 - val_loss: -0.0100 - val_acc: 0.9959\n",
      "Epoch 8/10\n",
      "380/380 [==============================] - 255s 670ms/step - loss: -0.0202 - acc: 0.9982 - val_loss: -0.0161 - val_acc: 0.9959\n",
      "Epoch 9/10\n",
      "380/380 [==============================] - 249s 656ms/step - loss: -0.0268 - acc: 0.9984 - val_loss: -0.0218 - val_acc: 0.9958\n",
      "Epoch 10/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: -0.0336 - acc: 0.9985\n",
      "New maximum F1 score: 0.8496210610291185 (before: 0.8457815565729234) Saving to model_lstm_conll.2.h5\n",
      "380/380 [==============================] - 252s 662ms/step - loss: -0.0336 - acc: 0.9985 - val_loss: -0.0289 - val_acc: 0.9960\n",
      "Epoch 1/10\n",
      "47/48 [============================>.] - ETA: 1s - loss: -0.0382 - acc: 0.9989\n",
      "New maximum F1 score: 0.8512981904012588 (before: 0.8496210610291185) Saving to model_lstm_conll.2.h5\n",
      "48/48 [==============================] - 107s 2s/step - loss: -0.0382 - acc: 0.9989 - val_loss: -0.0299 - val_acc: 0.9961\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 88s 2s/step - loss: -0.0392 - acc: 0.9990 - val_loss: -0.0305 - val_acc: 0.9961\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 88s 2s/step - loss: -0.0403 - acc: 0.9990 - val_loss: -0.0311 - val_acc: 0.9960\n",
      "Epoch 4/10\n",
      "47/48 [============================>.] - ETA: 0s - loss: -0.0412 - acc: 0.9991\n",
      "New maximum F1 score: 0.8517110266159696 (before: 0.8512981904012588) Saving to model_lstm_conll.2.h5\n",
      "48/48 [==============================] - 90s 2s/step - loss: -0.0412 - acc: 0.9991 - val_loss: -0.0320 - val_acc: 0.9961\n",
      "Epoch 5/10\n",
      "47/48 [============================>.] - ETA: 0s - loss: -0.0421 - acc: 0.9991\n",
      "New maximum F1 score: 0.8521876231769806 (before: 0.8517110266159696) Saving to model_lstm_conll.2.h5\n",
      "48/48 [==============================] - 89s 2s/step - loss: -0.0421 - acc: 0.9991 - val_loss: -0.0329 - val_acc: 0.9961\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 89s 2s/step - loss: -0.0432 - acc: 0.9992 - val_loss: -0.0334 - val_acc: 0.9961\n",
      "Epoch 7/10\n",
      "47/48 [============================>.] - ETA: 0s - loss: -0.0441 - acc: 0.9992\n",
      "New maximum F1 score: 0.8548916611950099 (before: 0.8521876231769806) Saving to model_lstm_conll.2.h5\n",
      "48/48 [==============================] - 87s 2s/step - loss: -0.0441 - acc: 0.9992 - val_loss: -0.0345 - val_acc: 0.9961\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 88s 2s/step - loss: -0.0451 - acc: 0.9993 - val_loss: -0.0352 - val_acc: 0.9961\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 88s 2s/step - loss: -0.0460 - acc: 0.9993 - val_loss: -0.0360 - val_acc: 0.9961\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 86s 2s/step - loss: -0.0470 - acc: 0.9993 - val_loss: -0.0367 - val_acc: 0.9961\n",
      "Run 3\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 52)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 52, 32) 3328        char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, None, 100)    33200       char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, None, 408)    0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, None, 400)    974400      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "crf (CRF)                       (None, None, 10)     4130        bidirectional_8[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,015,122\n",
      "Trainable params: 1,015,058\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9906\n",
      "New maximum F1 score: 0.7797169163116668 (before: 0) Saving to model_lstm_conll.3.h5\n",
      "380/380 [==============================] - 258s 678ms/step - loss: 0.0384 - acc: 0.9906 - val_loss: 0.0231 - val_acc: 0.9942\n",
      "Epoch 2/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9959\n",
      "New maximum F1 score: 0.8141568734626947 (before: 0.7797169163116668) Saving to model_lstm_conll.3.h5\n",
      "380/380 [==============================] - 247s 651ms/step - loss: 0.0156 - acc: 0.9959 - val_loss: 0.0171 - val_acc: 0.9951\n",
      "Epoch 3/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9966\n",
      "New maximum F1 score: 0.8233408999866471 (before: 0.8141568734626947) Saving to model_lstm_conll.3.h5\n",
      "380/380 [==============================] - 249s 655ms/step - loss: 0.0103 - acc: 0.9966 - val_loss: 0.0128 - val_acc: 0.9954\n",
      "Epoch 4/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9971\n",
      "New maximum F1 score: 0.8373983739837398 (before: 0.8233408999866471) Saving to model_lstm_conll.3.h5\n",
      "380/380 [==============================] - 246s 648ms/step - loss: 0.0053 - acc: 0.9971 - val_loss: 0.0080 - val_acc: 0.9957\n",
      "Epoch 5/10\n",
      "380/380 [==============================] - 248s 653ms/step - loss: 1.1785e-04 - acc: 0.9974 - val_loss: 0.0035 - val_acc: 0.9956\n",
      "Epoch 6/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: -0.0055 - acc: 0.9978\n",
      "New maximum F1 score: 0.8428155596718708 (before: 0.8373983739837398) Saving to model_lstm_conll.3.h5\n",
      "380/380 [==============================] - 247s 649ms/step - loss: -0.0055 - acc: 0.9978 - val_loss: -0.0016 - val_acc: 0.9958\n",
      "Epoch 7/10\n",
      "380/380 [==============================] - 250s 658ms/step - loss: -0.0113 - acc: 0.9979 - val_loss: -0.0068 - val_acc: 0.9957\n",
      "Epoch 8/10\n",
      "380/380 [==============================] - 250s 658ms/step - loss: -0.0177 - acc: 0.9982 - val_loss: -0.0125 - val_acc: 0.9956\n",
      "Epoch 9/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: -0.0244 - acc: 0.9984\n",
      "New maximum F1 score: 0.8470744680851064 (before: 0.8428155596718708) Saving to model_lstm_conll.3.h5\n",
      "380/380 [==============================] - 252s 662ms/step - loss: -0.0244 - acc: 0.9984 - val_loss: -0.0193 - val_acc: 0.9959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: -0.0314 - acc: 0.9987\n",
      "New maximum F1 score: 0.8516060525617203 (before: 0.8470744680851064) Saving to model_lstm_conll.3.h5\n",
      "380/380 [==============================] - 251s 662ms/step - loss: -0.0315 - acc: 0.9987 - val_loss: -0.0262 - val_acc: 0.9959\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 108s 2s/step - loss: -0.0360 - acc: 0.9989 - val_loss: -0.0271 - val_acc: 0.9960\n",
      "Epoch 2/10\n",
      "47/48 [============================>.] - ETA: 0s - loss: -0.0371 - acc: 0.9990\n",
      "New maximum F1 score: 0.8525490196078431 (before: 0.8516060525617203) Saving to model_lstm_conll.3.h5\n",
      "48/48 [==============================] - 88s 2s/step - loss: -0.0371 - acc: 0.9990 - val_loss: -0.0279 - val_acc: 0.9960\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 91s 2s/step - loss: -0.0380 - acc: 0.9991 - val_loss: -0.0286 - val_acc: 0.9960\n",
      "Epoch 4/10\n",
      "47/48 [============================>.] - ETA: 0s - loss: -0.0389 - acc: 0.9991\n",
      "New maximum F1 score: 0.8541830579596119 (before: 0.8525490196078431) Saving to model_lstm_conll.3.h5\n",
      "48/48 [==============================] - 89s 2s/step - loss: -0.0389 - acc: 0.9991 - val_loss: -0.0296 - val_acc: 0.9961\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 90s 2s/step - loss: -0.0400 - acc: 0.9991 - val_loss: -0.0304 - val_acc: 0.9960\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 89s 2s/step - loss: -0.0410 - acc: 0.9992 - val_loss: -0.0309 - val_acc: 0.9960\n",
      "Epoch 7/10\n",
      "47/48 [============================>.] - ETA: 0s - loss: -0.0419 - acc: 0.9992\n",
      "New maximum F1 score: 0.8549960453466913 (before: 0.8541830579596119) Saving to model_lstm_conll.3.h5\n",
      "48/48 [==============================] - 88s 2s/step - loss: -0.0419 - acc: 0.9992 - val_loss: -0.0319 - val_acc: 0.9961\n",
      "Epoch 8/10\n",
      "47/48 [============================>.] - ETA: 0s - loss: -0.0429 - acc: 0.9993\n",
      "New maximum F1 score: 0.8551236749116609 (before: 0.8549960453466913) Saving to model_lstm_conll.3.h5\n",
      "48/48 [==============================] - 89s 2s/step - loss: -0.0429 - acc: 0.9993 - val_loss: -0.0328 - val_acc: 0.9961\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 90s 2s/step - loss: -0.0439 - acc: 0.9993 - val_loss: -0.0337 - val_acc: 0.9960\n",
      "Epoch 10/10\n",
      "47/48 [============================>.] - ETA: 0s - loss: -0.0448 - acc: 0.9993\n",
      "New maximum F1 score: 0.8552666141318624 (before: 0.8551236749116609) Saving to model_lstm_conll.3.h5\n",
      "48/48 [==============================] - 91s 2s/step - loss: -0.0448 - acc: 0.9993 - val_loss: -0.0344 - val_acc: 0.9961\n",
      "Run 4\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 52)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 52, 32) 3328        char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, None, 100)    33200       char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, None, 408)    0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, None, 400)    974400      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "crf (CRF)                       (None, None, 10)     4130        bidirectional_10[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 1,015,122\n",
      "Trainable params: 1,015,058\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: 0.0386 - acc: 0.9904\n",
      "New maximum F1 score: 0.7716809421841541 (before: 0) Saving to model_lstm_conll.4.h5\n",
      "380/380 [==============================] - 264s 694ms/step - loss: 0.0385 - acc: 0.9904 - val_loss: 0.0217 - val_acc: 0.9943\n",
      "Epoch 2/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9959\n",
      "New maximum F1 score: 0.7951741157115437 (before: 0.7716809421841541) Saving to model_lstm_conll.4.h5\n",
      "380/380 [==============================] - 251s 660ms/step - loss: 0.0144 - acc: 0.9959 - val_loss: 0.0177 - val_acc: 0.9946\n",
      "Epoch 3/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9967\n",
      "New maximum F1 score: 0.8188890405350074 (before: 0.7951741157115437) Saving to model_lstm_conll.4.h5\n",
      "380/380 [==============================] - 251s 661ms/step - loss: 0.0089 - acc: 0.9967 - val_loss: 0.0123 - val_acc: 0.9952\n",
      "Epoch 4/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9972\n",
      "New maximum F1 score: 0.8327097808658472 (before: 0.8188890405350074) Saving to model_lstm_conll.4.h5\n",
      "380/380 [==============================] - 252s 663ms/step - loss: 0.0040 - acc: 0.9972 - val_loss: 0.0071 - val_acc: 0.9957\n",
      "Epoch 5/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: -8.1129e-04 - acc: 0.9975\n",
      "New maximum F1 score: 0.8349285433328963 (before: 0.8327097808658472) Saving to model_lstm_conll.4.h5\n",
      "380/380 [==============================] - 252s 664ms/step - loss: -8.2781e-04 - acc: 0.9975 - val_loss: 0.0025 - val_acc: 0.9957\n",
      "Epoch 6/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: -0.0063 - acc: 0.9978\n",
      "New maximum F1 score: 0.8389493234279649 (before: 0.8349285433328963) Saving to model_lstm_conll.4.h5\n",
      "380/380 [==============================] - 251s 662ms/step - loss: -0.0063 - acc: 0.9978 - val_loss: -0.0021 - val_acc: 0.9957\n",
      "Epoch 7/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: -0.0119 - acc: 0.9980\n",
      "New maximum F1 score: 0.8454233711421789 (before: 0.8389493234279649) Saving to model_lstm_conll.4.h5\n",
      "380/380 [==============================] - 251s 661ms/step - loss: -0.0120 - acc: 0.9980 - val_loss: -0.0078 - val_acc: 0.9959\n",
      "Epoch 8/10\n",
      "380/380 [==============================] - 253s 665ms/step - loss: -0.0182 - acc: 0.9983 - val_loss: -0.0130 - val_acc: 0.9957\n",
      "Epoch 9/10\n",
      "380/380 [==============================] - 252s 662ms/step - loss: -0.0247 - acc: 0.9984 - val_loss: -0.0199 - val_acc: 0.9957\n",
      "Epoch 10/10\n",
      "380/380 [==============================] - 251s 660ms/step - loss: -0.0316 - acc: 0.9986 - val_loss: -0.0259 - val_acc: 0.9958\n",
      "Epoch 1/10\n",
      "47/48 [============================>.] - ETA: 1s - loss: -0.0161 - acc: 0.9985\n",
      "New maximum F1 score: 0.8487715149126265 (before: 0.8454233711421789) Saving to model_lstm_conll.4.h5\n",
      "48/48 [==============================] - 109s 2s/step - loss: -0.0162 - acc: 0.9985 - val_loss: -0.0090 - val_acc: 0.9960\n",
      "Epoch 2/10\n",
      "47/48 [============================>.] - ETA: 0s - loss: -0.0173 - acc: 0.9986\n",
      "New maximum F1 score: 0.8494708994708996 (before: 0.8487715149126265) Saving to model_lstm_conll.4.h5\n",
      "48/48 [==============================] - 89s 2s/step - loss: -0.0174 - acc: 0.9986 - val_loss: -0.0096 - val_acc: 0.9960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "47/48 [============================>.] - ETA: 0s - loss: -0.0184 - acc: 0.9986\n",
      "New maximum F1 score: 0.8511873350923482 (before: 0.8494708994708996) Saving to model_lstm_conll.4.h5\n",
      "48/48 [==============================] - 89s 2s/step - loss: -0.0184 - acc: 0.9986 - val_loss: -0.0106 - val_acc: 0.9960\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 90s 2s/step - loss: -0.0194 - acc: 0.9988 - val_loss: -0.0111 - val_acc: 0.9960\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 88s 2s/step - loss: -0.0204 - acc: 0.9987 - val_loss: -0.0121 - val_acc: 0.9960\n",
      "Epoch 6/10\n",
      "47/48 [============================>.] - ETA: 0s - loss: -0.0213 - acc: 0.9988\n",
      "New maximum F1 score: 0.8530843088254637 (before: 0.8511873350923482) Saving to model_lstm_conll.4.h5\n",
      "48/48 [==============================] - 89s 2s/step - loss: -0.0213 - acc: 0.9988 - val_loss: -0.0130 - val_acc: 0.9960\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 89s 2s/step - loss: -0.0224 - acc: 0.9988 - val_loss: -0.0138 - val_acc: 0.9960\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 90s 2s/step - loss: -0.0234 - acc: 0.9989 - val_loss: -0.0147 - val_acc: 0.9960\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 89s 2s/step - loss: -0.0244 - acc: 0.9989 - val_loss: -0.0152 - val_acc: 0.9960\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 91s 2s/step - loss: -0.0253 - acc: 0.9989 - val_loss: -0.0163 - val_acc: 0.9960\n",
      "Run 5\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 52)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 52, 32) 3328        char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, None, 100)    33200       char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, None, 408)    0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, None, 400)    974400      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "crf (CRF)                       (None, None, 10)     4130        bidirectional_12[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 1,015,122\n",
      "Trainable params: 1,015,058\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 0.9902\n",
      "New maximum F1 score: 0.7799945340256901 (before: 0) Saving to model_lstm_conll.5.h5\n",
      "380/380 [==============================] - 276s 726ms/step - loss: 0.0364 - acc: 0.9902 - val_loss: 0.0194 - val_acc: 0.9943\n",
      "Epoch 2/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9959\n",
      "New maximum F1 score: 0.8157539789587268 (before: 0.7799945340256901) Saving to model_lstm_conll.5.h5\n",
      "380/380 [==============================] - 260s 684ms/step - loss: 0.0113 - acc: 0.9959 - val_loss: 0.0128 - val_acc: 0.9951\n",
      "Epoch 3/10\n",
      " 68/380 [====>.........................] - ETA: 3:08 - loss: 0.0072 - acc: 0.9965"
     ]
    }
   ],
   "source": [
    "f = open('results_lstm_conll.txt', 'a')\n",
    "for run_i in range(10):\n",
    "    print(\"Run \" + str(run_i))\n",
    "    \n",
    "    tmp_model_filename = 'model_lstm_conll.' + str(run_i) + '.h5'\n",
    "\n",
    "    history = utils.F1History(tmp_model_filename, devSet=devSentences)\n",
    "\n",
    "    model = models.get_model_lstm_v2()\n",
    "    model.fit_generator(\n",
    "        utils.NerSequence(trainSentences, shuffle_data=True, batch_size=32), \n",
    "        validation_data = utils.NerSequence(devSentences, batch_size=512), \n",
    "        epochs = 10, callbacks = [history]\n",
    "    )\n",
    "    \n",
    "    model.load_weights(tmp_model_filename)\n",
    "    \n",
    "    model.fit_generator(\n",
    "        utils.NerSequence(trainSentences, shuffle_data=True, batch_size=256), \n",
    "        validation_data = utils.NerSequence(devSentences, batch_size=512), \n",
    "        epochs = 10, callbacks = [history]\n",
    "    )\n",
    "    \n",
    "    model.load_weights(tmp_model_filename)\n",
    "    \n",
    "    true_labels, pred_labels = utils.predict_sequences(model, testSentences)\n",
    "    \n",
    "    pre, rec, f1 = compute_f1(pred_labels, true_labels, models.idx2Label)\n",
    "    f.write(str(run_i) + \"\\t\" + str(pre) + \"\\t\" + str(rec) +  \"\\t\" + str(f1))\n",
    "    f.write(\"\\n\")\n",
    "    f.flush()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../models/final_model_conll.indexes'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil, json\n",
    "# copy file for best run\n",
    "shutil.copyfile('model_lstm_conll.9.h5', '../models/final_model_conll.h5')\n",
    "shutil.copyfile('model_lstm_conll.9.h5.indexes', '../models/final_model_conll.indexes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8722241202596516, 0.8370491803278689, 0.8542747197590764)\n"
     ]
    }
   ],
   "source": [
    "from keras_contrib.layers import CRF\n",
    "def create_custom_objects():\n",
    "    instanceHolder = {\"instance\": None}\n",
    "    class ClassWrapper(CRF):\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            instanceHolder[\"instance\"] = self\n",
    "            super(ClassWrapper, self).__init__(*args, **kwargs)\n",
    "    def loss(*args):\n",
    "        method = getattr(instanceHolder[\"instance\"], \"loss_function\")\n",
    "        return method(*args)\n",
    "    def accuracy(*args):\n",
    "        method = getattr(instanceHolder[\"instance\"], \"accuracy\")\n",
    "        return method(*args)\n",
    "    return {\"ClassWrapper\": ClassWrapper ,\"CRF\": ClassWrapper, \"loss\": loss, \"accuracy\":accuracy}\n",
    "\n",
    "finalmodel = load_model('../models/final_model_conll.h5', custom_objects=create_custom_objects())\n",
    "true_labels, pred_labels = utils.predict_sequences(finalmodel, testSentences)\n",
    "print(compute_f1(pred_labels, true_labels, models.idx2Label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close()>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('conll_output.tsv', 'w', encoding='UTF-8')\n",
    "for i_sent, sent in enumerate(testSentences):\n",
    "    for i_tok, tok in enumerate(sent):\n",
    "        if tok[0] == 'PADDING_TOKEN':\n",
    "            break\n",
    "        correctlabel = models.idx2Label[true_labels[i_sent][i_tok]]\n",
    "        guessedlabel = models.idx2Label[pred_labels[i_sent][i_tok]]\n",
    "        line = \" \".join([tok[0], correctlabel, guessedlabel])\n",
    "        f.write(line + '\\n')\n",
    "    f.write('\\n')\n",
    "f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
