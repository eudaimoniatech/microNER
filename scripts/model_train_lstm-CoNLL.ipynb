{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gwiedemann/miniconda3/envs/kerasenv/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import fastText\n",
    "\n",
    "from validation import compute_f1\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "\n",
    "import models\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12152\n",
      "2867\n",
      "3005\n"
     ]
    }
   ],
   "source": [
    "# trainSentences = utils.get_sentences_germeval('../data/GermEVAL/NER-de-train.tsv')\n",
    "# devSentences = utils.get_sentences_germeval('../data/GermEVAL/NER-de-dev.tsv')\n",
    "# testSentences = utils.get_sentences_germeval('../data/GermEVAL/NER-de-test.tsv')\n",
    "\n",
    "trainSentences = utils.get_sentences_conll('../data/CONLL/deu/deu_utf.train.bio')\n",
    "devSentences = utils.get_sentences_conll('../data/CONLL/deu/deu_utf.testa.bio')\n",
    "testSentences = utils.get_sentences_conll('../data/CONLL/deu/deu_utf.testb.bio')\n",
    "\n",
    "print(len(trainSentences))\n",
    "print(len(devSentences))\n",
    "print(len(testSentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Die', 'O'], ['sechs', 'O'], ['Abgeordneten', 'O'], ['der', 'O'], ['Grünen', 'B-ORG'], [',', 'O'], ['die', 'O'], ['seit', 'O'], ['Bildung', 'O'], ['einer', 'O'], ['Großen', 'O'], ['Koalition', 'O'], ['von', 'O'], ['Christ-', 'O'], ['und', 'O'], ['Sozialdemokraten', 'O'], ['die', 'O'], ['Opposition', 'O'], ['darstellen', 'O'], [',', 'O'], ['hatten', 'O'], ['sich', 'O'], ['beim', 'O'], ['Vorsteher', 'O'], ['Rainer', 'B-PER'], ['Bergert', 'I-PER'], ['für', 'O'], ['ihr', 'O'], ['Fehlen', 'O'], ['entschuldigen', 'O'], ['lassen', 'O'], ['.', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(testSentences[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "labelSet = set()\n",
    "characters= set()\n",
    "models.max_sequence_length = 0\n",
    "n_gt_100 = 0\n",
    "for dataset in [trainSentences, devSentences, testSentences]:\n",
    "    for sentence in dataset:\n",
    "        for word, label in sentence:\n",
    "            for char in word:\n",
    "                characters.add(char)\n",
    "            labelSet.add(label)\n",
    "        if len(sentence) > models.max_sequence_length:\n",
    "            models.max_sequence_length = len(sentence)\n",
    "        if len(sentence) > 100:\n",
    "            n_gt_100 += 1\n",
    "print(n_gt_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(labelSet))\n",
    "print(models.max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# :: Create a mapping for the labels ::\n",
    "models.label2Idx = {\"PADDING_TOKEN\":0}\n",
    "for label in labelSet:\n",
    "    models.label2Idx[label] = len(models.label2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-ORG': 1, 'I-PER': 2, 'PADDING_TOKEN': 0, 'O': 6, 'B-PER': 4, 'I-ORG': 7, 'B-MISC': 3, 'B-LOC': 8, 'I-LOC': 5, 'I-MISC': 9}\n"
     ]
    }
   ],
   "source": [
    "print(models.label2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# :: Hard coded case lookup ::\n",
    "models.case2Idx = {'PADDING_TOKEN':0, 'numeric': 1, 'allLower':2, 'allUpper':3, 'initialUpper':4, 'other':5, 'mainly_numeric':6, 'contains_digit': 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'contains_digit': 7, 'PADDING_TOKEN': 0, 'allUpper': 3, 'other': 5, 'numeric': 1, 'initialUpper': 4, 'allLower': 2, 'mainly_numeric': 6}\n"
     ]
    }
   ],
   "source": [
    "print(models.case2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(trainSentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Ereignis', 'O'], ['und', 'O'], ['Erzählung', 'O'], ['oder', 'O'], [':', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(trainSentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<S>': 1, '7': 6, '<W>': 3, 'a': 62, 'J': 63, ')': 7, 'x': 5, '/': 9, 'v': 87, 'Q': 11, '=': 14, '3': 12, '-': 13, 'T': 60, 'P': 61, 'I': 69, 'A': 65, 'ì': 15, '4': 66, 'é': 16, 'ô': 17, 'p': 67, ',': 18, '!': 68, 'b': 95, '§': 70, 'O': 19, 'ñ': 72, 'ü': 73, '%': 20, 'q': 21, 'ç': 22, '9': 74, 'ä': 23, 'W': 24, 'c': 25, 'ö': 26, 'U': 27, 'V': 8, 'D': 76, '&': 77, 'u': 78, 'd': 28, 't': 29, 'í': 79, '\"': 30, 's': 31, 'ß': 32, 'z': 80, '8': 83, 'Y': 34, 'S': 81, 'e': 35, '</S>': 2, 'N': 36, 'X': 37, '5': 38, '</W>': 4, 'l': 39, 'G': 41, 'PADDING_TOKEN': 0, 'f': 42, 'Z': 44, 'n': 85, 'E': 86, 'Ö': 88, '2': 89, 'ê': 90, '*': 82, '(': 45, 'M': 46, 'L': 47, 'j': 48, '+': 91, '6': 49, 'g': 40, '1': 92, 'Ü': 50, 'm': 57, '0': 102, 'i': 84, 'h': 93, 'B': 51, ';': 52, \"'\": 94, ':': 53, 'Ä': 54, 'K': 33, 'á': 55, 'r': 96, 'y': 56, 'è': 43, '?': 97, 'F': 98, 'H': 64, 'UNKNOWN': 103, 'ò': 71, 'R': 58, 'w': 99, 'o': 100, '.': 101, 'k': 75, 'C': 10, 'ó': 59}\n"
     ]
    }
   ],
   "source": [
    "models.char2Idx={\"PADDING_TOKEN\":0, \"<S>\":1, \"</S>\":2, \"<W>\":3, \"</W>\":4}\n",
    "for char in characters:\n",
    "    models.char2Idx[char] = len(models.char2Idx)\n",
    "models.char2Idx['UNKNOWN'] = len(models.char2Idx)\n",
    "print(models.char2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Ereignis', 'O'], ['und', 'O'], ['Erzählung', 'O'], ['oder', 'O'], [':', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(trainSentences[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.ft = fastText.load_model(\"../embeddings/wiki.de.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(models.nb_embedding_dims)\n",
    "print(len(trainSentences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "models.idx2Label = {v: k for k, v in models.label2Idx.items()}\n",
    "print(len(models.label2Idx))\n",
    "print(len(models.idx2Label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# importlib.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_model_filename = 'model_lstm_conll.h5'\n",
    "# checkpoint = ModelCheckpoint(tmp_model_filename, verbose=1, save_best_only = True, monitor = 'val_acc')\n",
    "history = utils.F1History(tmp_model_filename, devSet = devSentences)\n",
    "model = models.get_model_lstm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import importlib\n",
    "#importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    utils.NerSequence(trainSentences[:1000], shuffle_data=True, batch_size=256), \n",
    "    validation_data = utils.NerSequence(devSentences[:1000], batch_size=256), \n",
    "    epochs = 3, callbacks = [history]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.acc)\n",
    "print(history.f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(tmp_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    utils.NerSequence(trainSentences, shuffle_data=True, batch_size=2048), \n",
    "    validation_data = utils.NerSequence(devSentences, batch_size=256), \n",
    "    epochs = 5, callbacks = [history]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(tmp_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels, pred_labels = utils.predict_sequences(model, testSentences[:1000])\n",
    "print(compute_f1(pred_labels, true_labels, models.idx2Label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 52)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 52, 32) 3328        char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, None, 100)    33200       char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 408)    0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, None, 400)    974400      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "crf (CRF)                       (None, None, 10)     4130        bidirectional_2[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,015,122\n",
      "Trainable params: 1,015,058\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: 0.0355 - acc: 0.9901\n",
      "New maximum F1 score: 0.7797853552506453 (before: 0) Saving to model_lstm_conll.0.h5\n",
      "380/380 [==============================] - 249s 655ms/step - loss: 0.0354 - acc: 0.9901 - val_loss: 0.0167 - val_acc: 0.9944\n",
      "Epoch 2/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9959\n",
      "New maximum F1 score: 0.8159045725646124 (before: 0.7797853552506453) Saving to model_lstm_conll.0.h5\n",
      "380/380 [==============================] - 242s 637ms/step - loss: 0.0092 - acc: 0.9959 - val_loss: 0.0108 - val_acc: 0.9951\n",
      "Epoch 3/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9965\n",
      "New maximum F1 score: 0.8212298086059455 (before: 0.8159045725646124) Saving to model_lstm_conll.0.h5\n",
      "380/380 [==============================] - 243s 640ms/step - loss: 0.0040 - acc: 0.9965 - val_loss: 0.0068 - val_acc: 0.9953\n",
      "Epoch 4/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: -8.1749e-04 - acc: 0.9971\n",
      "New maximum F1 score: 0.8291376539903589 (before: 0.8212298086059455) Saving to model_lstm_conll.0.h5\n",
      "380/380 [==============================] - 242s 636ms/step - loss: -8.1884e-04 - acc: 0.9971 - val_loss: 0.0023 - val_acc: 0.9954\n",
      "Epoch 5/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: -0.0057 - acc: 0.9974\n",
      "New maximum F1 score: 0.8401447139220154 (before: 0.8291376539903589) Saving to model_lstm_conll.0.h5\n",
      "380/380 [==============================] - 240s 631ms/step - loss: -0.0057 - acc: 0.9974 - val_loss: -0.0027 - val_acc: 0.9958\n",
      "Epoch 6/10\n",
      "380/380 [==============================] - 240s 632ms/step - loss: -0.0110 - acc: 0.9977 - val_loss: -0.0072 - val_acc: 0.9958\n",
      "Epoch 7/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: -0.0168 - acc: 0.9980\n",
      "New maximum F1 score: 0.841858648965248 (before: 0.8401447139220154) Saving to model_lstm_conll.0.h5\n",
      "380/380 [==============================] - 242s 637ms/step - loss: -0.0169 - acc: 0.9980 - val_loss: -0.0131 - val_acc: 0.9958\n",
      "Epoch 8/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: -0.0228 - acc: 0.9982\n",
      "New maximum F1 score: 0.8524937161000132 (before: 0.841858648965248) Saving to model_lstm_conll.0.h5\n",
      "380/380 [==============================] - 243s 639ms/step - loss: -0.0229 - acc: 0.9982 - val_loss: -0.0186 - val_acc: 0.9960\n",
      "Epoch 9/10\n",
      "380/380 [==============================] - 242s 637ms/step - loss: -0.0294 - acc: 0.9984 - val_loss: -0.0238 - val_acc: 0.9959\n",
      "Epoch 10/10\n",
      "380/380 [==============================] - 242s 638ms/step - loss: -0.0363 - acc: 0.9986 - val_loss: -0.0313 - val_acc: 0.9960\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 108s 2s/step - loss: -0.0271 - acc: 0.9985 - val_loss: -0.0199 - val_acc: 0.9961\n",
      "Epoch 2/10\n",
      "47/48 [============================>.] - ETA: 0s - loss: -0.0283 - acc: 0.9987\n",
      "New maximum F1 score: 0.8555584895695801 (before: 0.8524937161000132) Saving to model_lstm_conll.0.h5\n",
      "48/48 [==============================] - 88s 2s/step - loss: -0.0283 - acc: 0.9987 - val_loss: -0.0208 - val_acc: 0.9962\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 88s 2s/step - loss: -0.0293 - acc: 0.9987 - val_loss: -0.0215 - val_acc: 0.9961\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 89s 2s/step - loss: -0.0303 - acc: 0.9988 - val_loss: -0.0224 - val_acc: 0.9961\n",
      "Epoch 5/10\n",
      "47/48 [============================>.] - ETA: 0s - loss: -0.0313 - acc: 0.9989\n",
      "New maximum F1 score: 0.8556795797767565 (before: 0.8555584895695801) Saving to model_lstm_conll.0.h5\n",
      "48/48 [==============================] - 89s 2s/step - loss: -0.0313 - acc: 0.9989 - val_loss: -0.0233 - val_acc: 0.9961\n",
      "Epoch 6/10\n",
      "47/48 [============================>.] - ETA: 0s - loss: -0.0323 - acc: 0.9989\n",
      "New maximum F1 score: 0.8581550977562 (before: 0.8556795797767565) Saving to model_lstm_conll.0.h5\n",
      "48/48 [==============================] - 90s 2s/step - loss: -0.0323 - acc: 0.9989 - val_loss: -0.0241 - val_acc: 0.9962\n",
      "Epoch 7/10\n",
      "47/48 [============================>.] - ETA: 0s - loss: -0.0332 - acc: 0.9989\n",
      "New maximum F1 score: 0.8588002636783124 (before: 0.8581550977562) Saving to model_lstm_conll.0.h5\n",
      "48/48 [==============================] - 88s 2s/step - loss: -0.0332 - acc: 0.9989 - val_loss: -0.0248 - val_acc: 0.9962\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 86s 2s/step - loss: -0.0342 - acc: 0.9990 - val_loss: -0.0254 - val_acc: 0.9961\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 87s 2s/step - loss: -0.0352 - acc: 0.9990 - val_loss: -0.0264 - val_acc: 0.9961\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 88s 2s/step - loss: -0.0361 - acc: 0.9990 - val_loss: -0.0273 - val_acc: 0.9961\n",
      "Run 1\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 52)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 52, 32) 3328        char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, None, 100)    33200       char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, 408)    0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, None, 400)    974400      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "crf (CRF)                       (None, None, 10)     4130        bidirectional_4[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,015,122\n",
      "Trainable params: 1,015,058\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: 0.0394 - acc: 0.9900\n",
      "New maximum F1 score: 0.7657776604172168 (before: 0) Saving to model_lstm_conll.1.h5\n",
      "380/380 [==============================] - 250s 658ms/step - loss: 0.0393 - acc: 0.9900 - val_loss: 0.0212 - val_acc: 0.9942\n",
      "Epoch 2/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9958\n",
      "New maximum F1 score: 0.7961579509071505 (before: 0.7657776604172168) Saving to model_lstm_conll.1.h5\n",
      "380/380 [==============================] - 241s 634ms/step - loss: 0.0139 - acc: 0.9959 - val_loss: 0.0159 - val_acc: 0.9948\n",
      "Epoch 3/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9965\n",
      "New maximum F1 score: 0.8174667751559533 (before: 0.7961579509071505) Saving to model_lstm_conll.1.h5\n",
      "380/380 [==============================] - 242s 638ms/step - loss: 0.0085 - acc: 0.9965 - val_loss: 0.0113 - val_acc: 0.9953\n",
      "Epoch 4/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9970\n",
      "New maximum F1 score: 0.8274294880363587 (before: 0.8174667751559533) Saving to model_lstm_conll.1.h5\n",
      "380/380 [==============================] - 241s 634ms/step - loss: 0.0037 - acc: 0.9970 - val_loss: 0.0066 - val_acc: 0.9955\n",
      "Epoch 5/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: -0.0013 - acc: 0.9975\n",
      "New maximum F1 score: 0.8368476541908276 (before: 0.8274294880363587) Saving to model_lstm_conll.1.h5\n",
      "380/380 [==============================] - 253s 666ms/step - loss: -0.0013 - acc: 0.9975 - val_loss: 0.0018 - val_acc: 0.9957\n",
      "Epoch 6/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: -0.0066 - acc: 0.9976\n",
      "New maximum F1 score: 0.8431628392484343 (before: 0.8368476541908276) Saving to model_lstm_conll.1.h5\n",
      "380/380 [==============================] - 246s 647ms/step - loss: -0.0066 - acc: 0.9976 - val_loss: -0.0031 - val_acc: 0.9958\n",
      "Epoch 7/10\n",
      "379/380 [============================>.] - ETA: 0s - loss: -0.0124 - acc: 0.9980\n",
      "New maximum F1 score: 0.8509391234847475 (before: 0.8431628392484343) Saving to model_lstm_conll.1.h5\n",
      "380/380 [==============================] - 246s 648ms/step - loss: -0.0123 - acc: 0.9980 - val_loss: -0.0087 - val_acc: 0.9960\n",
      "Epoch 8/10\n",
      "380/380 [==============================] - 246s 648ms/step - loss: -0.0185 - acc: 0.9982 - val_loss: -0.0143 - val_acc: 0.9958\n",
      "Epoch 9/10\n",
      "380/380 [==============================] - 247s 651ms/step - loss: -0.0250 - acc: 0.9984 - val_loss: -0.0203 - val_acc: 0.9959\n",
      "Epoch 10/10\n",
      "380/380 [==============================] - 247s 650ms/step - loss: -0.0320 - acc: 0.9986 - val_loss: -0.0266 - val_acc: 0.9959\n",
      "Epoch 1/10\n",
      "47/48 [============================>.] - ETA: 1s - loss: -0.0166 - acc: 0.9984\n",
      "New maximum F1 score: 0.8523897544230262 (before: 0.8509391234847475) Saving to model_lstm_conll.1.h5\n",
      "48/48 [==============================] - 107s 2s/step - loss: -0.0165 - acc: 0.9984 - val_loss: -0.0096 - val_acc: 0.9960\n",
      "Epoch 2/10\n",
      "47/48 [============================>.] - ETA: 0s - loss: -0.0177 - acc: 0.9985\n",
      "New maximum F1 score: 0.8547234718179412 (before: 0.8523897544230262) Saving to model_lstm_conll.1.h5\n",
      "48/48 [==============================] - 89s 2s/step - loss: -0.0177 - acc: 0.9985 - val_loss: -0.0103 - val_acc: 0.9961\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 90s 2s/step - loss: -0.0187 - acc: 0.9985 - val_loss: -0.0111 - val_acc: 0.9961\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 88s 2s/step - loss: -0.0198 - acc: 0.9987 - val_loss: -0.0121 - val_acc: 0.9960\n",
      "Epoch 5/10\n",
      "47/48 [============================>.] - ETA: 0s - loss: -0.0207 - acc: 0.9987\n",
      "New maximum F1 score: 0.8554153522607781 (before: 0.8547234718179412) Saving to model_lstm_conll.1.h5\n",
      "48/48 [==============================] - 90s 2s/step - loss: -0.0207 - acc: 0.9987 - val_loss: -0.0129 - val_acc: 0.9961\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 88s 2s/step - loss: -0.0217 - acc: 0.9987 - val_loss: -0.0137 - val_acc: 0.9961\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 88s 2s/step - loss: -0.0227 - acc: 0.9988 - val_loss: -0.0145 - val_acc: 0.9961\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 90s 2s/step - loss: -0.0237 - acc: 0.9988 - val_loss: -0.0155 - val_acc: 0.9961\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 89s 2s/step - loss: -0.0247 - acc: 0.9989 - val_loss: -0.0160 - val_acc: 0.9961\n",
      "Epoch 10/10\n",
      "47/48 [============================>.] - ETA: 0s - loss: -0.0256 - acc: 0.9988\n",
      "New maximum F1 score: 0.8592964824120604 (before: 0.8554153522607781) Saving to model_lstm_conll.1.h5\n",
      "48/48 [==============================] - 88s 2s/step - loss: -0.0256 - acc: 0.9988 - val_loss: -0.0170 - val_acc: 0.9963\n",
      "Run 2\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 52)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 52, 32) 3328        char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, None, 100)    33200       char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, None, 408)    0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, None, 400)    974400      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "crf (CRF)                       (None, None, 10)     4130        bidirectional_6[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,015,122\n",
      "Trainable params: 1,015,058\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "259/380 [===================>..........] - ETA: 1:13 - loss: 0.0481 - acc: 0.9880"
     ]
    }
   ],
   "source": [
    "f = open('results_lstm_conll.txt', 'a')\n",
    "for run_i in range(10):\n",
    "    print(\"Run \" + str(run_i))\n",
    "    \n",
    "    tmp_model_filename = 'model_lstm_conll.' + str(run_i) + '.h5'\n",
    "\n",
    "    history = utils.F1History(tmp_model_filename, devSet=devSentences)\n",
    "\n",
    "    model = models.get_model_lstm()\n",
    "    model.fit_generator(\n",
    "        utils.NerSequence(trainSentences, shuffle_data=True, batch_size=32), \n",
    "        validation_data = utils.NerSequence(devSentences, batch_size=512), \n",
    "        epochs = 10, callbacks = [history]\n",
    "    )\n",
    "    \n",
    "    model.load_weights(tmp_model_filename)\n",
    "    \n",
    "    model.fit_generator(\n",
    "        utils.NerSequence(trainSentences, shuffle_data=True, batch_size=256), \n",
    "        validation_data = utils.NerSequence(devSentences, batch_size=512), \n",
    "        epochs = 10, callbacks = [history]\n",
    "    )\n",
    "    \n",
    "    model.load_weights(tmp_model_filename)\n",
    "    \n",
    "    true_labels, pred_labels = utils.predict_sequences(model, testSentences)\n",
    "    \n",
    "    pre, rec, f1 = compute_f1(pred_labels, true_labels, models.idx2Label)\n",
    "    f.write(str(run_i) + \"\\t\" + str(pre) + \"\\t\" + str(rec) +  \"\\t\" + str(f1))\n",
    "    f.write(\"\\n\")\n",
    "    f.flush()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, json\n",
    "# copy file for best run\n",
    "shutil.copyfile('tmp_3cnn_bi-lstm.h5', '../models/final_model_germeval_outer.h5')\n",
    "with open(\"../models/final_model_germeval.indexes\", \"w\") as f:\n",
    "    json.dump([models.idx2Label, models.label2Idx, models.char2Idx, models.case2Idx], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_contrib.layers import CRF\n",
    "def create_custom_objects():\n",
    "    instanceHolder = {\"instance\": None}\n",
    "    class ClassWrapper(CRF):\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            instanceHolder[\"instance\"] = self\n",
    "            super(ClassWrapper, self).__init__(*args, **kwargs)\n",
    "    def loss(*args):\n",
    "        method = getattr(instanceHolder[\"instance\"], \"loss_function\")\n",
    "        return method(*args)\n",
    "    def accuracy(*args):\n",
    "        method = getattr(instanceHolder[\"instance\"], \"accuracy\")\n",
    "        return method(*args)\n",
    "    return {\"ClassWrapper\": ClassWrapper ,\"CRF\": ClassWrapper, \"loss\": loss, \"accuracy\":accuracy}\n",
    "\n",
    "finalmodel = load_model('../models/final_model_germeval_outer.h5', custom_objects=create_custom_objects())\n",
    "true_labels, pred_labels = utils.predict_sequences(finalmodel, testSentences)\n",
    "print(compute_f1(pred_labels, true_labels, models.idx2Label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('germeval_output.tsv', 'w', encoding='UTF-8')\n",
    "for i_sent, sent in enumerate(testSentences):\n",
    "    for i_tok, tok in enumerate(sent):\n",
    "        if tok[0] == 'PADDING_TOKEN':\n",
    "            break\n",
    "        correctlabel = models.idx2Label[true_labels[i_sent][i_tok]]\n",
    "        guessedlabel = models.idx2Label[pred_labels[i_sent][i_tok]]\n",
    "        line = \"\\t\".join([str(i_tok+1), tok[0], correctlabel, correctlabel, guessedlabel, guessedlabel])\n",
    "        f.write(line + '\\n')\n",
    "    f.write('\\n')\n",
    "f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
