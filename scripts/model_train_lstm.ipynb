{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gwiedemann/miniconda3/envs/kerasenv/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import fastText\n",
    "\n",
    "from validation import compute_f1\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "\n",
    "import models\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000\n",
      "2200\n",
      "5100\n"
     ]
    }
   ],
   "source": [
    "trainSentences = utils.get_sentences_germeval('../data/GermEVAL/NER-de-train.tsv')\n",
    "devSentences = utils.get_sentences_germeval('../data/GermEVAL/NER-de-dev.tsv')\n",
    "testSentences = utils.get_sentences_germeval('../data/GermEVAL/NER-de-test.tsv')\n",
    "\n",
    "# trainSentences = utils.get_sentences_conll('../data/CONLL/deu/deu_utf.train.bio')\n",
    "# devSentences = utils.get_sentences_conll('../data/CONLL/deu/deu_utf.testa.bio')\n",
    "# testSentences = utils.get_sentences_conll('../data/CONLL/deu/deu_utf.testb.bio')\n",
    "\n",
    "print(len(trainSentences))\n",
    "print(len(devSentences))\n",
    "print(len(testSentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Die', 'O'], ['These', 'O'], [',', 'O'], ['Schlatter', 'B-PER'], ['sei', 'O'], ['Antisemit', 'O'], ['gewesen', 'O'], [',', 'O'], ['wurde', 'O'], ['seither', 'O'], ['in', 'O'], ['der', 'O'], ['theologischen', 'O'], ['Fachliteratur', 'O'], ['nicht', 'O'], ['mehr', 'O'], ['vertreten', 'O'], ['.', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(testSentences[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelSet = set()\n",
    "characters= set()\n",
    "models.max_sequence_length = 0\n",
    "\n",
    "for dataset in [trainSentences, devSentences, testSentences]:\n",
    "    for sentence in dataset:\n",
    "        for word, label in sentence:\n",
    "            for char in word:\n",
    "                characters.add(char)\n",
    "            labelSet.add(label)\n",
    "        if len(sentence) > models.max_sequence_length:\n",
    "            models.max_sequence_length = len(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "print(len(labelSet))\n",
    "print(models.max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# :: Create a mapping for the labels ::\n",
    "models.label2Idx = {\"PADDING_TOKEN\":0}\n",
    "for label in labelSet:\n",
    "    models.label2Idx[label] = len(models.label2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'I-OTH': 18, 'I-LOCderiv': 19, 'I-PERderiv': 1, 'B-PERderiv': 20, 'B-OTH': 3, 'PADDING_TOKEN': 0, 'I-PER': 4, 'B-PERpart': 21, 'O': 5, 'B-ORGderiv': 25, 'B-OTHderiv': 7, 'I-LOCpart': 10, 'B-LOC': 8, 'I-OTHderiv': 9, 'B-ORGpart': 11, 'I-ORG': 2, 'B-PER': 13, 'I-PERpart': 6, 'B-LOCderiv': 14, 'B-LOCpart': 22, 'B-OTHpart': 23, 'I-OTHpart': 24, 'I-ORGderiv': 15, 'I-ORGpart': 12, 'I-LOC': 16, 'B-ORG': 17}\n"
     ]
    }
   ],
   "source": [
    "print(models.label2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# :: Hard coded case lookup ::\n",
    "models.case2Idx = {'PADDING_TOKEN':0, 'numeric': 1, 'allLower':2, 'allUpper':3, 'initialUpper':4, 'other':5, 'mainly_numeric':6, 'contains_digit': 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'contains_digit': 7, 'allLower': 2, 'other': 5, 'initialUpper': 4, 'allUpper': 3, 'numeric': 1, 'PADDING_TOKEN': 0, 'mainly_numeric': 6}\n"
     ]
    }
   ],
   "source": [
    "print(models.case2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(trainSentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Schartau', 'B-PER'], ['sagte', 'O'], ['dem', 'O'], ['\"', 'O'], ['Tagesspiegel', 'B-ORG'], ['\"', 'O'], ['vom', 'O'], ['Freitag', 'O'], [',', 'O'], ['Fischer', 'B-PER'], ['sei', 'O'], ['\"', 'O'], ['in', 'O'], ['einer', 'O'], ['Weise', 'O'], ['aufgetreten', 'O'], [',', 'O'], ['die', 'O'], ['alles', 'O'], ['andere', 'O'], ['als', 'O'], ['überzeugend', 'O'], ['war', 'O'], ['\"', 'O'], ['.', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(trainSentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'є': 6, 'Ü': 7, '©': 9, 'ī': 10, 'C': 5, '守': 12, '別': 16, '章': 14, '¹': 17, 'Т': 18, '³': 19, '柯': 20, 'g': 22, 'м': 23, 'п': 8, 'ν': 263, '›': 25, 'õ': 28, 's': 29, 'ŏ': 30, 'J': 31, 'Ø': 219, 'y': 32, 'Ц': 34, 'ņ': 249, '!': 35, '公': 36, 'G': 217, 'è': 37, 'ı': 11, 'X': 39, '懿': 40, 'Ö': 242, 'κ': 41, 'ς': 42, '5': 44, 'S': 45, 'a': 46, '8': 47, '”': 13, 'à': 48, 'Ş': 304, 'д': 321, 'オ': 49, 'й': 50, 'č': 198, 'ɨ': 51, 'H': 52, '</S>': 2, 'ę': 53, 'V': 61, '=': 54, 'Ž': 55, 'ō': 117, 'н': 256, ']': 188, 'r': 57, 'ó': 318, '3': 271, 'ś': 298, 'L': 59, 'z': 60, '\\x95': 62, '術': 302, 'α': 63, 'ǒ': 64, 'ệ': 65, 'ñ': 66, '+': 67, 'г': 68, '\"': 69, '‹': 70, 'K': 71, 'ô': 72, 'ψ': 74, 'я': 322, 'ğ': 224, 'б': 75, 'Á': 173, '冲': 331, '*': 76, '€': 191, 'с': 77, '太': 78, 'ż': 292, 'Z': 79, '≤': 80, 'İ': 114, '}': 81, '\\x9a': 82, 'd': 83, 'A': 84, '鷹': 87, '“': 86, 'ã': 88, '寝': 91, 'm': 24, '<S>': 1, 'š': 93, '7': 316, 'É': 95, 'UNKNOWN': 333, 'á': 96, 'ế': 97, '鶴': 21, 'η': 183, '算': 98, 'π': 15, 'р': 99, 'Ġ': 101, 'ـ': 27, '<W>': 3, 'ض': 213, '¤': 104, '貴': 105, '−': 106, 'У': 120, '§': 107, ')': 108, 'ن': 163, 'x': 110, '½': 111, 'U': 241, 'ῦ': 112, '_': 294, 'έ': 113, 'ð': 115, 'ç': 116, '학': 119, 'ü': 123, 'β': 121, 'ي': 122, '²': 124, 'j': 125, '殿': 128, '×': 127, 'ċ': 234, 'ă': 129, '…': 130, 'ö': 126, 'ι': 133, 'أ': 222, '<': 137, 'e': 135, 'Λ': 136, 'ú': 139, 'ї': 118, 'À': 142, '[': 141, '?': 143, 'ř': 144, 'ß': 146, '(': 147, 'î': 149, '¸': 150, 'ж': 131, 'Л': 151, '.': 185, '傳': 152, '#': 153, '4': 288, 'ы': 154, 'Ш': 155, 'Π': 140, 'ب': 157, 'λ': 158, 'ラ': 161, '´': 160, 'D': 162, 'ź': 164, '\\x99': 189, 'W': 166, 'å': 167, '±': 253, '1': 168, '佐': 169, 'ć': 170, 'P': 134, '«': 171, 'O': 172, 'Œ': 178, '妃': 33, 'ą': 175, 'i': 176, '»': 177, '@': 179, 'φ': 180, '„': 181, ':': 182, ',': 239, 'х': 184, 'b': 240, 'ø': 38, 'T': 138, '\\x92': 186, 'Š': 187, 'ē': 193, 'з': 190, '≘': 192, 'ο': 26, 'µ': 195, 'é': 196, 'v': 197, 'p': 199, 'w': 200, '£': 201, 'Ä': 202, 'q': 203, '`': 309, 'а': 247, '별': 43, '·': 314, 'у': 206, 'u': 315, 'ε': 207, 'PADDING_TOKEN': 0, 'Î': 90, '—': 210, '~': 284, 'Ż': 194, 'R': 132, 'ا': 145, '$': 214, '東': 326, 'σ': 216, 'n': 317, 'ň': 250, 'k': 255, 't': 174, 'c': 218, 'F': 220, '\\x94': 221, '루': 215, 'М': 307, 'и': 85, '°': 258, '-': 223, '⊃': 225, 'ý': 236, 'â': 226, '樓': 228, '</W>': 4, 'ë': 229, 'ḳ': 230, '동': 231, '→': 232, '\\xad': 233, 'Č': 235, 'È': 204, 'ū': 275, 'В': 237, 'υ': 238, 'ά': 73, 'Y': 89, 'ḫ': 156, '/': 244, 'ρ': 248, 'l': 243, '6': 245, 'ő': 94, '⋅': 324, '%': 148, 'о': 319, 'í': 252, 'M': 254, '博': 58, 'E': 92, 'o': 259, '造': 265, 'f': 261, '\\x80': 260, 'ю': 205, '李': 227, 'ł': 267, '台': 268, 'ê': 269, 'Â': 270, 'ş': 257, '&': 262, 'ä': 273, 'л': 246, 'ь': 276, 'ό': 264, 'С': 277, 'û': 278, 'Е': 279, 'ě': 280, '士': 282, 'Å': 283, 'Q': 285, 'ń': 286, '\\x96': 287, '–': 208, 'И': 251, '†': 290, 'ā': 266, '\\u200e': 291, 'ъ': 293, '대': 299, ';': 295, '0': 296, '‘': 297, 'æ': 56, 'ĩ': 303, '九': 300, '9': 272, 'Ł': 305, '南': 328, '2': 306, '’': 109, 'B': 308, 'γ': 310, 'Æ': 311, 'œ': 281, 'Þ': 313, 'т': 209, '▪': 100, 'ʻ': 159, 'ž': 211, 'е': 312, '>': 323, '″': 320, 'ť': 102, 'П': 212, 'τ': 301, \"'\": 332, '‐': 325, 'ħ': 103, 'N': 327, 'h': 165, 'к': 329, 'в': 330, 'I': 274, '‚': 289}\n"
     ]
    }
   ],
   "source": [
    "models.char2Idx={\"PADDING_TOKEN\":0, \"<S>\":1, \"</S>\":2, \"<W>\":3, \"</W>\":4}\n",
    "for char in characters:\n",
    "    models.char2Idx[char] = len(models.char2Idx)\n",
    "models.char2Idx['UNKNOWN'] = len(models.char2Idx)\n",
    "print(models.char2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Schartau', 'B-PER'], ['sagte', 'O'], ['dem', 'O'], ['\"', 'O'], ['Tagesspiegel', 'B-ORG'], ['\"', 'O'], ['vom', 'O'], ['Freitag', 'O'], [',', 'O'], ['Fischer', 'B-PER'], ['sei', 'O'], ['\"', 'O'], ['in', 'O'], ['einer', 'O'], ['Weise', 'O'], ['aufgetreten', 'O'], [',', 'O'], ['die', 'O'], ['alles', 'O'], ['andere', 'O'], ['als', 'O'], ['überzeugend', 'O'], ['war', 'O'], ['\"', 'O'], ['.', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(trainSentences[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.ft = fastText.load_model(\"../embeddings/wiki.de.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "print(models.nb_embedding_dims)\n",
    "print(len(trainSentences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "models.idx2Label = {v: k for k, v in models.label2Idx.items()}\n",
    "print(len(models.label2Idx))\n",
    "print(len(models.idx2Label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# importlib.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_model_filename = 'model_lstm_germeval.h5'\n",
    "# checkpoint = ModelCheckpoint(tmp_model_filename, verbose=1, save_best_only = True, monitor = 'val_acc')\n",
    "history = utils.F1History(tmp_model_filename, devSet = devSentences)\n",
    "model = models.get_model_lstm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import importlib\n",
    "#importlib.reload(utils)\n",
    "# print(models.max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    utils.NerSequence(trainSentences[:1000], shuffle_data=True, batch_size=256), \n",
    "    validation_data = utils.NerSequence(devSentences[:1000], batch_size=256), \n",
    "    epochs = 3, callbacks = [history]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.acc)\n",
    "print(history.f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(tmp_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    utils.NerSequence(trainSentences, shuffle_data=True, batch_size=2048), \n",
    "    validation_data = utils.NerSequence(devSentences, batch_size=256), \n",
    "    epochs = 5, callbacks = [history]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(tmp_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels, pred_labels = utils.predict_sequences(model, testSentences[:1000])\n",
    "print(compute_f1(pred_labels, true_labels, models.idx2Label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 52)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 52, 32) 10688       char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, None, 100)    33200       char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, None, 408)    0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, None, 400)    974400      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "crf (CRF)                       (None, None, 26)     11154       bidirectional_10[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 1,029,506\n",
      "Trainable params: 1,029,442\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: 0.0488 - acc: 0.9837\n",
      "New maximum F1 score: 0.7584769842773251 (before: 0) Saving to model_lstm_germeval.0.h5\n",
      "1500/1500 [==============================] - 613s 408ms/step - loss: 0.0488 - acc: 0.9837 - val_loss: 0.0053 - val_acc: 0.9888\n",
      "Epoch 2/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.0179 - acc: 0.9888\n",
      "New maximum F1 score: 0.7844794467921629 (before: 0.7584769842773251) Saving to model_lstm_germeval.0.h5\n",
      "1500/1500 [==============================] - 604s 402ms/step - loss: -0.0179 - acc: 0.9888 - val_loss: -0.0467 - val_acc: 0.9902\n",
      "Epoch 3/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.0720 - acc: 0.9900\n",
      "New maximum F1 score: 0.8023840566213447 (before: 0.7844794467921629) Saving to model_lstm_germeval.0.h5\n",
      "1500/1500 [==============================] - 603s 402ms/step - loss: -0.0720 - acc: 0.9900 - val_loss: -0.0999 - val_acc: 0.9906\n",
      "Epoch 4/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.1278 - acc: 0.9910\n",
      "New maximum F1 score: 0.811751497005988 (before: 0.8023840566213447) Saving to model_lstm_germeval.0.h5\n",
      "1500/1500 [==============================] - 612s 408ms/step - loss: -0.1278 - acc: 0.9910 - val_loss: -0.1542 - val_acc: 0.9912\n",
      "Epoch 5/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.1831 - acc: 0.9917\n",
      "New maximum F1 score: 0.8172807181597158 (before: 0.811751497005988) Saving to model_lstm_germeval.0.h5\n",
      "1500/1500 [==============================] - 602s 402ms/step - loss: -0.1831 - acc: 0.9917 - val_loss: -0.2087 - val_acc: 0.9912\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 602s 401ms/step - loss: -0.2381 - acc: 0.9921 - val_loss: -0.2611 - val_acc: 0.9908\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 626s 417ms/step - loss: -0.2928 - acc: 0.9926 - val_loss: -0.3151 - val_acc: 0.9909\n",
      "Epoch 8/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.3473 - acc: 0.9929\n",
      "New maximum F1 score: 0.8204939181717655 (before: 0.8172807181597158) Saving to model_lstm_germeval.0.h5\n",
      "1500/1500 [==============================] - 641s 427ms/step - loss: -0.3473 - acc: 0.9929 - val_loss: -0.3690 - val_acc: 0.9913\n",
      "Epoch 9/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.4016 - acc: 0.9933\n",
      "New maximum F1 score: 0.8234415826801046 (before: 0.8204939181717655) Saving to model_lstm_germeval.0.h5\n",
      "1500/1500 [==============================] - 641s 427ms/step - loss: -0.4016 - acc: 0.9933 - val_loss: -0.4227 - val_acc: 0.9914\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 647s 432ms/step - loss: -0.4557 - acc: 0.9934 - val_loss: -0.4760 - val_acc: 0.9914\n",
      "Epoch 1/10\n",
      "47/47 [==============================] - 88s 2s/step - loss: -0.4311 - acc: 0.9941 - val_loss: -0.4243 - val_acc: 0.9914\n",
      "Epoch 2/10\n",
      "46/47 [============================>.] - ETA: 1s - loss: -0.4333 - acc: 0.9944\n",
      "New maximum F1 score: 0.8238562696795704 (before: 0.8234415826801046) Saving to model_lstm_germeval.0.h5\n",
      "47/47 [==============================] - 75s 2s/step - loss: -0.4333 - acc: 0.9944 - val_loss: -0.4261 - val_acc: 0.9915\n",
      "Epoch 3/10\n",
      "46/47 [============================>.] - ETA: 1s - loss: -0.4352 - acc: 0.9945\n",
      "New maximum F1 score: 0.8246358104370275 (before: 0.8238562696795704) Saving to model_lstm_germeval.0.h5\n",
      "47/47 [==============================] - 75s 2s/step - loss: -0.4352 - acc: 0.9945 - val_loss: -0.4277 - val_acc: 0.9916\n",
      "Epoch 4/10\n",
      "47/47 [==============================] - 75s 2s/step - loss: -0.4371 - acc: 0.9946 - val_loss: -0.4293 - val_acc: 0.9914\n",
      "Epoch 5/10\n",
      "47/47 [==============================] - 75s 2s/step - loss: -0.4390 - acc: 0.9948 - val_loss: -0.4310 - val_acc: 0.9915\n",
      "Epoch 6/10\n",
      "47/47 [==============================] - 75s 2s/step - loss: -0.4407 - acc: 0.9947 - val_loss: -0.4326 - val_acc: 0.9914\n",
      "Epoch 7/10\n",
      "47/47 [==============================] - 75s 2s/step - loss: -0.4426 - acc: 0.9948 - val_loss: -0.4343 - val_acc: 0.9915\n",
      "Epoch 8/10\n",
      "47/47 [==============================] - 73s 2s/step - loss: -0.4443 - acc: 0.9948 - val_loss: -0.4359 - val_acc: 0.9914\n",
      "Epoch 9/10\n",
      "47/47 [==============================] - 73s 2s/step - loss: -0.4459 - acc: 0.9947 - val_loss: -0.4375 - val_acc: 0.9915\n",
      "Epoch 10/10\n",
      "47/47 [==============================] - 72s 2s/step - loss: -0.4479 - acc: 0.9950 - val_loss: -0.4393 - val_acc: 0.9914\n",
      "Run 1\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 52)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 52, 32) 10688       char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, None, 100)    33200       char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, None, 408)    0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, None, 400)    974400      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "crf (CRF)                       (None, None, 26)     11154       bidirectional_12[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 1,029,506\n",
      "Trainable params: 1,029,442\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9838\n",
      "New maximum F1 score: 0.772098385857033 (before: 0) Saving to model_lstm_germeval.1.h5\n",
      "1500/1500 [==============================] - 650s 433ms/step - loss: 0.0401 - acc: 0.9838 - val_loss: -0.0031 - val_acc: 0.9893\n",
      "Epoch 2/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.0247 - acc: 0.9888\n",
      "New maximum F1 score: 0.790446841294299 (before: 0.772098385857033) Saving to model_lstm_germeval.1.h5\n",
      "1500/1500 [==============================] - 641s 427ms/step - loss: -0.0248 - acc: 0.9888 - val_loss: -0.0528 - val_acc: 0.9902\n",
      "Epoch 3/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.0786 - acc: 0.9901\n",
      "New maximum F1 score: 0.8038585209003216 (before: 0.790446841294299) Saving to model_lstm_germeval.1.h5\n",
      "1500/1500 [==============================] - 641s 428ms/step - loss: -0.0786 - acc: 0.9901 - val_loss: -0.1064 - val_acc: 0.9906\n",
      "Epoch 4/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.1340 - acc: 0.9910\n",
      "New maximum F1 score: 0.810271568446333 (before: 0.8038585209003216) Saving to model_lstm_germeval.1.h5\n",
      "1500/1500 [==============================] - 643s 429ms/step - loss: -0.1340 - acc: 0.9910 - val_loss: -0.1601 - val_acc: 0.9909\n",
      "Epoch 5/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.1894 - acc: 0.9916\n",
      "New maximum F1 score: 0.8216357851394347 (before: 0.810271568446333) Saving to model_lstm_germeval.1.h5\n",
      "1500/1500 [==============================] - 637s 425ms/step - loss: -0.1894 - acc: 0.9916 - val_loss: -0.2142 - val_acc: 0.9914\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 629s 419ms/step - loss: -0.2445 - acc: 0.9922 - val_loss: -0.2679 - val_acc: 0.9915\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 631s 421ms/step - loss: -0.2993 - acc: 0.9927 - val_loss: -0.3217 - val_acc: 0.9907\n",
      "Epoch 8/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.3536 - acc: 0.9930\n",
      "New maximum F1 score: 0.8256846780162842 (before: 0.8216357851394347) Saving to model_lstm_germeval.1.h5\n",
      "1500/1500 [==============================] - 630s 420ms/step - loss: -0.3537 - acc: 0.9930 - val_loss: -0.3752 - val_acc: 0.9916\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 644s 429ms/step - loss: -0.4079 - acc: 0.9931 - val_loss: -0.4279 - val_acc: 0.9910\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 644s 429ms/step - loss: -0.4621 - acc: 0.9935 - val_loss: -0.4822 - val_acc: 0.9915\n",
      "Epoch 1/10\n",
      "46/47 [============================>.] - ETA: 1s - loss: -0.3835 - acc: 0.9940\n",
      "New maximum F1 score: 0.8275606593813669 (before: 0.8256846780162842) Saving to model_lstm_germeval.1.h5\n",
      "47/47 [==============================] - 87s 2s/step - loss: -0.3835 - acc: 0.9940 - val_loss: -0.3772 - val_acc: 0.9916\n",
      "Epoch 2/10\n",
      "46/47 [============================>.] - ETA: 1s - loss: -0.3856 - acc: 0.9942\n",
      "New maximum F1 score: 0.828698553948832 (before: 0.8275606593813669) Saving to model_lstm_germeval.1.h5\n",
      "47/47 [==============================] - 75s 2s/step - loss: -0.3856 - acc: 0.9942 - val_loss: -0.3791 - val_acc: 0.9916\n",
      "Epoch 3/10\n",
      "47/47 [==============================] - 77s 2s/step - loss: -0.3874 - acc: 0.9942 - val_loss: -0.3808 - val_acc: 0.9916\n",
      "Epoch 4/10\n",
      "47/47 [==============================] - 74s 2s/step - loss: -0.3895 - acc: 0.9946 - val_loss: -0.3824 - val_acc: 0.9917\n",
      "Epoch 5/10\n",
      "46/47 [============================>.] - ETA: 1s - loss: -0.3912 - acc: 0.9945\n",
      "New maximum F1 score: 0.8289790624420973 (before: 0.828698553948832) Saving to model_lstm_germeval.1.h5\n",
      "47/47 [==============================] - 74s 2s/step - loss: -0.3912 - acc: 0.9945 - val_loss: -0.3841 - val_acc: 0.9917\n",
      "Epoch 6/10\n",
      "47/47 [==============================] - 74s 2s/step - loss: -0.3929 - acc: 0.9945 - val_loss: -0.3857 - val_acc: 0.9917\n",
      "Epoch 7/10\n",
      "46/47 [============================>.] - ETA: 1s - loss: -0.3948 - acc: 0.9946\n",
      "New maximum F1 score: 0.8321574452283699 (before: 0.8289790624420973) Saving to model_lstm_germeval.1.h5\n",
      "47/47 [==============================] - 75s 2s/step - loss: -0.3948 - acc: 0.9946 - val_loss: -0.3875 - val_acc: 0.9918\n",
      "Epoch 8/10\n",
      "47/47 [==============================] - 76s 2s/step - loss: -0.3966 - acc: 0.9947 - val_loss: -0.3890 - val_acc: 0.9916\n",
      "Epoch 9/10\n",
      "47/47 [==============================] - 74s 2s/step - loss: -0.3984 - acc: 0.9947 - val_loss: -0.3907 - val_acc: 0.9918\n",
      "Epoch 10/10\n",
      "47/47 [==============================] - 75s 2s/step - loss: -0.4001 - acc: 0.9947 - val_loss: -0.3925 - val_acc: 0.9917\n",
      "Run 2\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 52)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 52, 32) 10688       char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, None, 100)    33200       char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, None, 408)    0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, None, 400)    974400      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "crf (CRF)                       (None, None, 26)     11154       bidirectional_14[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 1,029,506\n",
      "Trainable params: 1,029,442\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: 0.0462 - acc: 0.9840\n",
      "New maximum F1 score: 0.767752059631228 (before: 0) Saving to model_lstm_germeval.2.h5\n",
      "1500/1500 [==============================] - 654s 436ms/step - loss: 0.0462 - acc: 0.9840 - val_loss: 0.0034 - val_acc: 0.9894\n",
      "Epoch 2/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.0193 - acc: 0.9889\n",
      "New maximum F1 score: 0.7968720198359717 (before: 0.767752059631228) Saving to model_lstm_germeval.2.h5\n",
      "1500/1500 [==============================] - 636s 424ms/step - loss: -0.0193 - acc: 0.9889 - val_loss: -0.0484 - val_acc: 0.9904\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 635s 424ms/step - loss: -0.0736 - acc: 0.9902 - val_loss: -0.1002 - val_acc: 0.9896\n",
      "Epoch 4/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.1291 - acc: 0.9910\n",
      "New maximum F1 score: 0.8114522508947071 (before: 0.7968720198359717) Saving to model_lstm_germeval.2.h5\n",
      "1500/1500 [==============================] - 646s 430ms/step - loss: -0.1290 - acc: 0.9910 - val_loss: -0.1553 - val_acc: 0.9911\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.1843 - acc: 0.9917\n",
      "New maximum F1 score: 0.8194110020374142 (before: 0.8114522508947071) Saving to model_lstm_germeval.2.h5\n",
      "1500/1500 [==============================] - 634s 423ms/step - loss: -0.1844 - acc: 0.9917 - val_loss: -0.2095 - val_acc: 0.9911\n",
      "Epoch 6/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.2394 - acc: 0.9922\n",
      "New maximum F1 score: 0.8207878675790641 (before: 0.8194110020374142) Saving to model_lstm_germeval.2.h5\n",
      "1500/1500 [==============================] - 638s 426ms/step - loss: -0.2394 - acc: 0.9922 - val_loss: -0.2630 - val_acc: 0.9912\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 639s 426ms/step - loss: -0.2942 - acc: 0.9926 - val_loss: -0.3164 - val_acc: 0.9909\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 638s 426ms/step - loss: -0.3486 - acc: 0.9930 - val_loss: -0.3701 - val_acc: 0.9907\n",
      "Epoch 9/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.4029 - acc: 0.9933\n",
      "New maximum F1 score: 0.8268156424581006 (before: 0.8207878675790641) Saving to model_lstm_germeval.2.h5\n",
      "1500/1500 [==============================] - 642s 428ms/step - loss: -0.4029 - acc: 0.9933 - val_loss: -0.4241 - val_acc: 0.9917\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 640s 426ms/step - loss: -0.4571 - acc: 0.9936 - val_loss: -0.4768 - val_acc: 0.9913\n",
      "Epoch 1/10\n",
      "47/47 [==============================] - 86s 2s/step - loss: -0.4325 - acc: 0.9943 - val_loss: -0.4260 - val_acc: 0.9916\n",
      "Epoch 2/10\n",
      "47/47 [==============================] - 71s 2s/step - loss: -0.4346 - acc: 0.9945 - val_loss: -0.4277 - val_acc: 0.9915\n",
      "Epoch 3/10\n",
      "47/47 [==============================] - 73s 2s/step - loss: -0.4365 - acc: 0.9945 - val_loss: -0.4293 - val_acc: 0.9914\n",
      "Epoch 4/10\n",
      "47/47 [==============================] - 74s 2s/step - loss: -0.4384 - acc: 0.9946 - val_loss: -0.4310 - val_acc: 0.9915\n",
      "Epoch 5/10\n",
      "46/47 [============================>.] - ETA: 1s - loss: -0.4403 - acc: 0.9948\n",
      "New maximum F1 score: 0.8270120259019427 (before: 0.8268156424581006) Saving to model_lstm_germeval.2.h5\n",
      "47/47 [==============================] - 73s 2s/step - loss: -0.4402 - acc: 0.9948 - val_loss: -0.4327 - val_acc: 0.9915\n",
      "Epoch 6/10\n",
      "47/47 [==============================] - 74s 2s/step - loss: -0.4420 - acc: 0.9947 - val_loss: -0.4342 - val_acc: 0.9914\n",
      "Epoch 7/10\n",
      "46/47 [============================>.] - ETA: 1s - loss: -0.4439 - acc: 0.9948\n",
      "New maximum F1 score: 0.8276627218934912 (before: 0.8270120259019427) Saving to model_lstm_germeval.2.h5\n",
      "47/47 [==============================] - 73s 2s/step - loss: -0.4439 - acc: 0.9948 - val_loss: -0.4360 - val_acc: 0.9914\n",
      "Epoch 8/10\n",
      "47/47 [==============================] - 76s 2s/step - loss: -0.4455 - acc: 0.9948 - val_loss: -0.4375 - val_acc: 0.9914\n",
      "Epoch 9/10\n",
      "47/47 [==============================] - 72s 2s/step - loss: -0.4474 - acc: 0.9949 - val_loss: -0.4392 - val_acc: 0.9914\n",
      "Epoch 10/10\n",
      "46/47 [============================>.] - ETA: 1s - loss: -0.4492 - acc: 0.9949\n",
      "New maximum F1 score: 0.8292772861356932 (before: 0.8276627218934912) Saving to model_lstm_germeval.2.h5\n",
      "47/47 [==============================] - 76s 2s/step - loss: -0.4492 - acc: 0.9949 - val_loss: -0.4409 - val_acc: 0.9915\n",
      "Run 3\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 52)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 52, 32) 10688       char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, None, 100)    33200       char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, None, 408)    0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, None, 400)    974400      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "crf (CRF)                       (None, None, 26)     11154       bidirectional_16[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 1,029,506\n",
      "Trainable params: 1,029,442\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      " 146/1500 [=>............................] - ETA: 10:39 - loss: 0.1638 - acc: 0.9638"
     ]
    }
   ],
   "source": [
    "f = open('results_lstm_germeval.txt', 'a')\n",
    "for run_i in range(10):\n",
    "    print(\"Run \" + str(run_i))\n",
    "    \n",
    "    tmp_model_filename = 'model_lstm_germeval.' + str(run_i) + '.h5'\n",
    "\n",
    "    history = utils.F1History(tmp_model_filename, devSet=devSentences)\n",
    "\n",
    "    model = models.get_model_lstm()\n",
    "    model.fit_generator(\n",
    "        utils.NerSequence(trainSentences, shuffle_data=True, batch_size=16), \n",
    "        validation_data = utils.NerSequence(devSentences, batch_size=512), \n",
    "        epochs = 10, callbacks = [history]\n",
    "    )\n",
    "    \n",
    "    model.load_weights(tmp_model_filename)\n",
    "    \n",
    "    model.fit_generator(\n",
    "        utils.NerSequence(trainSentences, shuffle_data=True, batch_size=512), \n",
    "        validation_data = utils.NerSequence(devSentences, batch_size=512), \n",
    "        epochs = 10, callbacks = [history]\n",
    "    )\n",
    "    \n",
    "    model.load_weights(tmp_model_filename)\n",
    "    \n",
    "    true_labels, pred_labels = utils.predict_sequences(model, testSentences)\n",
    "    \n",
    "    pre, rec, f1 = compute_f1(pred_labels, true_labels, models.idx2Label)\n",
    "    f.write(str(run_i) + \"\\t\" + str(pre) + \"\\t\" + str(rec) +  \"\\t\" + str(f1))\n",
    "    f.write(\"\\n\")\n",
    "    f.flush()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, json\n",
    "# copy file for best run\n",
    "shutil.copyfile('tmp_3cnn_bi-lstm.h5', '../models/final_model_germeval_outer.h5')\n",
    "with open(\"../models/final_model_germeval.indexes\", \"w\") as f:\n",
    "    json.dump([models.idx2Label, models.label2Idx, models.char2Idx, models.case2Idx], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_contrib.layers import CRF\n",
    "def create_custom_objects():\n",
    "    instanceHolder = {\"instance\": None}\n",
    "    class ClassWrapper(CRF):\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            instanceHolder[\"instance\"] = self\n",
    "            super(ClassWrapper, self).__init__(*args, **kwargs)\n",
    "    def loss(*args):\n",
    "        method = getattr(instanceHolder[\"instance\"], \"loss_function\")\n",
    "        return method(*args)\n",
    "    def accuracy(*args):\n",
    "        method = getattr(instanceHolder[\"instance\"], \"accuracy\")\n",
    "        return method(*args)\n",
    "    return {\"ClassWrapper\": ClassWrapper ,\"CRF\": ClassWrapper, \"loss\": loss, \"accuracy\":accuracy}\n",
    "\n",
    "finalmodel = load_model('../models/final_model_germeval_outer.h5', custom_objects=create_custom_objects())\n",
    "true_labels, pred_labels = utils.predict_sequences(finalmodel, testSentences)\n",
    "print(compute_f1(pred_labels, true_labels, models.idx2Label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('germeval_output.tsv', 'w', encoding='UTF-8')\n",
    "for i_sent, sent in enumerate(testSentences):\n",
    "    for i_tok, tok in enumerate(sent):\n",
    "        if tok[0] == 'PADDING_TOKEN':\n",
    "            break\n",
    "        correctlabel = models.idx2Label[true_labels[i_sent][i_tok]]\n",
    "        guessedlabel = models.idx2Label[pred_labels[i_sent][i_tok]]\n",
    "        line = \"\\t\".join([str(i_tok+1), tok[0], correctlabel, correctlabel, guessedlabel, guessedlabel])\n",
    "        f.write(line + '\\n')\n",
    "    f.write('\\n')\n",
    "f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
