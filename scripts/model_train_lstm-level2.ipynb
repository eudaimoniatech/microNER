{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import fastText\n",
    "\n",
    "from validation import compute_f1\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "\n",
    "import models\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "#%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000\n",
      "2200\n",
      "5100\n"
     ]
    }
   ],
   "source": [
    "trainSentences = utils.get_sentences_germeval('../../Resources/GermEVAL/NER-de-train.tsv', level2=True)\n",
    "devSentences = utils.get_sentences_germeval('../../Resources/GermEVAL/NER-de-dev.tsv', level2=True)\n",
    "testSentences = utils.get_sentences_germeval('../../Resources/GermEVAL/NER-de-test.tsv', level2=True)\n",
    "\n",
    "print(len(trainSentences))\n",
    "print(len(devSentences))\n",
    "print(len(testSentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Die', 'O'], ['These', 'O'], [',', 'O'], ['Schlatter', 'O'], ['sei', 'O'], ['Antisemit', 'O'], ['gewesen', 'O'], [',', 'O'], ['wurde', 'O'], ['seither', 'O'], ['in', 'O'], ['der', 'O'], ['theologischen', 'O'], ['Fachliteratur', 'O'], ['nicht', 'O'], ['mehr', 'O'], ['vertreten', 'O'], ['.', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(testSentences[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelSet = set()\n",
    "characters= set()\n",
    "models.max_sequence_length = 0\n",
    "\n",
    "for dataset in [trainSentences, devSentences, testSentences]:\n",
    "    for sentence in dataset:\n",
    "        for word, label in sentence:\n",
    "            for char in word:\n",
    "                characters.add(char)\n",
    "            labelSet.add(label)\n",
    "        if len(sentence) > models.max_sequence_length:\n",
    "            models.max_sequence_length = len(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "print(len(labelSet))\n",
    "print(models.max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# :: Create a mapping for the labels ::\n",
    "models.label2Idx = {\"PADDING_TOKEN\":0}\n",
    "for label in labelSet:\n",
    "    models.label2Idx[label] = len(models.label2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 1, 'B-OTHpart': 2, 'B-OTHderiv': 3, 'B-ORG': 4, 'B-ORGderiv': 5, 'B-ORGpart': 6, 'I-LOCderiv': 10, 'B-LOC': 7, 'I-PER': 8, 'B-LOCpart': 11, 'B-PER': 15, 'I-ORG': 14, 'B-LOCderiv': 17, 'PADDING_TOKEN': 0, 'B-PERderiv': 9, 'I-OTH': 16, 'I-LOC': 18, 'B-OTH': 13, 'B-PERpart': 12}\n"
     ]
    }
   ],
   "source": [
    "print(models.label2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# :: Hard coded case lookup ::\n",
    "models.case2Idx = {'PADDING_TOKEN':0, 'numeric': 1, 'allLower':2, 'allUpper':3, 'initialUpper':4, 'other':5, 'mainly_numeric':6, 'contains_digit': 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'other': 5, 'allUpper': 3, 'contains_digit': 7, 'numeric': 1, 'PADDING_TOKEN': 0, 'initialUpper': 4, 'mainly_numeric': 6, 'allLower': 2}\n"
     ]
    }
   ],
   "source": [
    "print(models.case2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(trainSentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Schartau', 'O'], ['sagte', 'O'], ['dem', 'O'], ['\"', 'O'], ['Tagesspiegel', 'O'], ['\"', 'O'], ['vom', 'O'], ['Freitag', 'O'], [',', 'O'], ['Fischer', 'O'], ['sei', 'O'], ['\"', 'O'], ['in', 'O'], ['einer', 'O'], ['Weise', 'O'], ['aufgetreten', 'O'], [',', 'O'], ['die', 'O'], ['alles', 'O'], ['andere', 'O'], ['als', 'O'], ['überzeugend', 'O'], ['war', 'O'], ['\"', 'O'], ['.', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(trainSentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'冲': 5, '→': 6, '루': 7, 'И': 280, 'з': 8, 'Ł': 240, 'ā': 9, '/': 10, '博': 11, 'k': 169, 'á': 12, 'ź': 14, 'κ': 19, 'ν': 16, 'ß': 17, 'у': 38, '佐': 20, 'ь': 21, 'Z': 22, ':': 24, '殿': 26, '!': 27, 'ē': 33, 'ú': 30, '太': 330, 'O': 32, '造': 274, 'а': 34, '\\xad': 35, 'B': 37, 'A': 305, 'q': 39, 'å': 40, 'б': 285, 'ŏ': 41, 'Ц': 42, 'ـ': 44, 'Λ': 45, 'Œ': 47, 'ī': 251, '‘': 49, 'ž': 50, '柯': 87, 'ğ': 51, 'M': 283, 'о': 52, 'd': 53, '\"': 154, '\\x99': 54, '▪': 55, 'ǒ': 329, 'H': 56, 'ي': 57, '‹': 58, 'σ': 172, 'Ġ': 296, 'ý': 60, 'ʻ': 61, 'е': 62, 'м': 13, 's': 188, 'ι': 64, 'G': 65, '公': 67, 'Ž': 306, 'έ': 68, '−': 69, 'ḳ': 70, '³': 205, '²': 71, '×': 18, 'D': 72, 'α': 74, 'W': 15, 'ο': 79, '±': 77, '術': 81, 'w': 80, 'ж': 289, 'ب': 83, 'ě': 84, 'Е': 85, 'я': 76, 'œ': 260, 'h': 88, 'o': 281, 'Ż': 183, 'Т': 89, '’': 90, 'к': 91, 'İ': 137, '″': 92, 'PADDING_TOKEN': 0, 'ş': 187, 'ż': 94, 'ð': 297, '`': 96, '守': 98, 'Ş': 213, '대': 100, '©': 25, 'и': 101, '\\x96': 102, 'У': 103, 'Š': 104, '동': 231, 'y': 291, '士': 82, '妃': 106, '傳': 28, 'ĩ': 107, '2': 108, 'ế': 110, '\\x9a': 111, 'Ш': 112, 'λ': 113, 'J': 114, 't': 115, 'П': 125, 'Â': 116, 'b': 117, 'æ': 197, 'х': 284, '>': 249, '\\x80': 118, '鷹': 119, ']': 193, '별': 120, 'ł': 122, 'g': 123, 'C': 124, '°': 126, 'ό': 309, 'ς': 195, 'm': 129, '@': 131, '_': 255, 'с': 133, 'â': 134, 'в': 130, '⋅': 135, 'ć': 292, '?': 139, 'أ': 48, 'ü': 141, 'UNKNOWN': 333, 'ラ': 319, 'ê': 308, 'ن': 143, 'Л': 151, 'π': 145, 'ø': 36, 'η': 147, 'e': 132, 'н': 150, 'X': 199, 'À': 152, '…': 73, 'F': 153, 'ض': 235, 'Ö': 155, 'ń': 159, 'È': 165, 'ệ': 160, 'c': 161, 'Ä': 162, '*': 163, '½': 164, '¤': 127, 'ε': 166, 'ô': 167, ',': 168, 'Î': 170, 'L': 171, '台': 173, 'й': 181, 'ῦ': 136, ';': 175, 'Q': 176, 'u': 158, 'ą': 178, 'z': 179, 'P': 180, 'ъ': 182, '南': 190, \"'\": 184, '7': 185, 'ç': 186, '\\x94': 189, '‐': 86, 'ó': 288, 'f': 191, 'л': 194, 'ã': 304, '—': 196, '別': 198, 'ά': 29, 'д': 200, 'x': 313, '李': 201, '(': 202, '학': 128, 'T': 203, 'j': 204, '<S>': 1, 'S': 140, '\\u200e': 23, 'В': 93, 'τ': 207, '»': 317, '+': 209, 'ņ': 46, 'é': 210, '\\x95': 212, 'É': 248, '4': 214, 'ɨ': 216, 'Æ': 217, '</W>': 4, 'l': 218, 'ö': 220, 'Π': 142, '寝': 221, '&': 222, '[': 208, 'õ': 177, 'n': 278, 'ū': 225, 'ă': 226, '<': 227, 'R': 228, '¸': 144, '≤': 294, 'ř': 232, 'Á': 233, '鶴': 310, 'ë': 234, 'v': 332, 'è': 303, '†': 236, '3': 146, 'ś': 238, 'г': 97, 'Ø': 241, '東': 242, '#': 243, '≘': 244, 'ň': 245, '=': 43, 'K': 246, 'č': 247, 'ō': 149, '</S>': 2, 'С': 250, 'ť': 252, 'υ': 253, 'U': 99, '§': 254, 'ő': 257, 'ы': 239, 'р': 300, 'γ': 258, '}': 211, '´': 259, '%': 261, 'a': 262, '⊃': 138, '9': 265, '算': 266, 'û': 268, 'п': 269, 'Å': 215, 'ψ': 256, '$': 229, 'オ': 267, '貴': 271, '8': 272, '0': 273, 'ċ': 105, '樓': 75, '5': 275, 'I': 326, 'М': 277, 'ю': 276, 'ї': 279, '“': 156, 'β': 282, 'Č': 78, '~': 286, '”': 287, '章': 237, 'ḫ': 219, '€': 295, '–': 157, '<W>': 3, 'Ü': 290, 'ħ': 148, 'š': 293, 'ı': 59, '£': 264, '懿': 121, 'ñ': 298, 'E': 299, 'V': 301, 'Y': 302, '›': 174, 'í': 192, '.': 270, 'φ': 31, 'т': 324, '‚': 311, 'î': 223, 'à': 66, 'i': 314, 'N': 315, 'p': 316, '-': 318, '„': 95, '\\x92': 312, 'ä': 320, '«': 224, 'ρ': 322, '九': 323, 'Þ': 263, '¹': 109, ')': 325, 'r': 327, '·': 328, 'ę': 331, 'µ': 63, 'є': 307, '1': 206, '6': 230, 'ا': 321}\n"
     ]
    }
   ],
   "source": [
    "models.char2Idx={\"PADDING_TOKEN\":0, \"<S>\":1, \"</S>\":2, \"<W>\":3, \"</W>\":4}\n",
    "for char in characters:\n",
    "    models.char2Idx[char] = len(models.char2Idx)\n",
    "models.char2Idx['UNKNOWN'] = len(models.char2Idx)\n",
    "print(models.char2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Schartau', 'O'], ['sagte', 'O'], ['dem', 'O'], ['\"', 'O'], ['Tagesspiegel', 'O'], ['\"', 'O'], ['vom', 'O'], ['Freitag', 'O'], [',', 'O'], ['Fischer', 'O'], ['sei', 'O'], ['\"', 'O'], ['in', 'O'], ['einer', 'O'], ['Weise', 'O'], ['aufgetreten', 'O'], [',', 'O'], ['die', 'O'], ['alles', 'O'], ['andere', 'O'], ['als', 'O'], ['überzeugend', 'O'], ['war', 'O'], ['\"', 'O'], ['.', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(trainSentences[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.ft = fastText.load_model(\"../../fastText/wiki.de.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "print(models.nb_embedding_dims)\n",
    "print(len(trainSentences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "models.idx2Label = {v: k for k, v in models.label2Idx.items()}\n",
    "print(len(models.label2Idx))\n",
    "print(len(models.idx2Label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Compute Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# importlib.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 52)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 52, 32) 10688       char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, None, 100)    33200       char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 408)    0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, None, 400)    974400      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "crf (CRF)                       (None, None, 19)     8018        bidirectional_2[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,026,370\n",
      "Trainable params: 1,026,306\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tmp_model_filename = 'model_lstm_germeval_2nd-level.h5'\n",
    "# checkpoint = ModelCheckpoint(tmp_model_filename, verbose=1, save_best_only = True, monitor = 'val_acc')\n",
    "history = utils.F1History(tmp_model_filename, devSet = devSentences)\n",
    "model = models.get_model_lstm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import importlib\n",
    "#importlib.reload(utils)\n",
    "# print(models.max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9956\n",
      "New maximum F1 score: 0.45307443365695793 (before: 0) Saving to model_lstm_germeval_2nd-level.h5\n",
      "1500/1500 [==============================] - 398s 266ms/step - loss: 0.0203 - acc: 0.9956 - val_loss: -0.0072 - val_acc: 0.9984\n",
      "Epoch 2/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.0238 - acc: 0.9983\n",
      "New maximum F1 score: 0.5217391304347825 (before: 0.45307443365695793) Saving to model_lstm_germeval_2nd-level.h5\n",
      "1500/1500 [==============================] - 397s 264ms/step - loss: -0.0238 - acc: 0.9983 - val_loss: -0.0442 - val_acc: 0.9985\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 395s 263ms/step - loss: -0.0675 - acc: 0.9983 - val_loss: -0.0926 - val_acc: 0.9985\n",
      "Epoch 4/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.1186 - acc: 0.9985\n",
      "New maximum F1 score: 0.5644768856447688 (before: 0.5217391304347825) Saving to model_lstm_germeval_2nd-level.h5\n",
      "1500/1500 [==============================] - 396s 264ms/step - loss: -0.1186 - acc: 0.9985 - val_loss: -0.1448 - val_acc: 0.9984\n",
      "Epoch 5/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.1720 - acc: 0.9986\n",
      "New maximum F1 score: 0.5808080808080809 (before: 0.5644768856447688) Saving to model_lstm_germeval_2nd-level.h5\n",
      "1500/1500 [==============================] - 396s 264ms/step - loss: -0.1721 - acc: 0.9986 - val_loss: -0.1983 - val_acc: 0.9985\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 396s 264ms/step - loss: -0.2258 - acc: 0.9986 - val_loss: -0.2516 - val_acc: 0.9982\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 397s 264ms/step - loss: -0.2798 - acc: 0.9987 - val_loss: -0.3055 - val_acc: 0.9985\n",
      "Epoch 8/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.3338 - acc: 0.9988\n",
      "New maximum F1 score: 0.5924050632911393 (before: 0.5808080808080809) Saving to model_lstm_germeval_2nd-level.h5\n",
      "1500/1500 [==============================] - 398s 265ms/step - loss: -0.3338 - acc: 0.9988 - val_loss: -0.3591 - val_acc: 0.9985\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 397s 265ms/step - loss: -0.3875 - acc: 0.9988 - val_loss: -0.4123 - val_acc: 0.9984\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 398s 265ms/step - loss: -0.4413 - acc: 0.9989 - val_loss: -0.4657 - val_acc: 0.9985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efa94dd6f98>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    utils.NerSequence(trainSentences, shuffle_data=True, batch_size=16), \n",
    "    validation_data = utils.NerSequence(devSentences, batch_size=256), \n",
    "    epochs = 10, callbacks = [history]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9984171995249661, 0.998506489016793, 0.9984902602976019, 0.9983928684754805, 0.9985308504104614, 0.9982467536492782, 0.9985227326913313, 0.9985470893166282, 0.9983847397023982, 0.9984659064899791]\n",
      "[0.45307443365695793, 0.5217391304347825, 0.5189504373177842, 0.5644768856447688, 0.5808080808080809, 0.5476190476190477, 0.555256064690027, 0.5924050632911393, 0.5773672055427251, 0.5839416058394161]\n"
     ]
    }
   ],
   "source": [
    "print(history.acc)\n",
    "print(history.f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(tmp_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12/12 [==============================] - 271s 23s/step - loss: -0.3613 - acc: 0.9989 - val_loss: -0.3595 - val_acc: 0.9985\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 262s 22s/step - loss: -0.3618 - acc: 0.9990 - val_loss: -0.3598 - val_acc: 0.9984\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 263s 22s/step - loss: -0.3623 - acc: 0.9990 - val_loss: -0.3603 - val_acc: 0.9984\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 262s 22s/step - loss: -0.3628 - acc: 0.9990 - val_loss: -0.3607 - val_acc: 0.9984\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 262s 22s/step - loss: -0.3632 - acc: 0.9990 - val_loss: -0.3611 - val_acc: 0.9985\n",
      "Epoch 6/10\n",
      "11/12 [==========================>...] - ETA: 18s - loss: -0.3636 - acc: 0.9990\n",
      "New maximum F1 score: 0.5938242280285035 (before: 0.5924050632911393) Saving to model_lstm_germeval_2nd-level.h5\n",
      "12/12 [==============================] - 259s 22s/step - loss: -0.3636 - acc: 0.9990 - val_loss: -0.3615 - val_acc: 0.9985\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 254s 21s/step - loss: -0.3641 - acc: 0.9991 - val_loss: -0.3620 - val_acc: 0.9985\n",
      "Epoch 8/10\n",
      "11/12 [==========================>...] - ETA: 18s - loss: -0.3645 - acc: 0.9991\n",
      "New maximum F1 score: 0.5957446808510638 (before: 0.5938242280285035) Saving to model_lstm_germeval_2nd-level.h5\n",
      "12/12 [==============================] - 254s 21s/step - loss: -0.3646 - acc: 0.9991 - val_loss: -0.3624 - val_acc: 0.9985\n",
      "Epoch 9/10\n",
      "11/12 [==========================>...] - ETA: 18s - loss: -0.3651 - acc: 0.9991\n",
      "New maximum F1 score: 0.6018957345971563 (before: 0.5957446808510638) Saving to model_lstm_germeval_2nd-level.h5\n",
      "12/12 [==============================] - 256s 21s/step - loss: -0.3651 - acc: 0.9991 - val_loss: -0.3628 - val_acc: 0.9985\n",
      "Epoch 10/10\n",
      "11/12 [==========================>...] - ETA: 18s - loss: -0.3655 - acc: 0.9991\n",
      "New maximum F1 score: 0.6052009456264775 (before: 0.6018957345971563) Saving to model_lstm_germeval_2nd-level.h5\n",
      "12/12 [==============================] - 257s 21s/step - loss: -0.3655 - acc: 0.9991 - val_loss: -0.3632 - val_acc: 0.9985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ef7d079e160>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    utils.NerSequence(trainSentences, shuffle_data=True, batch_size=2048), \n",
    "    validation_data = utils.NerSequence(devSentences, batch_size=256), \n",
    "    epochs = 10, callbacks = [history]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(tmp_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.4943820224719101, 0.5238095238095238, 0.5086705202312138)\n"
     ]
    }
   ],
   "source": [
    "true_labels, pred_labels = utils.predict_sequences(model, testSentences[:1000])\n",
    "print(compute_f1(pred_labels, true_labels, models.idx2Label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5936794582392777, 0.5106796116504855, 0.5490605427974948)\n"
     ]
    }
   ],
   "source": [
    "true_labels, pred_labels = utils.predict_sequences(model, testSentences)\n",
    "print(compute_f1(pred_labels, true_labels, models.idx2Label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, json\n",
    "# copy file for best run\n",
    "shutil.copyfile(tmp_model_filename, '../models/final_model_germeval_inner.h5')\n",
    "shutil.copyfile(tmp_model_filename + '.indexes', '../models/final_model_germeval_inner.indexes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_contrib.layers import CRF\n",
    "def create_custom_objects():\n",
    "    instanceHolder = {\"instance\": None}\n",
    "    class ClassWrapper(CRF):\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            instanceHolder[\"instance\"] = self\n",
    "            super(ClassWrapper, self).__init__(*args, **kwargs)\n",
    "    def loss(*args):\n",
    "        method = getattr(instanceHolder[\"instance\"], \"loss_function\")\n",
    "        return method(*args)\n",
    "    def accuracy(*args):\n",
    "        method = getattr(instanceHolder[\"instance\"], \"accuracy\")\n",
    "        return method(*args)\n",
    "    return {\"ClassWrapper\": ClassWrapper ,\"CRF\": ClassWrapper, \"loss\": loss, \"accuracy\":accuracy}\n",
    "\n",
    "finalmodel = load_model('../models/final_model_germeval_outer.h5', custom_objects=create_custom_objects())\n",
    "true_labels, pred_labels = utils.predict_sequences(finalmodel, testSentences)\n",
    "print(compute_f1(pred_labels, true_labels, models.idx2Label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('germeval_output.tsv', 'w', encoding='UTF-8')\n",
    "for i_sent, sent in enumerate(testSentences):\n",
    "    for i_tok, tok in enumerate(sent):\n",
    "        if tok[0] == 'PADDING_TOKEN':\n",
    "            break\n",
    "        correctlabel = models.idx2Label[true_labels[i_sent][i_tok]]\n",
    "        guessedlabel = models.idx2Label[pred_labels[i_sent][i_tok]]\n",
    "        line = \"\\t\".join([str(i_tok+1), tok[0], correctlabel, correctlabel, guessedlabel, guessedlabel])\n",
    "        f.write(line + '\\n')\n",
    "    f.write('\\n')\n",
    "f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
