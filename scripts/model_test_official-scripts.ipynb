{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gwiedemann/miniconda3/envs/kerasenv/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import fastText\n",
    "\n",
    "from validation import compute_f1\n",
    "import conlleval\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "\n",
    "import models\n",
    "import utils\n",
    "\n",
    "import shutil, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_contrib.layers import CRF\n",
    "def create_custom_objects():\n",
    "    instanceHolder = {\"instance\": None}\n",
    "    class ClassWrapper(CRF):\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            instanceHolder[\"instance\"] = self\n",
    "            super(ClassWrapper, self).__init__(*args, **kwargs)\n",
    "    def loss(*args):\n",
    "        method = getattr(instanceHolder[\"instance\"], \"loss_function\")\n",
    "        return method(*args)\n",
    "    def accuracy(*args):\n",
    "        method = getattr(instanceHolder[\"instance\"], \"accuracy\")\n",
    "        return method(*args)\n",
    "    return {\"ClassWrapper\": ClassWrapper ,\"CRF\": ClassWrapper, \"loss\": loss, \"accuracy\":accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.ft = fastText.load_model(\"../embeddings/wiki.de.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_model_indexes(indexes_file, max_sequence_length = 56):\n",
    "    indexMappings = json.load(open(indexes_file, 'r', encoding='UTF-8'))\n",
    "    models.idx2Label = {int(k):v for k,v in indexMappings[0].items()}\n",
    "    models.label2Idx = indexMappings[1]\n",
    "    models.char2Idx = indexMappings[2]\n",
    "    models.case2Idx = indexMappings[3]\n",
    "    models.max_sequence_length = max_sequence_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GermEval (outer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5100\n"
     ]
    }
   ],
   "source": [
    "testSentences = utils.get_sentences_germeval('../data/GermEVAL/NER-de-test.tsv')\n",
    "print(len(testSentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model_indexes('../models/germeval.indexes')\n",
    "finalmodel = load_model('../models/germeval.h5', custom_objects=create_custom_objects())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8315377081292851, 0.8245386856587893, 0.8280234070221067)\n"
     ]
    }
   ],
   "source": [
    "true_labels, pred_labels = utils.predict_sequences(finalmodel, testSentences)\n",
    "print(compute_f1(pred_labels, true_labels, models.idx2Label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GermEval (inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'I-OTHpart': 7, 'B-PER': 10, 'B-LOC': 12, 'I-OTHderiv': 20, 'B-PERpart': 23, 'B-ORGderiv': 2, 'I-PER': 19, 'I-PERderiv': 8, 'I-LOCpart': 17, 'O': 9, 'B-OTHderiv': 6, 'I-OTH': 4, 'I-ORGpart': 5, 'B-OTHpart': 24, 'I-PERpart': 13, 'I-LOC': 1, 'B-ORG': 18, 'B-OTH': 25, 'I-LOCderiv': 22, 'B-PERderiv': 11, 'B-LOCpart': 16, 'I-ORGderiv': 3, 'I-ORG': 15, 'B-ORGpart': 14, 'PADDING_TOKEN': 0, 'B-LOCderiv': 21}\n",
      "{0: 'PADDING_TOKEN', 1: 'I-LOC', 2: 'B-ORGderiv', 3: 'I-ORGderiv', 4: 'I-OTH', 5: 'I-ORGpart', 6: 'B-OTHderiv', 7: 'I-OTHpart', 8: 'I-PERderiv', 9: 'O', 10: 'B-PER', 11: 'B-PERderiv', 12: 'B-LOC', 13: 'I-PERpart', 14: 'B-ORGpart', 15: 'I-ORG', 16: 'B-LOCpart', 17: 'I-LOCpart', 18: 'B-ORG', 19: 'I-PER', 20: 'I-OTHderiv', 21: 'B-LOCderiv', 22: 'I-LOCderiv', 23: 'B-PERpart', 24: 'B-OTHpart', 25: 'B-OTH'}\n"
     ]
    }
   ],
   "source": [
    "idx_1st = models.idx2Label\n",
    "print(models.label2Idx)\n",
    "print(idx_1st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5938864628820961, 0.5281553398058253, 0.5590955806783146)\n"
     ]
    }
   ],
   "source": [
    "testSentences_2nd = utils.get_sentences_germeval('../data/GermEVAL/NER-de-test.tsv', level2=True)\n",
    "load_model_indexes('../models/germeval-inner.indexes')\n",
    "finalmodel_2nd = load_model('../models/germeval-inner.h5', custom_objects=create_custom_objects())\n",
    "true_labels_2nd, pred_labels_2nd = utils.predict_sequences(finalmodel_2nd, testSentences_2nd)\n",
    "print(compute_f1(pred_labels_2nd, true_labels_2nd, models.idx2Label))\n",
    "idx_2nd = models.idx2Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_file = 'germeval_outer_inner.tsv'\n",
    "conlleval.write_germeval_file(true_labels, pred_labels, true_labels_2nd, pred_labels_2nd, testSentences, idx_1st, idx_2nd, eval_file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Official script eval CoNLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3005\n"
     ]
    }
   ],
   "source": [
    "testSentences = utils.get_sentences_conll('../data/CONLL/deu/deu_utf.testb.bio')\n",
    "print(len(testSentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Die', 'O'], ['sechs', 'O'], ['Abgeordneten', 'O'], ['der', 'O'], ['Grünen', 'B-ORG'], [',', 'O'], ['die', 'O'], ['seit', 'O'], ['Bildung', 'O'], ['einer', 'O'], ['Großen', 'O'], ['Koalition', 'O'], ['von', 'O'], ['Christ-', 'O'], ['und', 'O'], ['Sozialdemokraten', 'O'], ['die', 'O'], ['Opposition', 'O'], ['darstellen', 'O'], [',', 'O'], ['hatten', 'O'], ['sich', 'O'], ['beim', 'O'], ['Vorsteher', 'O'], ['Rainer', 'B-PER'], ['Bergert', 'I-PER'], ['für', 'O'], ['ihr', 'O'], ['Fehlen', 'O'], ['entschuldigen', 'O'], ['lassen', 'O'], ['.', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(testSentences[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model_indexes('../models/conll.indexes', max_sequence_length = 100)\n",
    "finalmodel = load_model('../models/conll.h5', custom_objects=create_custom_objects())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8708474576271187, 0.8422950819672131, 0.8563333333333334)\n"
     ]
    }
   ],
   "source": [
    "true_labels, pred_labels = utils.predict_sequences(finalmodel, testSentences)\n",
    "print(compute_f1(pred_labels, true_labels, models.idx2Label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import conlleval\n",
    "\n",
    "eval_file = 'test_pl.tsv'\n",
    "conlleval.write_conll_file(true_labels, pred_labels, testSentences, models.idx2Label, eval_file) \n",
    "# p,r,f = conlleval.evaluate_conll_file(eval_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(p)\n",
    "print(r)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_base_name = 'model_lstm_germeval_v2.'\n",
    "eval_file = 'test_pl.tsv'\n",
    "all_f1_scores = []\n",
    "\n",
    "for run_i in range(10):\n",
    "    model_file = file_base_name + str(run_i) + '.h5'\n",
    "    index_file = file_base_name + str(run_i) + '.h5.indexes'\n",
    "    if not os.path.isfile(model_file):\n",
    "        print(model_file + ' not found')\n",
    "        continue\n",
    "    if not os.path.isfile(index_file):\n",
    "        print(model_file + ' not found')\n",
    "        continue\n",
    "    \n",
    "    print('Evaluating model ' + model_file)\n",
    "    \n",
    "    load_model_indexes(index_file)\n",
    "    finalmodel = load_model(model_file, custom_objects=create_custom_objects())\n",
    "    \n",
    "    true_labels, pred_labels = utils.predict_sequences(finalmodel, testSentences)\n",
    "    \n",
    "    conlleval.write_conll_file(true_labels, pred_labels, testSentences, models.idx2Label, eval_file) \n",
    "    p,r,f = conlleval.evaluate_conll_file(eval_file) \n",
    "    all_f1_scores.append(f)\n",
    "\n",
    "print(all_f1_scores)\n",
    "print(np.mean(all_f1_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# importlib.reload(conlleval)\n",
    "# importlib.reload(utils)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
