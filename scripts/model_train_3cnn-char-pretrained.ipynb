{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gwiedemann/miniconda3/envs/kerasenv/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import fastText\n",
    "\n",
    "from validation import compute_f1\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "\n",
    "import models\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000\n",
      "2200\n",
      "5100\n"
     ]
    }
   ],
   "source": [
    "trainSentences = utils.get_sentences_germeval('../data/GermEVAL/NER-de-train.tsv')\n",
    "devSentences = utils.get_sentences_germeval('../data/GermEVAL/NER-de-dev.tsv')\n",
    "testSentences = utils.get_sentences_germeval('../data/GermEVAL/NER-de-test.tsv')\n",
    "\n",
    "# trainSentences = get_sentences('../data/CONLL/deu/deu_utf.train')\n",
    "# devSentences = get_sentences('../data/CONLL/deu/deu_utf.testa')\n",
    "# testSentences = get_sentences('../data/CONLL/deu/deu_utf.testb')\n",
    "\n",
    "print(len(trainSentences))\n",
    "print(len(devSentences))\n",
    "print(len(testSentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1951', 'O'], ['bis', 'O'], ['1953', 'O'], ['wurde', 'O'], ['der', 'O'], ['nördliche', 'O'], ['Teil', 'O'], ['als', 'O'], ['Jugendburg', 'O'], ['des', 'O'], ['Kolpingwerkes', 'B-OTH'], ['gebaut', 'O'], ['.', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(testSentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelSet = set()\n",
    "characters= set()\n",
    "models.max_sequence_length = 0\n",
    "\n",
    "for dataset in [trainSentences, devSentences, testSentences]:\n",
    "    for sentence in dataset:\n",
    "        for word, label in sentence:\n",
    "            for char in word:\n",
    "                characters.add(char)\n",
    "            labelSet.add(label)\n",
    "        if len(sentence) > models.max_sequence_length:\n",
    "            models.max_sequence_length = len(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "print(len(labelSet))\n",
    "print(models.max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# :: Create a mapping for the labels ::\n",
    "models.label2Idx = {\"PADDING_TOKEN\":0}\n",
    "for label in labelSet:\n",
    "    models.label2Idx[label] = len(models.label2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'I-OTH': 1, 'B-PERderiv': 2, 'B-OTH': 16, 'B-ORGpart': 3, 'I-OTHderiv': 17, 'B-LOC': 5, 'B-PERpart': 6, 'B-PER': 24, 'B-LOCpart': 7, 'I-PER': 18, 'I-PERpart': 4, 'I-ORG': 19, 'B-OTHpart': 20, 'B-ORG': 8, 'B-ORGderiv': 23, 'I-ORGderiv': 10, 'I-ORGpart': 21, 'I-PERderiv': 9, 'O': 11, 'I-LOCpart': 12, 'I-OTHpart': 13, 'B-LOCderiv': 14, 'PADDING_TOKEN': 0, 'I-LOC': 15, 'I-LOCderiv': 25, 'B-OTHderiv': 22}\n"
     ]
    }
   ],
   "source": [
    "print(models.label2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# :: Hard coded case lookup ::\n",
    "models.case2Idx = {'PADDING_TOKEN':0, 'numeric': 1, 'allLower':2, 'allUpper':3, 'initialUpper':4, 'other':5, 'mainly_numeric':6, 'contains_digit': 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mainly_numeric': 6, 'contains_digit': 7, 'other': 5, 'PADDING_TOKEN': 0, 'allLower': 2, 'numeric': 1, 'allUpper': 3, 'initialUpper': 4}\n"
     ]
    }
   ],
   "source": [
    "print(models.case2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(trainSentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Schartau', 'B-PER'], ['sagte', 'O'], ['dem', 'O'], ['\"', 'O'], ['Tagesspiegel', 'B-ORG'], ['\"', 'O'], ['vom', 'O'], ['Freitag', 'O'], [',', 'O'], ['Fischer', 'B-PER'], ['sei', 'O'], ['\"', 'O'], ['in', 'O'], ['einer', 'O'], ['Weise', 'O'], ['aufgetreten', 'O'], [',', 'O'], ['die', 'O'], ['alles', 'O'], ['andere', 'O'], ['als', 'O'], ['überzeugend', 'O'], ['war', 'O'], ['\"', 'O'], ['.', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(trainSentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'í': 5, 'Å': 6, '-': 7, '²': 8, '術': 63, 'ν': 181, 'ю': 197, ':': 12, 'α': 117, 'г': 10, '造': 14, 'У': 15, '©': 16, 'Ġ': 320, 'κ': 17, 'ş': 20, 'ʻ': 311, '\\xad': 21, 'т': 22, '€': 283, 'É': 24, '(': 25, 'オ': 26, 'M': 27, 'τ': 28, '[': 29, 'x': 30, 'И': 67, '樓': 263, 'Ş': 173, 'ŏ': 36, 'ř': 33, 'g': 34, '\\x92': 35, '寝': 290, 'Π': 37, '算': 244, '\\x96': 38, '_': 174, 'ħ': 39, 'з': 40, '懿': 41, '\\x9a': 42, 'έ': 45, '.': 46, 'ą': 70, ']': 47, '\\x80': 48, 'Ü': 49, 'С': 50, 'ú': 51, 'н': 128, 'ǒ': 52, 'ø': 54, '殿': 55, 'γ': 56, 'ب': 59, 'ü': 60, 'л': 279, 'к': 13, 'Á': 61, 'é': 62, 'B': 65, 'ο': 178, 'ῦ': 66, 'I': 68, 'š': 69, '>': 71, '“': 287, '9': 72, 'ż': 73, 'ž': 74, 'Λ': 211, '7': 76, 'Y': 77, 'X': 80, '%': 79, 'Þ': 216, '¹': 18, 'ť': 89, '„': 82, '守': 84, 'b': 85, 'w': 140, 'ї': 87, 'V': 88, 'Ž': 242, 'h': 90, 'Î': 91, '대': 292, '#': 92, 'i': 19, 'β': 93, '‘': 94, 'İ': 318, '章': 96, 's': 97, '@': 101, 'σ': 103, 'z': 100, '…': 102, 'ـ': 104, 'ế': 23, '$': 105, 'е': 107, 'U': 78, 'æ': 109, 'ψ': 111, '‚': 112, 'φ': 187, '§': 113, 'N': 114, '£': 231, 'В': 186, 'ά': 115, 'ä': 116, '鷹': 118, 'Œ': 250, '`': 119, '°': 120, 'ă': 121, 'f': 123, 'ő': 239, 'р': 124, 'ñ': 125, '4': 127, 'Ä': 314, '李': 129, '«': 99, 'č': 131, '‐': 81, '″': 190, 'Ø': 135, 'в': 136, 'î': 137, 'Z': 138, 'ラ': 249, 'ğ': 141, '}': 83, 'λ': 192, '¤': 143, '貴': 144, 'М': 145, '´': 146, '+': 147, '!': 148, 'ā': 149, 'ū': 150, '\\u200e': 151, '’': 152, 'х': 304, 'Т': 58, 'è': 154, 't': 155, 'â': 156, 'û': 316, '*': 157, 'ń': 159, '×': 325, 'å': 161, '▪': 163, 'ç': 200, '柯': 167, 'à': 165, 'ņ': 166, 'œ': 132, 'ō': 293, 'Â': 168, 'ı': 169, 'б': 170, '博': 171, '佐': 172, 'ó': 31, '鶴': 175, 'ы': 176, '−': 201, 'ḳ': 177, 'n': 32, '±': 309, '⊃': 179, 'R': 180, 'S': 182, 'ě': 202, '=': 183, 'A': 184, '1': 185, '3': 189, 'Æ': 195, '≘': 191, '台': 75, '—': 193, '\"': 194, 'и': 198, 'F': 199, 'Ł': 95, 'UNKNOWN': 333, ';': 203, 'ł': 204, 'J': 205, 'O': 206, 'с': 207, 'ę': 209, '2': 254, 'Č': 210, '0': 130, 'G': 212, 'ē': 208, 'm': 217, 'ċ': 218, '‹': 219, 'ň': 86, 'T': 221, '별': 222, 'r': 126, 'д': 223, ',': 224, 'P': 225, 'p': 226, 'ς': 228, 'ɨ': 324, 'ś': 321, '<W>': 3, 'µ': 229, '루': 44, 'ي': 232, 'أ': 233, '학': 43, 'п': 236, 'W': 237, '›': 238, 'π': 240, 'Q': 241, 'ό': 264, 'ض': 213, 'ź': 243, '妃': 134, '<S>': 1, 'u': 246, 'q': 153, 'ö': 247, 'ж': 248, 'á': 214, '6': 98, 'Е': 251, 'j': 252, 'Л': 253, 'ð': 245, '南': 258, 'ệ': 256, 'ë': 257, 'ĩ': 301, '</S>': 2, 'a': 259, 'у': 260, 'ь': 261, 'ρ': 262, 'È': 106, '†': 9, 'L': 265, 'Ö': 266, 'Ш': 294, 'Ц': 267, 'є': 269, '½': 268, 'Ż': 272, '&': 270, '»': 271, 'м': 273, '\\x99': 220, 'й': 275, '\\x95': 276, 'П': 277, \"'\": 108, '~': 142, 'K': 158, 'o': 280, '?': 281, '⋅': 282, '公': 234, '冲': 110, '”': 215, 'ε': 284, 'а': 160, '士': 285, 'd': 286, '\\x94': 288, 'PADDING_TOKEN': 0, 'D': 289, '→': 274, 'y': 328, 'υ': 162, 'ô': 291, 'v': 53, '≤': 295, '九': 296, 'ć': 297, 'ḫ': 299, ')': 300, '別': 235, 'я': 302, 'ъ': 303, 'ī': 164, 'E': 305, 'ã': 278, 'ý': 306, 'ß': 307, 'Š': 308, 'η': 11, '³': 310, '/': 312, 'l': 313, 'о': 315, 'ê': 317, 'k': 255, '8': 57, 'c': 319, 'À': 188, '<': 322, '¸': 323, '太': 133, '·': 196, '東': 326, 'õ': 298, '傳': 139, 'e': 122, 'ن': 329, '5': 230, 'ا': 327, 'H': 330, '</W>': 4, '동': 64, 'ι': 331, 'C': 332, '–': 227}\n"
     ]
    }
   ],
   "source": [
    "models.char2Idx={\"PADDING_TOKEN\":0, \"<S>\":1, \"</S>\":2, \"<W>\":3, \"</W>\":4}\n",
    "for char in characters:\n",
    "    models.char2Idx[char] = len(models.char2Idx)\n",
    "models.char2Idx['UNKNOWN'] = len(models.char2Idx)\n",
    "print(models.char2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Schartau', 'B-PER'], ['sagte', 'O'], ['dem', 'O'], ['\"', 'O'], ['Tagesspiegel', 'B-ORG'], ['\"', 'O'], ['vom', 'O'], ['Freitag', 'O'], [',', 'O'], ['Fischer', 'B-PER'], ['sei', 'O'], ['\"', 'O'], ['in', 'O'], ['einer', 'O'], ['Weise', 'O'], ['aufgetreten', 'O'], [',', 'O'], ['die', 'O'], ['alles', 'O'], ['andere', 'O'], ['als', 'O'], ['überzeugend', 'O'], ['war', 'O'], ['\"', 'O'], ['.', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(trainSentences[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.ft = fastText.load_model(\"../embeddings/wiki.de.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "print(models.nb_embedding_dims)\n",
    "print(len(trainSentences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "models.idx2Label = {v: k for k, v in models.label2Idx.items()}\n",
    "print(len(models.label2Idx))\n",
    "print(len(models.idx2Label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "(300, 334)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "char_embeddings_full = []\n",
    "models.idx2Char = {v: k for k, v in models.char2Idx.items()}\n",
    "for idx in models.idx2Char:\n",
    "    # print(idx)\n",
    "    char_embeddings_full.append(models.ft.get_word_vector(models.idx2Char[idx]))\n",
    "\n",
    "char_embeddings_ft_dimensional = np.transpose(np.asarray(char_embeddings_full))\n",
    "\n",
    "print(models.nb_char_embeddings)\n",
    "print(char_embeddings_ft_dimensional.shape)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "char_embeddings_ft_dimensional = StandardScaler().fit_transform(char_embeddings_ft_dimensional)\n",
    "\n",
    "# reduce dimensions\n",
    "pca_embeddings = {}\n",
    "pca =  PCA(n_components = models.nb_char_embeddings)\n",
    "X_fit = pca.fit_transform(char_embeddings_ft_dimensional)\n",
    "U1 = pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52, 334)\n",
      "(334, 52)\n",
      "[ 0.06097103 -0.08364963  0.0420165  -0.05594541 -0.12055056  0.0753653\n",
      "  0.04046584 -0.00258806 -0.03529835 -0.00083467 -0.00248946 -0.01931428\n",
      "  0.00973782 -0.00163436  0.00931013  0.03026976  0.01325981  0.04547809\n",
      "  0.01414036  0.01067183  0.00755442  0.00483857 -0.00972926  0.0324423\n",
      " -0.02299908  0.0499439   0.0489522   0.03431637  0.11215851  0.06449113\n",
      "  0.02677515  0.01958173  0.02194596  0.05583817  0.01828234 -0.00787334\n",
      "  0.06406736 -0.02727523 -0.04293418 -0.03721522 -0.01577569  0.0299582\n",
      "  0.01945353 -0.07267907  0.03878674 -0.07088879 -0.02779063 -0.04633658\n",
      "  0.09528352  0.04456796 -0.00797106 -0.0847523 ]\n",
      "[ 0.06002061 -0.08579992  0.03255959 -0.03155637 -0.11854998  0.03731262\n",
      "  0.09541047 -0.00375484 -0.01461903  0.02828638  0.03400048 -0.00081043\n",
      " -0.0027184  -0.01664059  0.02811808  0.00161681  0.04817512  0.01968311\n",
      "  0.04087862  0.00571308  0.0027742  -0.05689412 -0.03675508  0.04068714\n",
      " -0.02999051 -0.02272069  0.01600836 -0.00285114  0.07411492  0.02234212\n",
      "  0.04651859  0.02081827  0.01770747 -0.0350418  -0.05216222 -0.02917424\n",
      "  0.02836099 -0.0317155  -0.04117434  0.01014042 -0.04695825  0.06534973\n",
      "  0.02849995 -0.03223549  0.02144969 -0.04399746 -0.03392225  0.19916387\n",
      "  0.00149062 -0.01938864 -0.01096727 -0.06865764]\n"
     ]
    }
   ],
   "source": [
    "print(U1.shape)\n",
    "ft_char_embeddings = np.transpose(U1)\n",
    "print(ft_char_embeddings.shape)\n",
    "\n",
    "print(ft_char_embeddings[models.char2Idx['?']])\n",
    "print(ft_char_embeddings[models.char2Idx['!']])\n",
    "models.ft_char_embeddings = ft_char_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import importlib\n",
    "#importlib.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 52)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 52, 32) 10688       char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, None, 52, 32) 3104        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, None, 52, 32) 4128        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, None, 52, 32) 5152        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, None, 32)     0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, None, 32)     0           time_distributed_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, None, 32)     0           time_distributed_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, None, 32)     0           time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, None, 32)     0           time_distributed_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_9 (TimeDistrib (None, None, 32)     0           time_distributed_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 404)    0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_3[0][0]         \n",
      "                                                                 time_distributed_6[0][0]         \n",
      "                                                                 time_distributed_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, None, 400)    968000      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "crf (CRF)                       (None, None, 26)     11154       bidirectional_1[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,002,290\n",
      "Trainable params: 1,002,226\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tmp_model_filename = 'tmp_3cnn_bi-lstm_pretrained.h5'\n",
    "# checkpoint = ModelCheckpoint(tmp_model_filename, verbose=1, save_best_only = True, monitor = 'val_acc')\n",
    "history = utils.F1History(tmp_model_filename, devSet = devSentences)\n",
    "model = models.get_model_3cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# importlib.reload(utils)\n",
    "#cprint(models.max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0653 - acc: 0.9818\n",
      "New maximum F1 score: 0.7508005274062913 (before: 0) Saving to tmp_3cnn_bi-lstm_pretrained.h5\n",
      "750/750 [==============================] - 232s 309ms/step - loss: 0.0653 - acc: 0.9818 - val_loss: 0.0248 - val_acc: 0.9887\n",
      "Epoch 2/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.9883\n",
      "New maximum F1 score: 0.7821800947867298 (before: 0.7508005274062913) Saving to tmp_3cnn_bi-lstm_pretrained.h5\n",
      "750/750 [==============================] - 221s 294ms/step - loss: 0.0159 - acc: 0.9883 - val_loss: 0.0010 - val_acc: 0.9899\n",
      "Epoch 3/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: -0.0097 - acc: 0.9898\n",
      "New maximum F1 score: 0.802118804388952 (before: 0.7821800947867298) Saving to tmp_3cnn_bi-lstm_pretrained.h5\n",
      "750/750 [==============================] - 221s 294ms/step - loss: -0.0097 - acc: 0.9898 - val_loss: -0.0240 - val_acc: 0.9906\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 217s 289ms/step - loss: -0.0361 - acc: 0.9906 - val_loss: -0.0465 - val_acc: 0.9894\n",
      "Epoch 5/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: -0.0631 - acc: 0.9913\n",
      "New maximum F1 score: 0.8114496768236381 (before: 0.802118804388952) Saving to tmp_3cnn_bi-lstm_pretrained.h5\n",
      "750/750 [==============================] - 214s 285ms/step - loss: -0.0631 - acc: 0.9913 - val_loss: -0.0748 - val_acc: 0.9909\n",
      "Epoch 6/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: -0.0909 - acc: 0.9919\n",
      "New maximum F1 score: 0.8211351755041075 (before: 0.8114496768236381) Saving to tmp_3cnn_bi-lstm_pretrained.h5\n",
      "750/750 [==============================] - 213s 283ms/step - loss: -0.0909 - acc: 0.9919 - val_loss: -0.1018 - val_acc: 0.9915\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 210s 280ms/step - loss: -0.1188 - acc: 0.9925 - val_loss: -0.1282 - val_acc: 0.9909\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 212s 283ms/step - loss: -0.1466 - acc: 0.9929 - val_loss: -0.1545 - val_acc: 0.9912\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 212s 282ms/step - loss: -0.1743 - acc: 0.9933 - val_loss: -0.1812 - val_acc: 0.9908\n",
      "Epoch 10/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: -0.2019 - acc: 0.9937\n",
      "New maximum F1 score: 0.8262002232973576 (before: 0.8211351755041075) Saving to tmp_3cnn_bi-lstm_pretrained.h5\n",
      "750/750 [==============================] - 213s 285ms/step - loss: -0.2019 - acc: 0.9937 - val_loss: -0.2086 - val_acc: 0.9915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f72337b5630>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    utils.NerSequence(trainSentences, shuffle_data=True, batch_size=32), \n",
    "    validation_data = utils.NerSequence(devSentences, batch_size=256), \n",
    "    epochs = 10, callbacks = [history]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9887094150890003, 0.9898701184446161, 0.9905925315076655, 0.9894480486349626, 0.9908847394856539, 0.9914529241215099, 0.9908685046976263, 0.9911850632320751, 0.9908116804469715, 0.9915340978449041]\n",
      "[0.7508005274062913, 0.7821800947867298, 0.802118804388952, 0.7946947674418605, 0.8114496768236381, 0.8211351755041075, 0.8159259259259259, 0.8185013876040703, 0.8167924875713497, 0.8262002232973576]\n"
     ]
    }
   ],
   "source": [
    "print(history.acc)\n",
    "print(history.f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(tmp_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/12 [==========================>...] - ETA: 5s - loss: -0.2172 - acc: 0.9945 \n",
      "New maximum F1 score: 0.8235511258767074 (before: 0) Saving to tmp_3cnn_bi-lstm_pretrained.h5\n",
      "12/12 [==============================] - 91s 8s/step - loss: -0.2172 - acc: 0.9945 - val_loss: -0.2088 - val_acc: 0.9914\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 70s 6s/step - loss: -0.2181 - acc: 0.9947 - val_loss: -0.2094 - val_acc: 0.9913\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 69s 6s/step - loss: -0.2187 - acc: 0.9948 - val_loss: -0.2098 - val_acc: 0.9914\n",
      "Epoch 4/10\n",
      "11/12 [==========================>...] - ETA: 3s - loss: -0.2191 - acc: 0.9948\n",
      "New maximum F1 score: 0.825654257279764 (before: 0.8235511258767074) Saving to tmp_3cnn_bi-lstm_pretrained.h5\n",
      "12/12 [==============================] - 67s 6s/step - loss: -0.2192 - acc: 0.9948 - val_loss: -0.2102 - val_acc: 0.9915\n",
      "Epoch 5/10\n",
      "11/12 [==========================>...] - ETA: 3s - loss: -0.2198 - acc: 0.9949\n",
      "New maximum F1 score: 0.8259587020648967 (before: 0.825654257279764) Saving to tmp_3cnn_bi-lstm_pretrained.h5\n",
      "12/12 [==============================] - 69s 6s/step - loss: -0.2198 - acc: 0.9949 - val_loss: -0.2107 - val_acc: 0.9915\n",
      "Epoch 6/10\n",
      "11/12 [==========================>...] - ETA: 4s - loss: -0.2204 - acc: 0.9950\n",
      "New maximum F1 score: 0.8268876611418048 (before: 0.8259587020648967) Saving to tmp_3cnn_bi-lstm_pretrained.h5\n",
      "12/12 [==============================] - 72s 6s/step - loss: -0.2205 - acc: 0.9950 - val_loss: -0.2111 - val_acc: 0.9916\n",
      "Epoch 7/10\n",
      "11/12 [==========================>...] - ETA: 3s - loss: -0.2210 - acc: 0.9951\n",
      "New maximum F1 score: 0.8275354316215717 (before: 0.8268876611418048) Saving to tmp_3cnn_bi-lstm_pretrained.h5\n",
      "12/12 [==============================] - 69s 6s/step - loss: -0.2211 - acc: 0.9951 - val_loss: -0.2115 - val_acc: 0.9915\n",
      "Epoch 8/10\n",
      "11/12 [==========================>...] - ETA: 3s - loss: -0.2214 - acc: 0.9950\n",
      "New maximum F1 score: 0.8279926335174955 (before: 0.8275354316215717) Saving to tmp_3cnn_bi-lstm_pretrained.h5\n",
      "12/12 [==============================] - 72s 6s/step - loss: -0.2215 - acc: 0.9950 - val_loss: -0.2119 - val_acc: 0.9916\n",
      "Epoch 9/10\n",
      "11/12 [==========================>...] - ETA: 4s - loss: -0.2219 - acc: 0.9951\n",
      "New maximum F1 score: 0.8291244239631337 (before: 0.8279926335174955) Saving to tmp_3cnn_bi-lstm_pretrained.h5\n",
      "12/12 [==============================] - 75s 6s/step - loss: -0.2220 - acc: 0.9951 - val_loss: -0.2123 - val_acc: 0.9917\n",
      "Epoch 10/10\n",
      "11/12 [==========================>...] - ETA: 4s - loss: -0.2223 - acc: 0.9951\n",
      "New maximum F1 score: 0.8294302046837543 (before: 0.8291244239631337) Saving to tmp_3cnn_bi-lstm_pretrained.h5\n",
      "12/12 [==============================] - 78s 7s/step - loss: -0.2224 - acc: 0.9951 - val_loss: -0.2128 - val_acc: 0.9917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6f0017c1d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    utils.NerSequence(trainSentences, shuffle_data=True, batch_size=2048), \n",
    "    validation_data = utils.NerSequence(devSentences, batch_size=256), \n",
    "    epochs = 10, callbacks = [history]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8182111200644642, 0.8217869860796374, 0.8199951546475006)\n"
     ]
    }
   ],
   "source": [
    "true_labels, pred_labels = utils.predict_sequences(model, testSentences)\n",
    "print(compute_f1(pred_labels, true_labels, models.idx2Label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 52)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 52, 32) 10688       char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_28 (TimeDistri (None, None, 52, 32) 3104        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_31 (TimeDistri (None, None, 52, 32) 4128        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_34 (TimeDistri (None, None, 52, 32) 5152        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_29 (TimeDistri (None, None, 32)     0           time_distributed_28[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_32 (TimeDistri (None, None, 32)     0           time_distributed_31[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_35 (TimeDistri (None, None, 32)     0           time_distributed_34[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_30 (TimeDistri (None, None, 32)     0           time_distributed_29[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_33 (TimeDistri (None, None, 32)     0           time_distributed_32[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_36 (TimeDistri (None, None, 32)     0           time_distributed_35[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, None, 404)    0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_30[0][0]        \n",
      "                                                                 time_distributed_33[0][0]        \n",
      "                                                                 time_distributed_36[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, None, 400)    968000      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "crf (CRF)                       (None, None, 26)     11154       bidirectional_4[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,002,290\n",
      "Trainable params: 1,002,226\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0668 - acc: 0.9818\n",
      "New maximum F1 score: 0.7453860640301317 (before: 0) Saving to tmp_generator_NER_3cnn_nodense_best.0.h5\n",
      "750/750 [==============================] - 248s 331ms/step - loss: 0.0667 - acc: 0.9818 - val_loss: 0.0268 - val_acc: 0.9884\n",
      "Epoch 2/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9884\n",
      "New maximum F1 score: 0.7849961330239752 (before: 0.7453860640301317) Saving to tmp_generator_NER_3cnn_nodense_best.0.h5\n",
      "750/750 [==============================] - 235s 313ms/step - loss: 0.0166 - acc: 0.9884 - val_loss: -1.6868e-05 - val_acc: 0.9901\n",
      "Epoch 3/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: -0.0103 - acc: 0.9896\n",
      "New maximum F1 score: 0.7996208530805687 (before: 0.7849961330239752) Saving to tmp_generator_NER_3cnn_nodense_best.0.h5\n",
      "750/750 [==============================] - 232s 310ms/step - loss: -0.0103 - acc: 0.9896 - val_loss: -0.0251 - val_acc: 0.9905\n",
      "Epoch 4/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: -0.0378 - acc: 0.9907\n",
      "New maximum F1 score: 0.803305785123967 (before: 0.7996208530805687) Saving to tmp_generator_NER_3cnn_nodense_best.0.h5\n",
      "750/750 [==============================] - 235s 314ms/step - loss: -0.0378 - acc: 0.9907 - val_loss: -0.0503 - val_acc: 0.9908\n",
      "Epoch 5/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: -0.0656 - acc: 0.9915\n",
      "New maximum F1 score: 0.815393195761294 (before: 0.803305785123967) Saving to tmp_generator_NER_3cnn_nodense_best.0.h5\n",
      "750/750 [==============================] - 238s 317ms/step - loss: -0.0656 - acc: 0.9914 - val_loss: -0.0779 - val_acc: 0.9910\n",
      "Epoch 6/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: -0.0934 - acc: 0.9920\n",
      "New maximum F1 score: 0.815946348733234 (before: 0.815393195761294) Saving to tmp_generator_NER_3cnn_nodense_best.0.h5\n",
      "750/750 [==============================] - 235s 313ms/step - loss: -0.0934 - acc: 0.9920 - val_loss: -0.1046 - val_acc: 0.9909\n",
      "Epoch 7/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: -0.1214 - acc: 0.9925\n",
      "New maximum F1 score: 0.8208286674132138 (before: 0.815946348733234) Saving to tmp_generator_NER_3cnn_nodense_best.0.h5\n",
      "750/750 [==============================] - 234s 312ms/step - loss: -0.1214 - acc: 0.9925 - val_loss: -0.1316 - val_acc: 0.9912\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 235s 314ms/step - loss: -0.1492 - acc: 0.9929 - val_loss: -0.1568 - val_acc: 0.9905\n",
      "Epoch 9/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: -0.1769 - acc: 0.9931\n",
      "New maximum F1 score: 0.8228339183447256 (before: 0.8208286674132138) Saving to tmp_generator_NER_3cnn_nodense_best.0.h5\n",
      "750/750 [==============================] - 232s 310ms/step - loss: -0.1770 - acc: 0.9931 - val_loss: -0.1849 - val_acc: 0.9914\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 238s 318ms/step - loss: -0.2045 - acc: 0.9936 - val_loss: -0.2112 - val_acc: 0.9911\n",
      "Epoch 1/15\n",
      "11/12 [==========================>...] - ETA: 5s - loss: -0.1927 - acc: 0.9944 \n",
      "New maximum F1 score: 0.8254612546125462 (before: 0) Saving to tmp_generator_NER_3cnn_nodense_best.0.h5\n",
      "12/12 [==============================] - 92s 8s/step - loss: -0.1927 - acc: 0.9944 - val_loss: -0.1853 - val_acc: 0.9914\n",
      "Epoch 2/15\n",
      "11/12 [==========================>...] - ETA: 4s - loss: -0.1935 - acc: 0.9945\n",
      "New maximum F1 score: 0.82752259730677 (before: 0.8254612546125462) Saving to tmp_generator_NER_3cnn_nodense_best.0.h5\n",
      "12/12 [==============================] - 78s 6s/step - loss: -0.1935 - acc: 0.9945 - val_loss: -0.1859 - val_acc: 0.9916\n",
      "Epoch 3/15\n",
      "11/12 [==========================>...] - ETA: 4s - loss: -0.1940 - acc: 0.9945\n",
      "New maximum F1 score: 0.8290519312511551 (before: 0.82752259730677) Saving to tmp_generator_NER_3cnn_nodense_best.0.h5\n",
      "12/12 [==============================] - 77s 6s/step - loss: -0.1940 - acc: 0.9945 - val_loss: -0.1865 - val_acc: 0.9915\n",
      "Epoch 4/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 79s 7s/step - loss: -0.1946 - acc: 0.9946 - val_loss: -0.1869 - val_acc: 0.9916\n",
      "Epoch 5/15\n",
      "12/12 [==============================] - 77s 6s/step - loss: -0.1952 - acc: 0.9946 - val_loss: -0.1873 - val_acc: 0.9916\n",
      "Epoch 6/15\n",
      "11/12 [==========================>...] - ETA: 4s - loss: -0.1956 - acc: 0.9947\n",
      "New maximum F1 score: 0.829520295202952 (before: 0.8290519312511551) Saving to tmp_generator_NER_3cnn_nodense_best.0.h5\n",
      "12/12 [==============================] - 76s 6s/step - loss: -0.1956 - acc: 0.9947 - val_loss: -0.1878 - val_acc: 0.9916\n",
      "Epoch 7/15\n",
      "11/12 [==========================>...] - ETA: 4s - loss: -0.1963 - acc: 0.9947\n",
      "New maximum F1 score: 0.829673371470751 (before: 0.829520295202952) Saving to tmp_generator_NER_3cnn_nodense_best.0.h5\n",
      "12/12 [==============================] - 81s 7s/step - loss: -0.1963 - acc: 0.9948 - val_loss: -0.1883 - val_acc: 0.9916\n",
      "Epoch 8/15\n",
      "12/12 [==============================] - 83s 7s/step - loss: -0.1969 - acc: 0.9948 - val_loss: -0.1887 - val_acc: 0.9916\n",
      "Epoch 9/15\n",
      "11/12 [==========================>...] - ETA: 4s - loss: -0.1973 - acc: 0.9949\n",
      "New maximum F1 score: 0.8299520472150497 (before: 0.829673371470751) Saving to tmp_generator_NER_3cnn_nodense_best.0.h5\n",
      "12/12 [==============================] - 84s 7s/step - loss: -0.1973 - acc: 0.9949 - val_loss: -0.1891 - val_acc: 0.9916\n",
      "Epoch 10/15\n",
      "11/12 [==========================>...] - ETA: 4s - loss: -0.1978 - acc: 0.9950\n",
      "New maximum F1 score: 0.8309963099630996 (before: 0.8299520472150497) Saving to tmp_generator_NER_3cnn_nodense_best.0.h5\n",
      "12/12 [==============================] - 85s 7s/step - loss: -0.1978 - acc: 0.9950 - val_loss: -0.1895 - val_acc: 0.9916\n",
      "Epoch 11/15\n",
      "11/12 [==========================>...] - ETA: 4s - loss: -0.1982 - acc: 0.9948\n",
      "New maximum F1 score: 0.8313030638612035 (before: 0.8309963099630996) Saving to tmp_generator_NER_3cnn_nodense_best.0.h5\n",
      "12/12 [==============================] - 85s 7s/step - loss: -0.1982 - acc: 0.9948 - val_loss: -0.1899 - val_acc: 0.9916\n",
      "Epoch 12/15\n",
      "11/12 [==========================>...] - ETA: 4s - loss: -0.1987 - acc: 0.9950\n",
      "New maximum F1 score: 0.8314565257522613 (before: 0.8313030638612035) Saving to tmp_generator_NER_3cnn_nodense_best.0.h5\n",
      "12/12 [==============================] - 84s 7s/step - loss: -0.1988 - acc: 0.9950 - val_loss: -0.1903 - val_acc: 0.9917\n",
      "Epoch 13/15\n",
      "12/12 [==============================] - 85s 7s/step - loss: -0.1994 - acc: 0.9950 - val_loss: -0.1908 - val_acc: 0.9917\n",
      "Epoch 14/15\n",
      "12/12 [==============================] - 87s 7s/step - loss: -0.1998 - acc: 0.9950 - val_loss: -0.1912 - val_acc: 0.9916\n",
      "Epoch 15/15\n",
      "12/12 [==============================] - 87s 7s/step - loss: -0.2003 - acc: 0.9951 - val_loss: -0.1915 - val_acc: 0.9916\n",
      "Run 1\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 52)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 52, 32) 10688       char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_37 (TimeDistri (None, None, 52, 32) 3104        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_40 (TimeDistri (None, None, 52, 32) 4128        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_43 (TimeDistri (None, None, 52, 32) 5152        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_38 (TimeDistri (None, None, 32)     0           time_distributed_37[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_41 (TimeDistri (None, None, 32)     0           time_distributed_40[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_44 (TimeDistri (None, None, 32)     0           time_distributed_43[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_39 (TimeDistri (None, None, 32)     0           time_distributed_38[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_42 (TimeDistri (None, None, 32)     0           time_distributed_41[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_45 (TimeDistri (None, None, 32)     0           time_distributed_44[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, None, 404)    0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_39[0][0]        \n",
      "                                                                 time_distributed_42[0][0]        \n",
      "                                                                 time_distributed_45[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, None, 400)    968000      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "crf (CRF)                       (None, None, 26)     11154       bidirectional_5[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,002,290\n",
      "Trainable params: 1,002,226\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0613 - acc: 0.9820\n",
      "New maximum F1 score: 0.7514941199151725 (before: 0) Saving to tmp_generator_NER_3cnn_nodense_best.1.h5\n",
      "750/750 [==============================] - 278s 370ms/step - loss: 0.0612 - acc: 0.9820 - val_loss: 0.0198 - val_acc: 0.9887\n",
      "Epoch 2/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9883\n",
      "New maximum F1 score: 0.7880517503805174 (before: 0.7514941199151725) Saving to tmp_generator_NER_3cnn_nodense_best.1.h5\n",
      "750/750 [==============================] - 261s 348ms/step - loss: 0.0110 - acc: 0.9883 - val_loss: -0.0041 - val_acc: 0.9900\n",
      "Epoch 3/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: -0.0146 - acc: 0.9896\n",
      "New maximum F1 score: 0.7946344228225959 (before: 0.7880517503805174) Saving to tmp_generator_NER_3cnn_nodense_best.1.h5\n",
      "750/750 [==============================] - 257s 342ms/step - loss: -0.0146 - acc: 0.9896 - val_loss: -0.0284 - val_acc: 0.9903\n",
      "Epoch 4/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: -0.0410 - acc: 0.9905\n",
      "New maximum F1 score: 0.8036546708931569 (before: 0.7946344228225959) Saving to tmp_generator_NER_3cnn_nodense_best.1.h5\n",
      "750/750 [==============================] - 261s 348ms/step - loss: -0.0410 - acc: 0.9905 - val_loss: -0.0538 - val_acc: 0.9906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: -0.0684 - acc: 0.9914\n",
      "New maximum F1 score: 0.816057293629853 (before: 0.8036546708931569) Saving to tmp_generator_NER_3cnn_nodense_best.1.h5\n",
      "750/750 [==============================] - 258s 344ms/step - loss: -0.0684 - acc: 0.9914 - val_loss: -0.0802 - val_acc: 0.9909\n",
      "Epoch 6/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: -0.0960 - acc: 0.9919\n",
      "New maximum F1 score: 0.819757688723206 (before: 0.816057293629853) Saving to tmp_generator_NER_3cnn_nodense_best.1.h5\n",
      "750/750 [==============================] - 263s 350ms/step - loss: -0.0960 - acc: 0.9919 - val_loss: -0.1074 - val_acc: 0.9914\n",
      "Epoch 7/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: -0.1238 - acc: 0.9924\n",
      "New maximum F1 score: 0.8220402084884586 (before: 0.819757688723206) Saving to tmp_generator_NER_3cnn_nodense_best.1.h5\n",
      "750/750 [==============================] - 260s 347ms/step - loss: -0.1238 - acc: 0.9924 - val_loss: -0.1340 - val_acc: 0.9914\n",
      "Epoch 8/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: -0.1516 - acc: 0.9929\n",
      "New maximum F1 score: 0.8227106227106228 (before: 0.8220402084884586) Saving to tmp_generator_NER_3cnn_nodense_best.1.h5\n",
      "750/750 [==============================] - 259s 345ms/step - loss: -0.1517 - acc: 0.9929 - val_loss: -0.1601 - val_acc: 0.9913\n",
      "Epoch 9/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: -0.1795 - acc: 0.9932\n",
      "New maximum F1 score: 0.8230513483561138 (before: 0.8227106227106228) Saving to tmp_generator_NER_3cnn_nodense_best.1.h5\n",
      "750/750 [==============================] - 259s 345ms/step - loss: -0.1795 - acc: 0.9932 - val_loss: -0.1870 - val_acc: 0.9915\n",
      "Epoch 10/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: -0.2069 - acc: 0.9935\n",
      "New maximum F1 score: 0.8241819190238491 (before: 0.8230513483561138) Saving to tmp_generator_NER_3cnn_nodense_best.1.h5\n",
      "750/750 [==============================] - 260s 346ms/step - loss: -0.2070 - acc: 0.9935 - val_loss: -0.2136 - val_acc: 0.9913\n",
      "Epoch 1/15\n",
      "11/12 [==========================>...] - ETA: 6s - loss: -0.2223 - acc: 0.9944 \n",
      "New maximum F1 score: 0.8250139172388198 (before: 0) Saving to tmp_generator_NER_3cnn_nodense_best.1.h5\n",
      "12/12 [==============================] - 101s 8s/step - loss: -0.2224 - acc: 0.9944 - val_loss: -0.2145 - val_acc: 0.9914\n",
      "Epoch 2/15\n",
      "12/12 [==============================] - 83s 7s/step - loss: -0.2231 - acc: 0.9945 - val_loss: -0.2149 - val_acc: 0.9914\n",
      "Epoch 3/15\n",
      "11/12 [==========================>...] - ETA: 4s - loss: -0.2238 - acc: 0.9947\n",
      "New maximum F1 score: 0.8258302583025829 (before: 0.8250139172388198) Saving to tmp_generator_NER_3cnn_nodense_best.1.h5\n",
      "12/12 [==============================] - 82s 7s/step - loss: -0.2238 - acc: 0.9947 - val_loss: -0.2153 - val_acc: 0.9915\n",
      "Epoch 4/15\n",
      "11/12 [==========================>...] - ETA: 4s - loss: -0.2245 - acc: 0.9949\n",
      "New maximum F1 score: 0.8264798082242302 (before: 0.8258302583025829) Saving to tmp_generator_NER_3cnn_nodense_best.1.h5\n",
      "12/12 [==============================] - 82s 7s/step - loss: -0.2245 - acc: 0.9948 - val_loss: -0.2157 - val_acc: 0.9915\n",
      "Epoch 5/15\n",
      "11/12 [==========================>...] - ETA: 4s - loss: -0.2250 - acc: 0.9949\n",
      "New maximum F1 score: 0.82687338501292 (before: 0.8264798082242302) Saving to tmp_generator_NER_3cnn_nodense_best.1.h5\n",
      "12/12 [==============================] - 82s 7s/step - loss: -0.2249 - acc: 0.9948 - val_loss: -0.2162 - val_acc: 0.9915\n",
      "Epoch 6/15\n",
      "12/12 [==============================] - 83s 7s/step - loss: -0.2255 - acc: 0.9948 - val_loss: -0.2165 - val_acc: 0.9914\n",
      "Epoch 7/15\n",
      "11/12 [==========================>...] - ETA: 4s - loss: -0.2259 - acc: 0.9949\n",
      "New maximum F1 score: 0.8278023598820059 (before: 0.82687338501292) Saving to tmp_generator_NER_3cnn_nodense_best.1.h5\n",
      "12/12 [==============================] - 83s 7s/step - loss: -0.2260 - acc: 0.9949 - val_loss: -0.2170 - val_acc: 0.9915\n",
      "Epoch 8/15\n",
      "12/12 [==============================] - 82s 7s/step - loss: -0.2266 - acc: 0.9950 - val_loss: -0.2174 - val_acc: 0.9914\n",
      "Epoch 9/15\n",
      "11/12 [==========================>...] - ETA: 4s - loss: -0.2269 - acc: 0.9949\n",
      "New maximum F1 score: 0.8279292557111274 (before: 0.8278023598820059) Saving to tmp_generator_NER_3cnn_nodense_best.1.h5\n",
      "12/12 [==============================] - 80s 7s/step - loss: -0.2270 - acc: 0.9950 - val_loss: -0.2178 - val_acc: 0.9915\n",
      "Epoch 10/15\n",
      "12/12 [==============================] - 81s 7s/step - loss: -0.2276 - acc: 0.9951 - val_loss: -0.2182 - val_acc: 0.9915\n",
      "Epoch 11/15\n",
      "12/12 [==============================] - 82s 7s/step - loss: -0.2281 - acc: 0.9951 - val_loss: -0.2186 - val_acc: 0.9915\n",
      "Epoch 12/15\n",
      "12/12 [==============================] - 82s 7s/step - loss: -0.2285 - acc: 0.9951 - val_loss: -0.2190 - val_acc: 0.9914\n",
      "Epoch 13/15\n",
      "12/12 [==============================] - 82s 7s/step - loss: -0.2291 - acc: 0.9951 - val_loss: -0.2194 - val_acc: 0.9914\n",
      "Epoch 14/15\n",
      "12/12 [==============================] - 75s 6s/step - loss: -0.2295 - acc: 0.9951 - val_loss: -0.2198 - val_acc: 0.9914\n",
      "Epoch 15/15\n",
      "12/12 [==============================] - 72s 6s/step - loss: -0.2301 - acc: 0.9952 - val_loss: -0.2202 - val_acc: 0.9914\n",
      "Run 2\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 52)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 52, 32) 10688       char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_46 (TimeDistri (None, None, 52, 32) 3104        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_49 (TimeDistri (None, None, 52, 32) 4128        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_52 (TimeDistri (None, None, 52, 32) 5152        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_47 (TimeDistri (None, None, 32)     0           time_distributed_46[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_50 (TimeDistri (None, None, 32)     0           time_distributed_49[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_53 (TimeDistri (None, None, 32)     0           time_distributed_52[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_48 (TimeDistri (None, None, 32)     0           time_distributed_47[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_51 (TimeDistri (None, None, 32)     0           time_distributed_50[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_54 (TimeDistri (None, None, 32)     0           time_distributed_53[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, None, 404)    0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_48[0][0]        \n",
      "                                                                 time_distributed_51[0][0]        \n",
      "                                                                 time_distributed_54[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, None, 400)    968000      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "crf (CRF)                       (None, None, 26)     11154       bidirectional_6[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,002,290\n",
      "Trainable params: 1,002,226\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0685 - acc: 0.9820\n",
      "New maximum F1 score: 0.7461318051575931 (before: 0) Saving to tmp_generator_NER_3cnn_nodense_best.2.h5\n",
      "750/750 [==============================] - 250s 333ms/step - loss: 0.0684 - acc: 0.9820 - val_loss: 0.0293 - val_acc: 0.9884\n",
      "Epoch 2/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9883\n",
      "New maximum F1 score: 0.7803379416282642 (before: 0.7461318051575931) Saving to tmp_generator_NER_3cnn_nodense_best.2.h5\n",
      "750/750 [==============================] - 227s 303ms/step - loss: 0.0193 - acc: 0.9883 - val_loss: 0.0035 - val_acc: 0.9897\n",
      "Epoch 3/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: -0.0072 - acc: 0.9897\n",
      "New maximum F1 score: 0.7954587753582729 (before: 0.7803379416282642) Saving to tmp_generator_NER_3cnn_nodense_best.2.h5\n",
      "750/750 [==============================] - 230s 307ms/step - loss: -0.0072 - acc: 0.9898 - val_loss: -0.0210 - val_acc: 0.9904\n",
      "Epoch 4/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: -0.0343 - acc: 0.9906\n",
      "New maximum F1 score: 0.7988940092165899 (before: 0.7954587753582729) Saving to tmp_generator_NER_3cnn_nodense_best.2.h5\n",
      "750/750 [==============================] - 237s 316ms/step - loss: -0.0343 - acc: 0.9906 - val_loss: -0.0461 - val_acc: 0.9901\n",
      "Epoch 5/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: -0.0619 - acc: 0.9915\n",
      "New maximum F1 score: 0.8130806391675958 (before: 0.7988940092165899) Saving to tmp_generator_NER_3cnn_nodense_best.2.h5\n",
      "750/750 [==============================] - 240s 319ms/step - loss: -0.0619 - acc: 0.9915 - val_loss: -0.0737 - val_acc: 0.9907\n",
      "Epoch 6/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: -0.0897 - acc: 0.9920\n",
      "New maximum F1 score: 0.8134078212290503 (before: 0.8130806391675958) Saving to tmp_generator_NER_3cnn_nodense_best.2.h5\n",
      "750/750 [==============================] - 241s 322ms/step - loss: -0.0897 - acc: 0.9920 - val_loss: -0.1008 - val_acc: 0.9910\n",
      "Epoch 7/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: -0.1175 - acc: 0.9925\n",
      "New maximum F1 score: 0.8198248555990311 (before: 0.8134078212290503) Saving to tmp_generator_NER_3cnn_nodense_best.2.h5\n",
      "750/750 [==============================] - 243s 324ms/step - loss: -0.1176 - acc: 0.9925 - val_loss: -0.1280 - val_acc: 0.9910\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 240s 320ms/step - loss: -0.1453 - acc: 0.9929 - val_loss: -0.1539 - val_acc: 0.9909\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 225s 300ms/step - loss: -0.1731 - acc: 0.9933 - val_loss: -0.1804 - val_acc: 0.9910\n",
      "Epoch 10/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: -0.2008 - acc: 0.9936\n",
      "New maximum F1 score: 0.8221520163538375 (before: 0.8198248555990311) Saving to tmp_generator_NER_3cnn_nodense_best.2.h5\n",
      "750/750 [==============================] - 251s 334ms/step - loss: -0.2008 - acc: 0.9936 - val_loss: -0.2077 - val_acc: 0.9911\n",
      "Epoch 1/15\n",
      "11/12 [==========================>...] - ETA: 6s - loss: -0.2161 - acc: 0.9945 \n",
      "New maximum F1 score: 0.8192548874953891 (before: 0) Saving to tmp_generator_NER_3cnn_nodense_best.2.h5\n",
      "12/12 [==============================] - 95s 8s/step - loss: -0.2161 - acc: 0.9945 - val_loss: -0.2078 - val_acc: 0.9910\n",
      "Epoch 2/15\n",
      "11/12 [==========================>...] - ETA: 4s - loss: -0.2168 - acc: 0.9946\n",
      "New maximum F1 score: 0.8216454997239094 (before: 0.8192548874953891) Saving to tmp_generator_NER_3cnn_nodense_best.2.h5\n",
      "12/12 [==============================] - 83s 7s/step - loss: -0.2169 - acc: 0.9946 - val_loss: -0.2083 - val_acc: 0.9911\n",
      "Epoch 3/15\n",
      "11/12 [==========================>...] - ETA: 4s - loss: -0.2175 - acc: 0.9947\n",
      "New maximum F1 score: 0.8223163321671884 (before: 0.8216454997239094) Saving to tmp_generator_NER_3cnn_nodense_best.2.h5\n",
      "12/12 [==============================] - 80s 7s/step - loss: -0.2175 - acc: 0.9947 - val_loss: -0.2088 - val_acc: 0.9912\n",
      "Epoch 4/15\n",
      "12/12 [==============================] - 81s 7s/step - loss: -0.2182 - acc: 0.9948 - val_loss: -0.2092 - val_acc: 0.9911\n",
      "Epoch 5/15\n",
      "12/12 [==============================] - 81s 7s/step - loss: -0.2187 - acc: 0.9948 - val_loss: -0.2097 - val_acc: 0.9911\n",
      "Epoch 6/15\n",
      "11/12 [==========================>...] - ETA: 4s - loss: -0.2192 - acc: 0.9949\n",
      "New maximum F1 score: 0.8242446573323507 (before: 0.8223163321671884) Saving to tmp_generator_NER_3cnn_nodense_best.2.h5\n",
      "12/12 [==============================] - 85s 7s/step - loss: -0.2192 - acc: 0.9949 - val_loss: -0.2101 - val_acc: 0.9912\n",
      "Epoch 7/15\n",
      "12/12 [==============================] - 81s 7s/step - loss: -0.2198 - acc: 0.9950 - val_loss: -0.2105 - val_acc: 0.9912\n",
      "Epoch 8/15\n",
      "12/12 [==============================] - 81s 7s/step - loss: -0.2203 - acc: 0.9951 - val_loss: -0.2109 - val_acc: 0.9911\n",
      "Epoch 9/15\n",
      "12/12 [==============================] - 81s 7s/step - loss: -0.2210 - acc: 0.9951 - val_loss: -0.2114 - val_acc: 0.9912\n",
      "Epoch 10/15\n",
      "11/12 [==========================>...] - ETA: 4s - loss: -0.2215 - acc: 0.9951\n",
      "New maximum F1 score: 0.8258706467661692 (before: 0.8242446573323507) Saving to tmp_generator_NER_3cnn_nodense_best.2.h5\n",
      "12/12 [==============================] - 79s 7s/step - loss: -0.2214 - acc: 0.9951 - val_loss: -0.2118 - val_acc: 0.9913\n",
      "Epoch 11/15\n",
      "12/12 [==============================] - 80s 7s/step - loss: -0.2219 - acc: 0.9951 - val_loss: -0.2122 - val_acc: 0.9912\n",
      "Epoch 12/15\n",
      "11/12 [==========================>...] - ETA: 4s - loss: -0.2222 - acc: 0.9951\n",
      "New maximum F1 score: 0.826239174497881 (before: 0.8258706467661692) Saving to tmp_generator_NER_3cnn_nodense_best.2.h5\n",
      "12/12 [==============================] - 80s 7s/step - loss: -0.2222 - acc: 0.9951 - val_loss: -0.2127 - val_acc: 0.9913\n",
      "Epoch 13/15\n",
      "12/12 [==============================] - 76s 6s/step - loss: -0.2227 - acc: 0.9951 - val_loss: -0.2132 - val_acc: 0.9913\n",
      "Epoch 14/15\n",
      "12/12 [==============================] - 78s 7s/step - loss: -0.2232 - acc: 0.9952 - val_loss: -0.2135 - val_acc: 0.9913\n",
      "Epoch 15/15\n",
      "12/12 [==============================] - 79s 7s/step - loss: -0.2238 - acc: 0.9953 - val_loss: -0.2139 - val_acc: 0.9913\n",
      "Run 3\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 52)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 52, 32) 10688       char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_55 (TimeDistri (None, None, 52, 32) 3104        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_58 (TimeDistri (None, None, 52, 32) 4128        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_61 (TimeDistri (None, None, 52, 32) 5152        char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_56 (TimeDistri (None, None, 32)     0           time_distributed_55[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_59 (TimeDistri (None, None, 32)     0           time_distributed_58[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_62 (TimeDistri (None, None, 32)     0           time_distributed_61[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_57 (TimeDistri (None, None, 32)     0           time_distributed_56[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_60 (TimeDistri (None, None, 32)     0           time_distributed_59[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_63 (TimeDistri (None, None, 32)     0           time_distributed_62[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, None, 404)    0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_57[0][0]        \n",
      "                                                                 time_distributed_60[0][0]        \n",
      "                                                                 time_distributed_63[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, None, 400)    968000      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "crf (CRF)                       (None, None, 26)     11154       bidirectional_7[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,002,290\n",
      "Trainable params: 1,002,226\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0647 - acc: 0.9821\n",
      "New maximum F1 score: 0.7454933126574917 (before: 0) Saving to tmp_generator_NER_3cnn_nodense_best.3.h5\n",
      "750/750 [==============================] - 249s 332ms/step - loss: 0.0646 - acc: 0.9821 - val_loss: 0.0245 - val_acc: 0.9884\n",
      "Epoch 2/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9883\n",
      "New maximum F1 score: 0.77794852093738 (before: 0.7454933126574917) Saving to tmp_generator_NER_3cnn_nodense_best.3.h5\n",
      "750/750 [==============================] - 247s 329ms/step - loss: 0.0144 - acc: 0.9883 - val_loss: -5.4810e-04 - val_acc: 0.9895\n",
      "Epoch 3/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: -0.0119 - acc: 0.9898\n",
      "New maximum F1 score: 0.7941176470588234 (before: 0.77794852093738) Saving to tmp_generator_NER_3cnn_nodense_best.3.h5\n",
      "750/750 [==============================] - 264s 353ms/step - loss: -0.0119 - acc: 0.9898 - val_loss: -0.0251 - val_acc: 0.9903\n",
      "Epoch 4/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: -0.0385 - acc: 0.9907\n",
      "New maximum F1 score: 0.8068991376077989 (before: 0.7941176470588234) Saving to tmp_generator_NER_3cnn_nodense_best.3.h5\n",
      "750/750 [==============================] - 267s 356ms/step - loss: -0.0385 - acc: 0.9907 - val_loss: -0.0521 - val_acc: 0.9909\n",
      "Epoch 5/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: -0.0658 - acc: 0.9913\n",
      "New maximum F1 score: 0.8128041931860726 (before: 0.8068991376077989) Saving to tmp_generator_NER_3cnn_nodense_best.3.h5\n",
      "750/750 [==============================] - 266s 354ms/step - loss: -0.0658 - acc: 0.9913 - val_loss: -0.0781 - val_acc: 0.9910\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 263s 351ms/step - loss: -0.0938 - acc: 0.9921 - val_loss: -0.1047 - val_acc: 0.9910\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 263s 351ms/step - loss: -0.1214 - acc: 0.9923 - val_loss: -0.1304 - val_acc: 0.9908\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 266s 355ms/step - loss: -0.1493 - acc: 0.9928 - val_loss: -0.1583 - val_acc: 0.9912\n",
      "Epoch 9/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: -0.1773 - acc: 0.9935\n",
      "New maximum F1 score: 0.8151747336946366 (before: 0.8128041931860726) Saving to tmp_generator_NER_3cnn_nodense_best.3.h5\n",
      "750/750 [==============================] - 288s 384ms/step - loss: -0.1773 - acc: 0.9935 - val_loss: -0.1851 - val_acc: 0.9913\n",
      "Epoch 10/10\n",
      "749/750 [============================>.] - ETA: 0s - loss: -0.2047 - acc: 0.9935\n",
      "New maximum F1 score: 0.8177810433504775 (before: 0.8151747336946366) Saving to tmp_generator_NER_3cnn_nodense_best.3.h5\n",
      "750/750 [==============================] - 278s 371ms/step - loss: -0.2048 - acc: 0.9935 - val_loss: -0.2112 - val_acc: 0.9910\n",
      "Epoch 1/15\n",
      "11/12 [==========================>...] - ETA: 7s - loss: -0.2203 - acc: 0.9945 \n",
      "New maximum F1 score: 0.8232463446233576 (before: 0) Saving to tmp_generator_NER_3cnn_nodense_best.3.h5\n",
      "12/12 [==============================] - 112s 9s/step - loss: -0.2203 - acc: 0.9945 - val_loss: -0.2121 - val_acc: 0.9913\n",
      "Epoch 2/15\n",
      "11/12 [==========================>...] - ETA: 5s - loss: -0.2208 - acc: 0.9945 \n",
      "New maximum F1 score: 0.8242894056847546 (before: 0.8232463446233576) Saving to tmp_generator_NER_3cnn_nodense_best.3.h5\n",
      "12/12 [==============================] - 96s 8s/step - loss: -0.2209 - acc: 0.9945 - val_loss: -0.2126 - val_acc: 0.9914\n",
      "Epoch 3/15\n",
      "11/12 [==========================>...] - ETA: 5s - loss: -0.2216 - acc: 0.9947 \n",
      "New maximum F1 score: 0.8259587020648967 (before: 0.8242894056847546) Saving to tmp_generator_NER_3cnn_nodense_best.3.h5\n",
      "12/12 [==============================] - 94s 8s/step - loss: -0.2217 - acc: 0.9947 - val_loss: -0.2131 - val_acc: 0.9915\n",
      "Epoch 4/15\n",
      "12/12 [==============================] - 93s 8s/step - loss: -0.2222 - acc: 0.9948 - val_loss: -0.2135 - val_acc: 0.9915\n",
      "Epoch 5/15\n",
      "11/12 [==========================>...] - ETA: 5s - loss: -0.2228 - acc: 0.9949 \n",
      "New maximum F1 score: 0.8272174073391112 (before: 0.8259587020648967) Saving to tmp_generator_NER_3cnn_nodense_best.3.h5\n",
      "12/12 [==============================] - 96s 8s/step - loss: -0.2229 - acc: 0.9949 - val_loss: -0.2141 - val_acc: 0.9915\n",
      "Epoch 6/15\n",
      "11/12 [==========================>...] - ETA: 5s - loss: -0.2233 - acc: 0.9949 \n",
      "New maximum F1 score: 0.8284765769088897 (before: 0.8272174073391112) Saving to tmp_generator_NER_3cnn_nodense_best.3.h5\n",
      "12/12 [==============================] - 93s 8s/step - loss: -0.2234 - acc: 0.9949 - val_loss: -0.2145 - val_acc: 0.9916\n",
      "Epoch 7/15\n",
      " 6/12 [==============>...............] - ETA: 30s - loss: -0.2237 - acc: 0.9948"
     ]
    }
   ],
   "source": [
    "f = open('results_3cnn_nodense.txt', 'a')\n",
    "for run_i in range(10):\n",
    "    print(\"Run \" + str(run_i))\n",
    "    \n",
    "    tmp_model_filename = 'tmp_generator_NER_3cnn_nodense_best.' + str(run_i) + '.h5'\n",
    "\n",
    "    history = utils.F1History(tmp_model_filename, devSet=devSentences)\n",
    "\n",
    "    model = models.get_model_3cnn()\n",
    "    model.fit_generator(\n",
    "        utils.NerSequence(trainSentences, shuffle_data=True, batch_size=32), \n",
    "        validation_data = utils.NerSequence(devSentences, batch_size=512), \n",
    "        epochs = 10, callbacks = [history]\n",
    "    )\n",
    "    \n",
    "    model.load_weights(tmp_model_filename)\n",
    "    \n",
    "    model.fit_generator(\n",
    "        utils.NerSequence(trainSentences, shuffle_data=True, batch_size=2048), \n",
    "        validation_data = utils.NerSequence(devSentences, batch_size=512), \n",
    "        epochs = 15, callbacks = [history]\n",
    "    )\n",
    "    \n",
    "    model.load_weights(tmp_model_filename)\n",
    "    \n",
    "    true_labels, pred_labels = utils.predict_sequences(model, testSentences)\n",
    "    \n",
    "    pre, rec, f1 = compute_f1(pred_labels, true_labels, models.idx2Label)\n",
    "    f.write(str(run_i) + \"\\t\" + str(pre) + \"\\t\" + str(rec) +  \"\\t\" + str(f1))\n",
    "    f.write(\"\\n\")\n",
    "    f.flush()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, json\n",
    "# copy file for best run\n",
    "shutil.copyfile('tmp_3cnn_bi-lstm.h5', '../models/final_model_germeval_outer.h5')\n",
    "with open(\"../models/final_model_germeval.indexes\", \"w\") as f:\n",
    "    json.dump([models.idx2Label, models.label2Idx, models.char2Idx, models.case2Idx], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_contrib.layers import CRF\n",
    "def create_custom_objects():\n",
    "    instanceHolder = {\"instance\": None}\n",
    "    class ClassWrapper(CRF):\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            instanceHolder[\"instance\"] = self\n",
    "            super(ClassWrapper, self).__init__(*args, **kwargs)\n",
    "    def loss(*args):\n",
    "        method = getattr(instanceHolder[\"instance\"], \"loss_function\")\n",
    "        return method(*args)\n",
    "    def accuracy(*args):\n",
    "        method = getattr(instanceHolder[\"instance\"], \"accuracy\")\n",
    "        return method(*args)\n",
    "    return {\"ClassWrapper\": ClassWrapper ,\"CRF\": ClassWrapper, \"loss\": loss, \"accuracy\":accuracy}\n",
    "\n",
    "finalmodel = load_model('../models/final_model_germeval_outer.h5', custom_objects=create_custom_objects())\n",
    "true_labels, pred_labels = utils.predict_sequences(finalmodel, testSentences)\n",
    "print(compute_f1(pred_labels, true_labels, models.idx2Label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('germeval_output.tsv', 'w', encoding='UTF-8')\n",
    "for i_sent, sent in enumerate(testSentences):\n",
    "    for i_tok, tok in enumerate(sent):\n",
    "        if tok[0] == 'PADDING_TOKEN':\n",
    "            break\n",
    "        correctlabel = models.idx2Label[true_labels[i_sent][i_tok]]\n",
    "        guessedlabel = models.idx2Label[pred_labels[i_sent][i_tok]]\n",
    "        line = \"\\t\".join([str(i_tok+1), tok[0], correctlabel, correctlabel, guessedlabel, guessedlabel])\n",
    "        f.write(line + '\\n')\n",
    "    f.write('\\n')\n",
    "f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
