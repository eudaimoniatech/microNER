{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gwiedemann/miniconda3/envs/kerasenv/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import fastText\n",
    "\n",
    "from validation import compute_f1\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "\n",
    "import models\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000\n",
      "2200\n",
      "5100\n"
     ]
    }
   ],
   "source": [
    "trainSentences = utils.get_sentences_germeval('../data/GermEVAL/NER-de-train.tsv')\n",
    "devSentences = utils.get_sentences_germeval('../data/GermEVAL/NER-de-dev.tsv')\n",
    "testSentences = utils.get_sentences_germeval('../data/GermEVAL/NER-de-test.tsv')\n",
    "\n",
    "# trainSentences = utils.get_sentences_conll('../data/CONLL/deu/deu_utf.train.bio')\n",
    "# devSentences = utils.get_sentences_conll('../data/CONLL/deu/deu_utf.testa.bio')\n",
    "# testSentences = utils.get_sentences_conll('../data/CONLL/deu/deu_utf.testb.bio')\n",
    "\n",
    "print(len(trainSentences))\n",
    "print(len(devSentences))\n",
    "print(len(testSentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Die', 'O'], ['These', 'O'], [',', 'O'], ['Schlatter', 'B-PER'], ['sei', 'O'], ['Antisemit', 'O'], ['gewesen', 'O'], [',', 'O'], ['wurde', 'O'], ['seither', 'O'], ['in', 'O'], ['der', 'O'], ['theologischen', 'O'], ['Fachliteratur', 'O'], ['nicht', 'O'], ['mehr', 'O'], ['vertreten', 'O'], ['.', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(testSentences[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelSet = set()\n",
    "characters= set()\n",
    "models.max_sequence_length = 0\n",
    "\n",
    "for dataset in [trainSentences, devSentences, testSentences]:\n",
    "    for sentence in dataset:\n",
    "        for word, label in sentence:\n",
    "            for char in word:\n",
    "                characters.add(char)\n",
    "            labelSet.add(label)\n",
    "        if len(sentence) > models.max_sequence_length:\n",
    "            models.max_sequence_length = len(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "print(len(labelSet))\n",
    "print(models.max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# :: Create a mapping for the labels ::\n",
    "models.label2Idx = {\"PADDING_TOKEN\":0}\n",
    "for label in labelSet:\n",
    "    models.label2Idx[label] = len(models.label2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'I-ORGpart': 1, 'I-PER': 2, 'B-LOCderiv': 15, 'B-LOC': 14, 'B-PER': 3, 'I-LOCderiv': 4, 'I-LOC': 6, 'I-LOCpart': 17, 'B-PERderiv': 8, 'B-OTHderiv': 18, 'B-PERpart': 10, 'B-LOCpart': 20, 'B-OTH': 21, 'I-OTHderiv': 5, 'PADDING_TOKEN': 0, 'I-ORGderiv': 9, 'B-OTHpart': 16, 'I-ORG': 7, 'B-ORGpart': 23, 'O': 11, 'B-ORG': 24, 'I-OTH': 25, 'B-ORGderiv': 12, 'I-PERderiv': 22, 'I-PERpart': 13, 'I-OTHpart': 19}\n"
     ]
    }
   ],
   "source": [
    "print(models.label2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# :: Hard coded case lookup ::\n",
    "models.case2Idx = {'PADDING_TOKEN':0, 'numeric': 1, 'allLower':2, 'allUpper':3, 'initialUpper':4, 'other':5, 'mainly_numeric':6, 'contains_digit': 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mainly_numeric': 6, 'initialUpper': 4, 'contains_digit': 7, 'allUpper': 3, 'numeric': 1, 'other': 5, 'PADDING_TOKEN': 0, 'allLower': 2}\n"
     ]
    }
   ],
   "source": [
    "print(models.case2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(trainSentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Schartau', 'B-PER'], ['sagte', 'O'], ['dem', 'O'], ['\"', 'O'], ['Tagesspiegel', 'B-ORG'], ['\"', 'O'], ['vom', 'O'], ['Freitag', 'O'], [',', 'O'], ['Fischer', 'B-PER'], ['sei', 'O'], ['\"', 'O'], ['in', 'O'], ['einer', 'O'], ['Weise', 'O'], ['aufgetreten', 'O'], [',', 'O'], ['die', 'O'], ['alles', 'O'], ['andere', 'O'], ['als', 'O'], ['überzeugend', 'O'], ['war', 'O'], ['\"', 'O'], ['.', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(trainSentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'⋅': 5, 'ą': 6, 'X': 319, 'ē': 300, '_': 8, '−': 187, 'η': 9, 'λ': 304, '<': 56, 'ḫ': 10, '傳': 11, 'ō': 12, 'ř': 13, 'F': 14, 'š': 15, 'E': 16, '학': 17, '‹': 18, 'y': 19, 'Λ': 21, 'n': 22, 'K': 23, 'B': 112, 'S': 25, 'ḳ': 171, 'з': 26, '»': 27, 'ž': 28, 'r': 29, '</S>': 2, 'È': 32, '術': 225, '章': 275, 'v': 33, 'Ö': 34, 'П': 36, '→': 192, 'À': 37, 'Л': 38, '佐': 173, 'o': 39, 'ю': 40, '1': 41, 'Ø': 43, '`': 44, 'Ż': 47, 'č': 46, 'ā': 302, '}': 48, 'Å': 49, '³': 51, '\"': 61, 'ъ': 327, 'ő': 52, 'µ': 53, 'п': 180, 'ñ': 55, 'ب': 57, 'у': 58, 'k': 177, 'д': 59, 'Ä': 179, '0': 60, '<W>': 3, '†': 62, 'ť': 63, 'ن': 65, 'ĩ': 66, 'J': 67, '\\u200e': 69, 'ệ': 71, 'P': 72, 'õ': 75, ')': 74, 'υ': 77, 'В': 289, 'М': 282, 'т': 64, 'ж': 20, '別': 196, '©': 78, '≘': 80, '公': 83, 'z': 325, ':': 84, '½': 86, 'й': 88, 'à': 90, '寝': 284, '동': 91, '–': 92, '.': 93, 'к': 94, 'q': 95, 'γ': 97, '\\xad': 98, 'ċ': 235, '$': 99, 'м': 100, 'Ш': 101, ';': 102, 'е': 125, 'ά': 70, '柯': 104, 'N': 105, 'φ': 107, '鶴': 109, '</W>': 4, 'f': 110, 'ы': 117, 'A': 113, 'Т': 120, '造': 118, 'ç': 116, '守': 121, 'έ': 119, 'Þ': 294, '£': 122, 'ο': 132, 'Î': 239, 'σ': 24, 'É': 123, '<S>': 1, '九': 124, 'D': 73, 'є': 128, 'é': 126, 'Ş': 266, '@': 292, 'c': 129, 'α': 130, 'p': 131, 'Ü': 133, 'R': 134, '~': 135, 'Æ': 136, 'ħ': 137, 'Π': 138, '\\x92': 139, 'U': 68, 'ε': 140, '[': 141, 'è': 142, 'ῦ': 144, '’': 255, 'И': 245, '太': 147, 'Е': 146, 'Â': 149, '冲': 148, 'í': 152, 'ǒ': 154, 'İ': 155, '″': 156, 'ü': 111, '2': 157, 'Z': 158, '南': 7, '”': 160, 'á': 324, 'Ž': 248, '妃': 162, 'У': 163, 'Č': 165, '⊃': 167, 'œ': 168, 'ν': 169, 'ć': 170, '\\x95': 172, '¹': 200, 'd': 174, 'ň': 175, 'g': 176, 'l': 30, 'ū': 181, 'أ': 257, '博': 82, '·': 182, 'V': 183, 'G': 79, 'T': 184, 'w': 185, 'ـ': 50, '×': 188, 's': 189, \"'\": 190, '3': 143, 'ö': 193, 'ι': 81, 'ς': 195, 'β': 312, 'р': 197, '4': 252, 'б': 203, '樓': 329, '#': 198, 'O': 199, 'х': 202, '9': 145, 'Y': 254, 'ê': 205, '¤': 315, 'ğ': 303, 'î': 207, '(': 35, 'â': 208, 'C': 209, 'Q': 85, 'i': 211, 'h': 150, '懿': 296, '▪': 212, 'ź': 213, 'ό': 214, '…': 215, 'x': 87, 'н': 54, 'ń': 220, '%': 221, 'π': 204, 'ă': 223, 'ا': 206, '²': 151, '士': 259, 'о': 224, 'τ': 194, 'Œ': 226, 'u': 227, 'ð': 322, 'ي': 228, '§': 153, 'UNKNOWN': 333, 'a': 229, 'ī': 231, 'ë': 232, 'ض': 234, 'æ': 238, 'Ł': 236, 'ρ': 237, 'ŏ': 240, ']': 233, 'κ': 241, 'W': 242, '\\x94': 243, 'ú': 244, '>': 246, 'ę': 293, '6': 247, 'Ц': 249, 'я': 250, 'ʻ': 316, '\\x80': 42, 'и': 186, 'ł': 76, 'ь': 96, '5': 256, 'л': 210, '‚': 191, 'ô': 219, 'ɨ': 201, '„': 260, 'с': 261, '鷹': 262, '›': 263, 'ý': 264, '“': 265, 'ß': 230, '&': 268, 'ś': 269, 'в': 45, 'ó': 270, '7': 301, '¸': 251, '´': 272, '+': 273, 'j': 274, ',': 159, '≤': 89, 'г': 276, '-': 323, '별': 217, '殿': 320, '루': 277, '/': 278, 'オ': 279, 'ě': 216, 'M': 280, 'H': 281, '8': 178, '±': 283, 'L': 115, '貴': 285, 'b': 286, '«': 287, 'm': 288, 'û': 161, 'å': 290, 'e': 291, '—': 127, '*': 114, 'ş': 295, '\\x9a': 297, '‐': 298, '‘': 299, 'ї': 222, '?': 328, 'PADDING_TOKEN': 0, '東': 103, 'ã': 218, 'Š': 305, '=': 306, '台': 307, '!': 308, 'ế': 309, 'ı': 310, 'Á': 311, 'I': 313, 'С': 314, '\\x96': 317, 'а': 318, 'Ġ': 108, '€': 330, 't': 321, 'ψ': 258, 'ø': 164, '°': 326, 'ラ': 106, 'ņ': 253, '대': 166, '\\x99': 267, '算': 271, 'ä': 31, '李': 331, 'ż': 332}\n"
     ]
    }
   ],
   "source": [
    "models.char2Idx={\"PADDING_TOKEN\":0, \"<S>\":1, \"</S>\":2, \"<W>\":3, \"</W>\":4}\n",
    "for char in characters:\n",
    "    models.char2Idx[char] = len(models.char2Idx)\n",
    "models.char2Idx['UNKNOWN'] = len(models.char2Idx)\n",
    "print(models.char2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Schartau', 'B-PER'], ['sagte', 'O'], ['dem', 'O'], ['\"', 'O'], ['Tagesspiegel', 'B-ORG'], ['\"', 'O'], ['vom', 'O'], ['Freitag', 'O'], [',', 'O'], ['Fischer', 'B-PER'], ['sei', 'O'], ['\"', 'O'], ['in', 'O'], ['einer', 'O'], ['Weise', 'O'], ['aufgetreten', 'O'], [',', 'O'], ['die', 'O'], ['alles', 'O'], ['andere', 'O'], ['als', 'O'], ['überzeugend', 'O'], ['war', 'O'], ['\"', 'O'], ['.', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(trainSentences[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.ft = fastText.load_model(\"../embeddings/wiki.de.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "print(models.nb_embedding_dims)\n",
    "print(len(trainSentences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "models.idx2Label = {v: k for k, v in models.label2Idx.items()}\n",
    "print(len(models.label2Idx))\n",
    "print(len(models.idx2Label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models' from '/home/gwiedemann/microNER/scripts/models.py'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_model_filename = 'model_lstm2_germeval.h5'\n",
    "# checkpoint = ModelCheckpoint(tmp_model_filename, verbose=1, save_best_only = True, monitor = 'val_acc')\n",
    "history = utils.F1History(tmp_model_filename, devSet = devSentences)\n",
    "model = models.get_model_2lstm_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/home/gwiedemann/microNER/scripts/utils.py'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    utils.NerSequence(trainSentences[:1000], shuffle_data=True, batch_size=256), \n",
    "    validation_data = utils.NerSequence(devSentences[:1000], batch_size=256), \n",
    "    epochs = 3, callbacks = [history]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.acc)\n",
    "print(history.f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(tmp_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    utils.NerSequence(trainSentences, shuffle_data=True, batch_size=2048), \n",
    "    validation_data = utils.NerSequence(devSentences, batch_size=256), \n",
    "    epochs = 5, callbacks = [history]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(tmp_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels, pred_labels = utils.predict_sequences(model, testSentences[:1000])\n",
    "print(compute_f1(pred_labels, true_labels, models.idx2Label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 52)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 52, 32) 10688       char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, None, 52, 100 33200       char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, None, 100)    60400       time_distributed_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, None, 408)    0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, None, 400)    974400      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "crf (CRF)                       (None, None, 26)     11154       bidirectional_9[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,089,906\n",
      "Trainable params: 1,089,842\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: 0.0446 - acc: 0.9837\n",
      "New maximum F1 score: 0.7668912415784408 (before: 0) Saving to model_lstm2_germeval.0.h5\n",
      "1500/1500 [==============================] - 807s 538ms/step - loss: 0.0446 - acc: 0.9837 - val_loss: 0.0012 - val_acc: 0.9892\n",
      "Epoch 2/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.0210 - acc: 0.9889\n",
      "New maximum F1 score: 0.7849141150112025 (before: 0.7668912415784408) Saving to model_lstm2_germeval.0.h5\n",
      "1500/1500 [==============================] - 790s 527ms/step - loss: -0.0210 - acc: 0.9889 - val_loss: -0.0485 - val_acc: 0.9900\n",
      "Epoch 3/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.0747 - acc: 0.9899\n",
      "New maximum F1 score: 0.7995452823039031 (before: 0.7849141150112025) Saving to model_lstm2_germeval.0.h5\n",
      "1500/1500 [==============================] - 786s 524ms/step - loss: -0.0747 - acc: 0.9899 - val_loss: -0.1026 - val_acc: 0.9902\n",
      "Epoch 4/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.1300 - acc: 0.9908\n",
      "New maximum F1 score: 0.811751497005988 (before: 0.7995452823039031) Saving to model_lstm2_germeval.0.h5\n",
      "1500/1500 [==============================] - 791s 527ms/step - loss: -0.1301 - acc: 0.9908 - val_loss: -0.1567 - val_acc: 0.9912\n",
      "Epoch 5/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.1855 - acc: 0.9914\n",
      "New maximum F1 score: 0.8117845749671608 (before: 0.811751497005988) Saving to model_lstm2_germeval.0.h5\n",
      "1500/1500 [==============================] - 792s 528ms/step - loss: -0.1855 - acc: 0.9914 - val_loss: -0.2108 - val_acc: 0.9911\n",
      "Epoch 6/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.2405 - acc: 0.9919\n",
      "New maximum F1 score: 0.813247470101196 (before: 0.8117845749671608) Saving to model_lstm2_germeval.0.h5\n",
      "1500/1500 [==============================] - 787s 525ms/step - loss: -0.2405 - acc: 0.9919 - val_loss: -0.2639 - val_acc: 0.9909\n",
      "Epoch 7/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.2954 - acc: 0.9924\n",
      "New maximum F1 score: 0.8155988857938719 (before: 0.813247470101196) Saving to model_lstm2_germeval.0.h5\n",
      "1500/1500 [==============================] - 790s 526ms/step - loss: -0.2954 - acc: 0.9924 - val_loss: -0.3180 - val_acc: 0.9909\n",
      "Epoch 8/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.3499 - acc: 0.9929\n",
      "New maximum F1 score: 0.824186046511628 (before: 0.8155988857938719) Saving to model_lstm2_germeval.0.h5\n",
      "1500/1500 [==============================] - 793s 529ms/step - loss: -0.3499 - acc: 0.9929 - val_loss: -0.3716 - val_acc: 0.9913\n",
      "Epoch 9/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.4042 - acc: 0.9932\n",
      "New maximum F1 score: 0.8261269549218031 (before: 0.824186046511628) Saving to model_lstm2_germeval.0.h5\n",
      "1500/1500 [==============================] - 800s 534ms/step - loss: -0.4042 - acc: 0.9932 - val_loss: -0.4255 - val_acc: 0.9916\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 784s 523ms/step - loss: -0.4584 - acc: 0.9934 - val_loss: -0.4779 - val_acc: 0.9913\n",
      "Epoch 1/10\n",
      "93/94 [============================>.] - ETA: 0s - loss: -0.4347 - acc: 0.9941\n",
      "New maximum F1 score: 0.8265437788018433 (before: 0.8261269549218031) Saving to model_lstm2_germeval.0.h5\n",
      "94/94 [==============================] - 106s 1s/step - loss: -0.4347 - acc: 0.9941 - val_loss: -0.4290 - val_acc: 0.9916\n",
      "Epoch 2/10\n",
      "94/94 [==============================] - 99s 1s/step - loss: -0.4386 - acc: 0.9944 - val_loss: -0.4323 - val_acc: 0.9916\n",
      "Epoch 3/10\n",
      "93/94 [============================>.] - ETA: 0s - loss: -0.4424 - acc: 0.9946\n",
      "New maximum F1 score: 0.8272811059907834 (before: 0.8265437788018433) Saving to model_lstm2_germeval.0.h5\n",
      "94/94 [==============================] - 100s 1s/step - loss: -0.4424 - acc: 0.9946 - val_loss: -0.4358 - val_acc: 0.9916\n",
      "Epoch 4/10\n",
      "94/94 [==============================] - 100s 1s/step - loss: -0.4458 - acc: 0.9945 - val_loss: -0.4389 - val_acc: 0.9915\n",
      "Epoch 5/10\n",
      "94/94 [==============================] - 100s 1s/step - loss: -0.4495 - acc: 0.9949 - val_loss: -0.4424 - val_acc: 0.9916\n",
      "Epoch 6/10\n",
      "94/94 [==============================] - 98s 1s/step - loss: -0.4529 - acc: 0.9949 - val_loss: -0.4455 - val_acc: 0.9915\n",
      "Epoch 7/10\n",
      "94/94 [==============================] - 99s 1s/step - loss: -0.4566 - acc: 0.9950 - val_loss: -0.4489 - val_acc: 0.9916\n",
      "Epoch 8/10\n",
      "94/94 [==============================] - 99s 1s/step - loss: -0.4603 - acc: 0.9951 - val_loss: -0.4521 - val_acc: 0.9915\n",
      "Epoch 9/10\n",
      "94/94 [==============================] - 101s 1s/step - loss: -0.4637 - acc: 0.9952 - val_loss: -0.4553 - val_acc: 0.9917\n",
      "Epoch 10/10\n",
      "94/94 [==============================] - 99s 1s/step - loss: -0.4671 - acc: 0.9951 - val_loss: -0.4588 - val_acc: 0.9917\n",
      "Run 1\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 52)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 52, 32) 10688       char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_9 (TimeDistrib (None, None, 52, 100 33200       char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_10 (TimeDistri (None, None, 100)    60400       time_distributed_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, None, 408)    0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, None, 400)    974400      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "crf (CRF)                       (None, None, 26)     11154       bidirectional_12[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 1,089,906\n",
      "Trainable params: 1,089,842\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: 0.0467 - acc: 0.9835\n",
      "New maximum F1 score: 0.7574827321565617 (before: 0) Saving to model_lstm2_germeval.1.h5\n",
      "1500/1500 [==============================] - 799s 533ms/step - loss: 0.0467 - acc: 0.9835 - val_loss: 0.0046 - val_acc: 0.9890\n",
      "Epoch 2/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.0166 - acc: 0.9887\n",
      "New maximum F1 score: 0.7847957639939486 (before: 0.7574827321565617) Saving to model_lstm2_germeval.1.h5\n",
      "1500/1500 [==============================] - 788s 525ms/step - loss: -0.0166 - acc: 0.9887 - val_loss: -0.0443 - val_acc: 0.9903\n",
      "Epoch 3/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.0697 - acc: 0.9901\n",
      "New maximum F1 score: 0.7965433026488822 (before: 0.7847957639939486) Saving to model_lstm2_germeval.1.h5\n",
      "1500/1500 [==============================] - 787s 525ms/step - loss: -0.0697 - acc: 0.9901 - val_loss: -0.0970 - val_acc: 0.9908\n",
      "Epoch 4/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.1247 - acc: 0.9908\n",
      "New maximum F1 score: 0.8088538735696867 (before: 0.7965433026488822) Saving to model_lstm2_germeval.1.h5\n",
      "1500/1500 [==============================] - 785s 524ms/step - loss: -0.1248 - acc: 0.9908 - val_loss: -0.1509 - val_acc: 0.9911\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 785s 523ms/step - loss: -0.1800 - acc: 0.9916 - val_loss: -0.2046 - val_acc: 0.9906\n",
      "Epoch 6/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.2349 - acc: 0.9921\n",
      "New maximum F1 score: 0.8099539170506913 (before: 0.8088538735696867) Saving to model_lstm2_germeval.1.h5\n",
      "1500/1500 [==============================] - 794s 530ms/step - loss: -0.2349 - acc: 0.9921 - val_loss: -0.2580 - val_acc: 0.9907\n",
      "Epoch 7/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.2898 - acc: 0.9926\n",
      "New maximum F1 score: 0.8174967836794708 (before: 0.8099539170506913) Saving to model_lstm2_germeval.1.h5\n",
      "1500/1500 [==============================] - 784s 522ms/step - loss: -0.2898 - acc: 0.9926 - val_loss: -0.3117 - val_acc: 0.9911\n",
      "Epoch 8/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.3443 - acc: 0.9928\n",
      "New maximum F1 score: 0.8222180939996284 (before: 0.8174967836794708) Saving to model_lstm2_germeval.1.h5\n",
      "1500/1500 [==============================] - 777s 518ms/step - loss: -0.3443 - acc: 0.9928 - val_loss: -0.3663 - val_acc: 0.9913\n",
      "Epoch 9/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.3985 - acc: 0.9932\n",
      "New maximum F1 score: 0.8264771877337322 (before: 0.8222180939996284) Saving to model_lstm2_germeval.1.h5\n",
      "1500/1500 [==============================] - 780s 520ms/step - loss: -0.3985 - acc: 0.9932 - val_loss: -0.4194 - val_acc: 0.9916\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 780s 520ms/step - loss: -0.4525 - acc: 0.9934 - val_loss: -0.4722 - val_acc: 0.9911\n",
      "Epoch 1/10\n",
      "93/94 [============================>.] - ETA: 0s - loss: -0.4291 - acc: 0.9941\n",
      "New maximum F1 score: 0.8294573643410853 (before: 0.8264771877337322) Saving to model_lstm2_germeval.1.h5\n",
      "94/94 [==============================] - 104s 1s/step - loss: -0.4292 - acc: 0.9941 - val_loss: -0.4228 - val_acc: 0.9915\n",
      "Epoch 2/10\n",
      "94/94 [==============================] - 99s 1s/step - loss: -0.4331 - acc: 0.9945 - val_loss: -0.4261 - val_acc: 0.9915\n",
      "Epoch 3/10\n",
      "93/94 [============================>.] - ETA: 0s - loss: -0.4366 - acc: 0.9945\n",
      "New maximum F1 score: 0.8316100443131462 (before: 0.8294573643410853) Saving to model_lstm2_germeval.1.h5\n",
      "94/94 [==============================] - 99s 1s/step - loss: -0.4367 - acc: 0.9945 - val_loss: -0.4296 - val_acc: 0.9917\n",
      "Epoch 4/10\n",
      "94/94 [==============================] - 99s 1s/step - loss: -0.4404 - acc: 0.9948 - val_loss: -0.4330 - val_acc: 0.9916\n",
      "Epoch 5/10\n",
      "94/94 [==============================] - 99s 1s/step - loss: -0.4440 - acc: 0.9949 - val_loss: -0.4361 - val_acc: 0.9916\n",
      "Epoch 6/10\n",
      "94/94 [==============================] - 100s 1s/step - loss: -0.4474 - acc: 0.9949 - val_loss: -0.4394 - val_acc: 0.9917\n",
      "Epoch 7/10\n",
      "94/94 [==============================] - 99s 1s/step - loss: -0.4511 - acc: 0.9950 - val_loss: -0.4427 - val_acc: 0.9917\n",
      "Epoch 8/10\n",
      "94/94 [==============================] - 98s 1s/step - loss: -0.4544 - acc: 0.9951 - val_loss: -0.4462 - val_acc: 0.9916\n",
      "Epoch 9/10\n",
      "94/94 [==============================] - 97s 1s/step - loss: -0.4581 - acc: 0.9952 - val_loss: -0.4492 - val_acc: 0.9916\n",
      "Epoch 10/10\n",
      "93/94 [============================>.] - ETA: 0s - loss: -0.4616 - acc: 0.9952\n",
      "New maximum F1 score: 0.8325341202508298 (before: 0.8316100443131462) Saving to model_lstm2_germeval.1.h5\n",
      "94/94 [==============================] - 97s 1s/step - loss: -0.4616 - acc: 0.9952 - val_loss: -0.4529 - val_acc: 0.9918\n",
      "Run 2\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 52)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 52, 32) 10688       char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_11 (TimeDistri (None, None, 52, 100 33200       char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "case_embed (Embedding)          (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_12 (TimeDistri (None, None, 100)    60400       time_distributed_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, None, 408)    0           words_input[0][0]                \n",
      "                                                                 case_embed[0][0]                 \n",
      "                                                                 time_distributed_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, None, 400)    974400      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "crf (CRF)                       (None, None, 26)     11154       bidirectional_15[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 1,089,906\n",
      "Trainable params: 1,089,842\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: 0.0444 - acc: 0.9835\n",
      "New maximum F1 score: 0.7617267800411137 (before: 0) Saving to model_lstm2_germeval.2.h5\n",
      "1500/1500 [==============================] - 761s 507ms/step - loss: 0.0444 - acc: 0.9835 - val_loss: 0.0019 - val_acc: 0.9890\n",
      "Epoch 2/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.0205 - acc: 0.9887\n",
      "New maximum F1 score: 0.7893425340233852 (before: 0.7617267800411137) Saving to model_lstm2_germeval.2.h5\n",
      "1500/1500 [==============================] - 751s 501ms/step - loss: -0.0205 - acc: 0.9887 - val_loss: -0.0487 - val_acc: 0.9901\n",
      "Epoch 3/10\n",
      " 679/1500 [============>.................] - ETA: 6:45 - loss: -0.0600 - acc: 0.9900"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.1294 - acc: 0.9908\n",
      "New maximum F1 score: 0.8047226386806596 (before: 0.8028009084027252) Saving to model_lstm2_germeval.2.h5\n",
      "1500/1500 [==============================] - 753s 502ms/step - loss: -0.1294 - acc: 0.9908 - val_loss: -0.1558 - val_acc: 0.9905\n",
      "Epoch 5/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.1848 - acc: 0.9915\n",
      "New maximum F1 score: 0.8162273322116285 (before: 0.8047226386806596) Saving to model_lstm2_germeval.2.h5\n",
      "1500/1500 [==============================] - 748s 499ms/step - loss: -0.1848 - acc: 0.9915 - val_loss: -0.2098 - val_acc: 0.9912\n",
      "Epoch 6/10\n",
      "1459/1500 [============================>.] - ETA: 19s - loss: -0.2392 - acc: 0.9922"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 752s 501ms/step - loss: -0.4036 - acc: 0.9932 - val_loss: -0.4239 - val_acc: 0.9911\n",
      "Epoch 10/10\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.4577 - acc: 0.9935\n",
      "New maximum F1 score: 0.8191391095510807 (before: 0.8162273322116285) Saving to model_lstm2_germeval.2.h5\n",
      "1500/1500 [==============================] - 746s 497ms/step - loss: -0.4577 - acc: 0.9935 - val_loss: -0.4773 - val_acc: 0.9914\n",
      "Epoch 1/10\n",
      "39/94 [===========>..................] - ETA: 53s - loss: -0.4872 - acc: 0.9945"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1499/1500 [============================>.] - ETA: 0s - loss: -0.0161 - acc: 0.9888\n",
      "New maximum F1 score: 0.7884542347132549 (before: 0.7645024971187091) Saving to model_lstm2_germeval.3.h5\n",
      "1500/1500 [==============================] - 750s 500ms/step - loss: -0.0161 - acc: 0.9888 - val_loss: -0.0442 - val_acc: 0.9903\n",
      "Epoch 3/10\n",
      " 180/1500 [==>...........................] - ETA: 10:45 - loss: -0.0473 - acc: 0.9900"
     ]
    }
   ],
   "source": [
    "f = open('results_lstm2_germeval.txt', 'a')\n",
    "for run_i in range(10):\n",
    "    print(\"Run \" + str(run_i))\n",
    "    \n",
    "    tmp_model_filename = 'model_lstm2_germeval.' + str(run_i) + '.h5'\n",
    "\n",
    "    history = utils.F1History(tmp_model_filename, devSet=devSentences)\n",
    "\n",
    "    model = models.get_model_2lstm_v2()\n",
    "    model.fit_generator(\n",
    "        utils.NerSequence(trainSentences, shuffle_data=True, batch_size=16), \n",
    "        validation_data = utils.NerSequence(devSentences, batch_size=512), \n",
    "        epochs = 10, callbacks = [history]\n",
    "    )\n",
    "    \n",
    "    model.load_weights(tmp_model_filename)\n",
    "    \n",
    "    model.fit_generator(\n",
    "        utils.NerSequence(trainSentences, shuffle_data=True, batch_size=256), \n",
    "        validation_data = utils.NerSequence(devSentences, batch_size=512), \n",
    "        epochs = 10, callbacks = [history]\n",
    "    )\n",
    "    \n",
    "    model.load_weights(tmp_model_filename)\n",
    "    \n",
    "    true_labels, pred_labels = utils.predict_sequences(model, testSentences)\n",
    "    \n",
    "    pre, rec, f1 = compute_f1(pred_labels, true_labels, models.idx2Label)\n",
    "    f.write(str(run_i) + \"\\t\" + str(pre) + \"\\t\" + str(rec) +  \"\\t\" + str(f1))\n",
    "    f.write(\"\\n\")\n",
    "    f.flush()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, json\n",
    "# copy file for best run\n",
    "shutil.copyfile('tmp_3cnn_bi-lstm.h5', '../models/final_model_germeval_outer.h5')\n",
    "with open(\"../models/final_model_germeval.indexes\", \"w\") as f:\n",
    "    json.dump([models.idx2Label, models.label2Idx, models.char2Idx, models.case2Idx], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_contrib.layers import CRF\n",
    "def create_custom_objects():\n",
    "    instanceHolder = {\"instance\": None}\n",
    "    class ClassWrapper(CRF):\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            instanceHolder[\"instance\"] = self\n",
    "            super(ClassWrapper, self).__init__(*args, **kwargs)\n",
    "    def loss(*args):\n",
    "        method = getattr(instanceHolder[\"instance\"], \"loss_function\")\n",
    "        return method(*args)\n",
    "    def accuracy(*args):\n",
    "        method = getattr(instanceHolder[\"instance\"], \"accuracy\")\n",
    "        return method(*args)\n",
    "    return {\"ClassWrapper\": ClassWrapper ,\"CRF\": ClassWrapper, \"loss\": loss, \"accuracy\":accuracy}\n",
    "\n",
    "finalmodel = load_model('../models/final_model_germeval_outer.h5', custom_objects=create_custom_objects())\n",
    "true_labels, pred_labels = utils.predict_sequences(finalmodel, testSentences)\n",
    "print(compute_f1(pred_labels, true_labels, models.idx2Label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('germeval_output.tsv', 'w', encoding='UTF-8')\n",
    "for i_sent, sent in enumerate(testSentences):\n",
    "    for i_tok, tok in enumerate(sent):\n",
    "        if tok[0] == 'PADDING_TOKEN':\n",
    "            break\n",
    "        correctlabel = models.idx2Label[true_labels[i_sent][i_tok]]\n",
    "        guessedlabel = models.idx2Label[pred_labels[i_sent][i_tok]]\n",
    "        line = \"\\t\".join([str(i_tok+1), tok[0], correctlabel, correctlabel, guessedlabel, guessedlabel])\n",
    "        f.write(line + '\\n')\n",
    "    f.write('\\n')\n",
    "f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
